{
 "metadata": {
  "name": "",
  "signature": "sha256:bb539f8aaa222da8b1f8669aa763afda6419f484823880b50394aad200d430b5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import twitter\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import os\n",
      "import json\n",
      "import time\n",
      "import datetime\n",
      "import seaborn as sns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 8.2. Twitter Time Series.\n",
      "\n",
      "- When you are done, rename your file to `FirstName_LastName_twitter_series.ipynb`\n",
      "  and submit it via Moodle.\n",
      "- In this problem, you will use a real-time stream of tweets\n",
      "  to track the number of tweets that contain your query phrase.\n",
      "\n",
      "### Create a Twitter API Connection\n",
      "\n",
      "First, You have to get Twitter OAuth credentials and obtain API access at\n",
      "  https://dev.twitter.com/apps/new as detailed in Chapter 1 of\n",
      "  Mining the Social Web 2nd Edition by Matthew A. Russell\n",
      "  (hereafter referred to as simply the book),\n",
      "  and fill in your OAuth credentials in place of the empty strings.\n",
      "  See https://dev.twitter.com/docs/auth/oauth for more information\n",
      "  on Twitter's OAuth implementation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CONSUMER_KEY = ''\n",
      "CONSUMER_SECRET = ''\n",
      "OAUTH_TOKEN = ''\n",
      "OAUTH_TOKEN_SECRET = ''\n",
      "\n",
      "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
      "                           CONSUMER_KEY, CONSUMER_SECRET)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The search API (`twitter.Twitter` connector) described in Chapter 1 of the book is easy to use,\n",
      "  but the data you get from the search API can be delayed by minutes or even hours.\n",
      "  But when you want to do a time-series analysis using a *real-time* stream of tweets,\n",
      "  you can use the streaming API (`twitter.TwitterStream` connector) instead.\n",
      "  Note that the streaming data is a 1% random subsample of all tweets available.\n",
      "  Similar to the search API `twitter.Twitter`,\n",
      "  the streaming API `twitter.TwitterStream` takes the same `twitter.oauth.OAuth` object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twitter_api = twitter.TwitterStream(auth=auth)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the following cell, try a search query and replace the file path if necessary.\n",
      "  Run it, and grab a snack or study the `get_time_series_data()` function, as it may take up to 10 minutes.\n",
      "  I repeat, do not stop this cell. It takes up to 10 minutes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Search query, try your own.\n",
      "# Note that an unpopular trend won't get you\n",
      "# enough number of tweets in 10 minutes, so\n",
      "# you may have to increase max_time.\n",
      "# justinbieber is a safe bet to get enough tweets.\n",
      "q = 'justinbieber'\n",
      "# we will save the fetched twitter data to a file at fpath.\n",
      "fpath = '/data/twitter'\n",
      "\n",
      "def get_time_series_data(twitter_api, q, max_time=600, max_iter=None):\n",
      "    '''\n",
      "    Use the Twitter streaming API to get a real-time stream of tweets\n",
      "    and\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    twitter_api: Use twitter.TwitterStream to create an object.\n",
      "    q: A str. The search query (e.g. '#informatics')\n",
      "    max_time: In seconds. Stops the query when max_time is reached.\n",
      "    max_iter: Stops the query after max_iter number of iterations.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    A list of dictionaries.\n",
      "    '''\n",
      "    count = 0\n",
      "    twitter_stream = twitter.TwitterStream(auth=twitter_api.auth)\n",
      "    \n",
      "    # See https://dev.twitter.com/docs/streaming-apis\n",
      "    stream = twitter_stream.statuses.filter(track=q)\n",
      "    \n",
      "    statuses = []\n",
      "    \n",
      "    start = datetime.datetime.now()\n",
      "    \n",
      "    try:\n",
      "        for tweet in stream:\n",
      "            \n",
      "            statuses.append(tweet)\n",
      "        \n",
      "            count += 1\n",
      "            \n",
      "            if count % 100 == 0:\n",
      "                \n",
      "                print('{0} tweets fetched...'.format(count))\n",
      "                \n",
      "                now = datetime.datetime.now()\n",
      "                if now - start > datetime.timedelta(0, max_time, 0):\n",
      "                    break\n",
      "\n",
      "            if max_iter is not None and count >= max_iter:\n",
      "                break\n",
      "                    \n",
      "    except Exception as e:\n",
      "        print(e)\n",
      "            \n",
      "    return statuses\n",
      "\n",
      "# if the keyword has never been queried,\n",
      "# use twitter streaming API to get real-time data.\n",
      "if not os.path.isfile(os.path.join(fpath, '{0}.json'.format(q))):\n",
      "    \n",
      "    tweets = get_time_series_data(twitter_api, q)\n",
      "    \n",
      "    if not os.path.exists(fpath):\n",
      "        os.mkdir(fpath)\n",
      "        \n",
      "    with open(os.path.join(fpath, '{0}.json'.format(q)), 'w') as f:\n",
      "        json.dump(tweets, f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After about 10 minutes, the result will be saved to the file named `<query>.json`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(os.path.join(fpath, '{0}.json'.format(q)), 'r') as f:\n",
      "    tweets = json.load(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you read the book, you know that `tweets` returned from `get_time_series_data()` function\n",
      "  is a list of dictionaries that contains all the metadata from every tweets we fetched.\n",
      "  You can check this by doing `print(tweets)`, `print(type(tweets))`, and/or `print(type(tweets[0]))`.\n",
      "  \n",
      "### Function: get_created_at()\n",
      "\n",
      "Now your task is to\n",
      "\n",
      "- write a function that takes a list of dictionaries\n",
      "  (`tweets` or Twitter statuses) and returns a `pandas.Series` object.\n",
      "  \n",
      "Each status is a dictionary and has the key `created_at`.\n",
      "For example, `print(tweets[0]['created_at']` for my data set says\n",
      "    \n",
      "    Fri Mar 06 04:31:26 +0000 2015\n",
      "    \n",
      "You should use this `created_at` time to create each `DatetimeIndex` for `pd.Series`.\n",
      "\n",
      "In the end, you should return a `pd.Series` with the number of tweets created at **each second**.\n",
      "\n",
      "```python\n",
      ">>> print(get_created_at(tweets))\n",
      "\n",
      "2015-03-06 04:31:26    4\n",
      "2015-03-06 04:31:27    5\n",
      "2015-03-06 04:31:28    4\n",
      "2015-03-06 04:31:29    4\n",
      "2015-03-06 04:31:30    4\n",
      "2015-03-06 04:31:31    7\n",
      "2015-03-06 04:31:32    6\n",
      "2015-03-06 04:31:33    8\n",
      "2015-03-06 04:31:34    2\n",
      "2015-03-06 04:31:35    7\n",
      "2015-03-06 04:31:36    8\n",
      "2015-03-06 04:31:37    5\n",
      "2015-03-06 04:31:38    5\n",
      "2015-03-06 04:31:39    6\n",
      "2015-03-06 04:31:40    6\n",
      "...\n",
      "2015-03-06 04:41:22    1\n",
      "2015-03-06 04:41:23    1\n",
      "2015-03-06 04:41:24    2\n",
      "2015-03-06 04:41:25    1\n",
      "2015-03-06 04:41:26    5\n",
      "2015-03-06 04:41:27    0\n",
      "2015-03-06 04:41:28    1\n",
      "2015-03-06 04:41:29    3\n",
      "2015-03-06 04:41:30    0\n",
      "2015-03-06 04:41:31    3\n",
      "2015-03-06 04:41:32    4\n",
      "2015-03-06 04:41:33    1\n",
      "2015-03-06 04:41:34    2\n",
      "2015-03-06 04:41:35    2\n",
      "2015-03-06 04:41:36    2\n",
      "Length: 611\n",
      "```\n",
      "\n",
      "Note that you will get different times and numbers.\n",
      "  And if there was no tweet at a particular second in time,\n",
      "  the count should be zero."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_created_at(tweets):\n",
      "    '''\n",
      "    Takes a list of dictionaries (twitter statuses)\n",
      "    and returns a Pandas Series indexed by the 'created_at' time\n",
      "    in the twitter metadata.\n",
      "    Returns the number of tweets at each timestamp.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    tweets: A list of dictionaries.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    A pandas.Series.\n",
      "    '''\n",
      "    \n",
      "    # your code goes here\n",
      "    \n",
      "    return ts\n",
      "\n",
      "ts = get_created_at(tweets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Plot\n",
      "\n",
      "Finally, you should\n",
      "\n",
      "- plot the **median** (the 50th percentile)\n",
      "  number of tweets in a certain time interval.\n",
      "  \n",
      "An interval of 60 seconds seems reasonable,\n",
      "  but you should choose an interval that is most appropriate for your data set.\n",
      "  You should also\n",
      "  \n",
      "- draw confidence bands based on the 16th and 84th percentiles\n",
      "  (a 68% or one standard deviation level of confidence).\n",
      "\n",
      "You can do this by using [pandas.Series.resample](http://pandas.pydata.org/pandas-docs/dev/generated/pandas.Series.resample.html) to\n",
      "  redefine the time interval of your time series data.\n",
      "  Note that the `how` parameter can be a list or a dictionary.\n",
      "  For our purposes, you can use the following:\n",
      "  \n",
      "```python\n",
      "how={'50th percentile': np.median,\n",
      "     '16th percentile': lambda x: np.percentile(x, 16),\n",
      "     '84th percentile': lambda x: np.percentile(x, 84)}\n",
      "```\n",
      "\n",
      "If you have multiple `how` functions, the `resample()` method will\n",
      "  return a dataframe. You can use the `16th percentile` and `84th percentile` columns\n",
      "  of this dataframe in the\n",
      "  [`fill_bewteen()` function](http://matplotlib.org/users/recipes.html#fill-between-and-alpha)\n",
      "  to draw the confidence band."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# your code goes here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
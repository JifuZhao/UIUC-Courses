## Problem 12.1. HDF.

- The IPython notebook template for this problem is
  [hdf.ipynb](http://nbviewer.ipython.org/github/INFO490/spring2015/blob/master/week12/hdf.ipynb).

This problem will give you a chance to practice what you have learned in
  [lesson 1](http://nbviewer.ipython.org/github/INFO490/spring2015/blob/master/w
eek12/intro2de.ipynb)
  about saving a DataFrame to an HDF file.


You should use
  [columns 9-14](http://stat-computing.org/dataexpo/2009/the-data.html)
  of `2001.csv`:
  `UniqueCarrier`, `FlightNum`, `TailNum`, `ActualElapsedTime`,
`CRSElapsedTime`,
  and `AirTime`.

  ```python
  ucs = list(range(8, 14)) # the count starts at 0
  cnms = ['UniqueCarrier',
          'FlightNum',
          'TailNum',
          'ActualElapsedTime',
          'CRSElapsedTime',
          'AirTime']
  ```

### Function: csv\_to\_hdf()

Write a function that takes three strings: the path to the CSV file,
  the path to the HDF file, and the table name.

- Use six columns listed in `ucs` and `cnms`.
- Don't forget that there may be missing values.
  You should drop all rows that have missing values in any or all columns of
that row.
- After you use `pandas.read_csv()` to create a DataFrame,
  use [`pandas.DataFrame.info()`](http://pandas.pydata.org/pandas-
docs/version/0.13.1/generated/pandas.DataFrame.info.html)
  or [`pandas.DataFrame.dtypes`](http://pandas.pydata.org/pandas-
docs/version/0.13.1/generated/pandas.DataFrame.html)
  to check the data types in the DataFrame.
  If you didn't specify which data types should be used,
  it is likely that Pandas has selected the biggest data type for each column.
  You should change the data type of each column to its optimal data type.

  To do this, use [`Pandas.DataFrame.describe()`](http://pandas.pydata.org
/pandas-docs/version/0.13.1/generated/pandas.DataFrame.describe.html)
  to check the minimum and maximum values of each column.
  Compare them with the ranges of each data type. You can find this information
in the docs,
  e.g. [Numpy data
types](http://docs.scipy.org/doc/numpy/user/basics.types.html),
  or use [numpy.iinfo()](http://docs.scipy.org/doc/numpy/reference/generated/num
py.iinfo.html)
  for ints and
  [numpy.finfo()](http://docs.scipy.org/doc/numpy/reference/generated/numpy.finf
o.html)
  for floats.
  For example, to find the minimum and maximum values that one-byte (8 bits)
unsigned integer would hold,
  run

  ```python
  print(np.iinfo(np.uint8))
  ```

  which prints out

  ```text
  Machine parameters for uint8
  ---------------------------------------------------------------------
  min = 0
  max = 255
  ---------------------------------------------------------------------
  ```

- The function should take three strings.
  The first string is the file path and/or name of the CSV file,
  e.g. `/data/airline/2001.csv`.
  The second string is the file path and/or name that points to the
  HDF file you have created, e.g. `/data/airline/w12p1.h5`
  The third string is the key that can be used to access the table
  in the HDF database, i.e. the string `"table"` you would pass as the
  `key` argument in

  ```python
  store_path = '/data/airline/w12p1.h5'
  df = pd.read_hdf(store_path, key='table')
  ```

  You can list the keys with

  ```python
  with pd.get_store(store_path) as store:
    print(store.keys())
  ```

  which should print out

  ```text
  ['/', '/table']
  ```

- In the end, when I ran

  ```python
  csv_path = '/data/airline/2001.csv'
  store_path = '/data/airline/w12p1.h5'
  table_name = 'table'

  csv_to_hdf(csv_path, store_path, table_name)

  !ls -lah $store_path
  ```

  I got

  ```text
  -rw-r--r-- 1 root root 144M Apr  9 04:35 /data/airline/w12p1.h5
  ```

  So your HDF file should be **no larger than 144M**.


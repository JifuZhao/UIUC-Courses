{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Follow the tutorial material from Kaggle (use TF-IDF instead)\n",
    "* 2-gram\n",
    "* top 10000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./labeledTrainData.tsv', delimiter='\\t', quoting=3)\n",
    "test = pd.read_csv('./testData.tsv', delimiter='\\t', quoting=3)\n",
    "\n",
    "# get the number of training and test examples\n",
    "n_train = len(train)\n",
    "n_test = len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def review2words(review):\n",
    "    \"\"\" function to convert input review into string of words \"\"\"\n",
    "    # Remove HTML\n",
    "    review_text = BeautifulSoup(review, 'lxml').get_text() \n",
    "\n",
    "    # Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "\n",
    "    # Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "\n",
    "    # Join the words and return the result.\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get train label\n",
    "train_y = train['sentiment'].values\n",
    "\n",
    "# transform reviews into words list\n",
    "train_review = list(map(review2words, train['review']))\n",
    "test_review = list(map(review2words, test['review']))\n",
    "\n",
    "# combine train and test reviews\n",
    "all_review = train_review + test_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perform TF-IDF transformation\n",
    "vectorizer = TfidfVectorizer(min_df=3, analyzer=\"word\", strip_accents='unicode', \n",
    "                             sublinear_tf=True, stop_words='english', \n",
    "                             max_features=10000, ngram_range=(1, 2)) \n",
    "\n",
    "# fit and transform the data\n",
    "all_features = vectorizer.fit_transform(all_review)\n",
    "\n",
    "# trainsform into array\n",
    "train_features = all_features[:n_train, :].toarray()\n",
    "test_features = all_features[n_train:, :].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Ridge Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the Logistic model\n",
    "logit2 = LogisticRegression(penalty='l2', tol=0.0001, C=2.7825549, random_state=2017, \n",
    "                            solver='liblinear', n_jobs=-1, verbose=0)\n",
    "logit2 = logit2.fit(train_features, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "train_pred1 = logit2.predict_proba(train_features)[:, 1]\n",
    "test_pred1 = logit2.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC\t 0.988545088\n"
     ]
    }
   ],
   "source": [
    "# # save prediction into local files\n",
    "# output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred1})\n",
    "# output.to_csv(\"./result/logit_ridge.csv\", index=False, quoting=3)\n",
    "\n",
    "# get the AUC score\n",
    "print('Training AUC\\t', roc_auc_score(train_y, train_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Lasso Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the Logistic model\n",
    "logit1 = LogisticRegression(penalty='l1', tol=0.0001, C=2.7825549, random_state=2017, \n",
    "                            solver='liblinear', n_jobs=-1, verbose=0)\n",
    "logit1 = logit1.fit(train_features, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "train_pred2 = logit1.predict_proba(train_features)[:, 1]\n",
    "test_pred2 = logit1.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC\t 0.9879110592\n"
     ]
    }
   ],
   "source": [
    "# # save prediction into local files\n",
    "# output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred2})\n",
    "# output.to_csv(\"./result/logit_lasso.csv\", index=False, quoting=3)\n",
    "\n",
    "# get the AUC score\n",
    "print('Training AUC\\t', roc_auc_score(train_y, train_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Multinomial Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the NB model\n",
    "nb = MultinomialNB(alpha=5.0, fit_prior=True, class_prior=None)\n",
    "nb = nb.fit(train_features, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "train_pred3 = nb.predict_proba(train_features)[:, 1]\n",
    "test_pred3 = nb.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC\t 0.9498812928\n"
     ]
    }
   ],
   "source": [
    "# # save prediction into local files\n",
    "# output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred3})\n",
    "# output.to_csv(\"./result/naive_bayes.csv\", index=False, quoting=3)\n",
    "\n",
    "# get the AUC score\n",
    "print('Training AUC\\t', roc_auc_score(train_y, train_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the AdaBoost classifier\n",
    "adaboost = AdaBoostClassifier(n_estimators=400, learning_rate=1.0, \n",
    "                              algorithm='SAMME.R', random_state=2017)\n",
    "adaboost = adaboost.fit(train_features, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "train_pred4 = adaboost.predict_proba(train_features)[:, 1]\n",
    "test_pred4 = adaboost.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC\t 0.9622484224\n"
     ]
    }
   ],
   "source": [
    "# # save prediction into local files\n",
    "# output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred4})\n",
    "# output.to_csv(\"./result/adaboost.csv\", index=False, quoting=3)\n",
    "\n",
    "# get the AUC score\n",
    "print('Training AUC\\t', roc_auc_score(train_y, train_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the Gradient Boosting classifier\n",
    "gbm = GradientBoostingClassifier(learning_rate=0.2, n_estimators=500, subsample=1.0,\n",
    "                                 max_features='auto', min_samples_split=2, random_state=2017, \n",
    "                                 min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3)\n",
    "gbm = gbm.fit(train_features, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "train_pred5 = gbm.predict_proba(train_features)[:, 1]\n",
    "test_pred5 = gbm.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC\t 0.991960976\n"
     ]
    }
   ],
   "source": [
    "# # save prediction into local files\n",
    "# output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred5})\n",
    "# output.to_csv(\"./result/gbm.csv\", index=False, quoting=3)\n",
    "\n",
    "# get the AUC score\n",
    "print('Training AUC\\t', roc_auc_score(train_y, train_pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize a Random Forest classifier\n",
    "forest = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=2017, \n",
    "                                oob_score=True, max_features='auto') \n",
    "\n",
    "# Fit the forest to the training set\n",
    "forest = forest.fit(train_features, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "train_pred6 = forest.predict_proba(train_features)[:, 1]\n",
    "test_pred6 = forest.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC\t 1.0\n"
     ]
    }
   ],
   "source": [
    "# # save prediction into local files\n",
    "# output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred6})\n",
    "# output.to_csv(\"./result/random_forest.csv\", index=False, quoting=3)\n",
    "\n",
    "# get the AUC score\n",
    "print('Training AUC\\t', roc_auc_score(train_y, train_pred6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC\t 0.9952052544\n"
     ]
    }
   ],
   "source": [
    "# define weights\n",
    "w = np.array([2, 2, 1, 1, 1, 1]) / 8.0\n",
    "\n",
    "# weighted train and test prediction\n",
    "train_pred = w[0] * train_pred1 + w[1] * train_pred2 + w[2] * train_pred3 +\\\n",
    "    w[3] * train_pred4 + w[4] * train_pred5 + w[5] * train_pred6\n",
    "    \n",
    "test_pred = w[0] * test_pred1 + w[1] * test_pred2 + w[2] * test_pred3 +\\\n",
    "    w[3] * test_pred4 + w[4] * test_pred5 + w[5] * test_pred6\n",
    "    \n",
    "# save prediction into local files\n",
    "output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred})\n",
    "output.to_csv(\"./mysubmission.csv\", index=False, quoting=3)\n",
    "\n",
    "# get the AUC score\n",
    "print('Training AUC\\t', roc_auc_score(train_y, train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC\t 0.9932406976\n"
     ]
    }
   ],
   "source": [
    "# define weights\n",
    "w = np.array([4, 4, 1, 1, 1, 1]) / 12.0\n",
    "\n",
    "# weighted train and test prediction\n",
    "train_pred = w[0] * train_pred1 + w[1] * train_pred2 + w[2] * train_pred3 +\\\n",
    "    w[3] * train_pred4 + w[4] * train_pred5 + w[5] * train_pred6\n",
    "    \n",
    "test_pred = w[0] * test_pred1 + w[1] * test_pred2 + w[2] * test_pred3 +\\\n",
    "    w[3] * test_pred4 + w[4] * test_pred5 + w[5] * test_pred6\n",
    "    \n",
    "# save prediction into local files\n",
    "output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred})\n",
    "output.to_csv(\"./mysubmission1.csv\", index=False, quoting=3)\n",
    "\n",
    "# get the AUC score\n",
    "print('Training AUC\\t', roc_auc_score(train_y, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC\t 0.9889091904\n"
     ]
    }
   ],
   "source": [
    "# define weights\n",
    "w = np.array([1, 1, 0, 0, 0, 0]) / 2.0\n",
    "\n",
    "# weighted train and test prediction\n",
    "train_pred = w[0] * train_pred1 + w[1] * train_pred2 + w[2] * train_pred3 +\\\n",
    "    w[3] * train_pred4 + w[4] * train_pred5 + w[5] * train_pred6\n",
    "    \n",
    "test_pred = w[0] * test_pred1 + w[1] * test_pred2 + w[2] * test_pred3 +\\\n",
    "    w[3] * test_pred4 + w[4] * test_pred5 + w[5] * test_pred6\n",
    "    \n",
    "# save prediction into local files\n",
    "output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred})\n",
    "output.to_csv(\"./mysubmission2.csv\", index=False, quoting=3)\n",
    "\n",
    "# get the AUC score\n",
    "print('Training AUC\\t', roc_auc_score(train_y, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC\t 0.9940442496\n"
     ]
    }
   ],
   "source": [
    "# define weights\n",
    "w = np.array([3, 3, 1, 1, 1, 1]) / 10.0\n",
    "\n",
    "# weighted train and test prediction\n",
    "train_pred = w[0] * train_pred1 + w[1] * train_pred2 + w[2] * train_pred3 +\\\n",
    "    w[3] * train_pred4 + w[4] * train_pred5 + w[5] * train_pred6\n",
    "    \n",
    "test_pred = w[0] * test_pred1 + w[1] * test_pred2 + w[2] * test_pred3 +\\\n",
    "    w[3] * test_pred4 + w[4] * test_pred5 + w[5] * test_pred6\n",
    "    \n",
    "# save prediction into local files\n",
    "output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred})\n",
    "output.to_csv(\"./mysubmission3.csv\", index=False, quoting=3)\n",
    "\n",
    "# get the AUC score\n",
    "print('Training AUC\\t', roc_auc_score(train_y, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC\t 0.9952052544\n"
     ]
    }
   ],
   "source": [
    "# define weights\n",
    "w = np.array([2, 2, 1, 1, 1, 1]) / 8.0\n",
    "\n",
    "# weighted train and test prediction\n",
    "train_pred = w[0] * train_pred1 + w[1] * train_pred2 + w[2] * train_pred3 +\\\n",
    "    w[3] * train_pred4 + w[4] * train_pred5 + w[5] * train_pred6\n",
    "    \n",
    "test_pred = w[0] * test_pred1 + w[1] * test_pred2 + w[2] * test_pred3 +\\\n",
    "    w[3] * test_pred4 + w[4] * test_pred5 + w[5] * test_pred6\n",
    "    \n",
    "# save prediction into local files\n",
    "output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred})\n",
    "output.to_csv(\"./mysubmission4.csv\", index=False, quoting=3)\n",
    "\n",
    "# get the AUC score\n",
    "print('Training AUC\\t', roc_auc_score(train_y, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC\t 0.9969895488\n"
     ]
    }
   ],
   "source": [
    "# define weights\n",
    "w = np.array([1, 1, 1, 1, 1, 1]) / 6.0\n",
    "\n",
    "# weighted train and test prediction\n",
    "train_pred = w[0] * train_pred1 + w[1] * train_pred2 + w[2] * train_pred3 +\\\n",
    "    w[3] * train_pred4 + w[4] * train_pred5 + w[5] * train_pred6\n",
    "    \n",
    "test_pred = w[0] * test_pred1 + w[1] * test_pred2 + w[2] * test_pred3 +\\\n",
    "    w[3] * test_pred4 + w[4] * test_pred5 + w[5] * test_pred6\n",
    "    \n",
    "# save prediction into local files\n",
    "output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": test_pred})\n",
    "output.to_csv(\"./mysubmission5.csv\", index=False, quoting=3)\n",
    "\n",
    "# get the AUC score\n",
    "print('Training AUC\\t', roc_auc_score(train_y, train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

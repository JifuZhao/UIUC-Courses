{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oneHotEncoder(label, n):\n",
    "    \"\"\" One-Hot-Encoder for n class case \"\"\"\n",
    "    tmp = np.zeros((len(label), n))\n",
    "    for number in range(n):\n",
    "        tmp[:, number] = (label[:, 0] == number)\n",
    "    tmp = tmp.astype(int)\n",
    "\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Data loading and preprocessing\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    "\n",
    "# get detailed data\n",
    "train_img = mnist.train.images\n",
    "train_label = mnist.train.labels\n",
    "\n",
    "cv_img = mnist.validation.images\n",
    "cv_label = mnist.validation.labels\n",
    "\n",
    "test_img = mnist.test.images\n",
    "test_label = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4300  | total loss: \u001b[1m\u001b[32m0.01354\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 020 | loss: 0.01354 | val_loss: 0.00938 -- iter: 55000/55000\n",
      "Training Step: 4300  | total loss: \u001b[1m\u001b[32m0.01354\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 020 | loss: 0.01354 | val_loss: 0.00938 -- iter: 55000/55000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    tflearn.init_graph(num_cores=2, gpu_memory_fraction=0.4)\n",
    "    \n",
    "    # Building the encoder\n",
    "    encoder = tflearn.input_data(shape=[None, 784])\n",
    "    encoder = tflearn.fully_connected(encoder, 512, activation='sigmoid')\n",
    "    encoder = tflearn.fully_connected(encoder, 256, activation='sigmoid')\n",
    "\n",
    "    # Building the decoder\n",
    "    decoder = tflearn.fully_connected(encoder, 512, activation='sigmoid')\n",
    "    decoder = tflearn.fully_connected(decoder, 784, activation='sigmoid')\n",
    "\n",
    "    # Regression, with mean square error\n",
    "    net = tflearn.regression(decoder, optimizer='adam', learning_rate=0.001,\n",
    "                             loss='mean_square', metric=None)\n",
    "\n",
    "    # Training the auto encoder\n",
    "    model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "    model.fit(train_img, train_img, n_epoch=20, validation_set=(cv_img, cv_img),\n",
    "              run_id=\"auto_encoder\", batch_size=256)\n",
    "\n",
    "    # New model, re-using the same session, for weights sharing\n",
    "    encoding_model = tflearn.DNN(encoder, session=model.session)\n",
    "    train_encoded = encoding_model.predict(train_img)\n",
    "    cv_encoded = encoding_model.predict(cv_img)\n",
    "    test_encoded = encoding_model.predict(test_img)\n",
    "\n",
    "train_encoded = np.array(train_encoded)\n",
    "cv_encoded = np.array(cv_encoded)\n",
    "test_encoded = np.array(test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 17200  | total loss: \u001b[1m\u001b[32m0.44562\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 020 | loss: 0.44562 | val_loss: 0.21219 -- iter: 55000/55000\n",
      "Training Step: 17200  | total loss: \u001b[1m\u001b[32m0.44562\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 020 | loss: 0.44562 | val_loss: 0.21219 -- iter: 55000/55000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Classification using tflearn\n",
    "with tf.Graph().as_default():\n",
    "    tflearn.init_graph(num_cores=8, gpu_memory_fraction=0.8)\n",
    "\n",
    "    # build the one-layer fully connected neural network\n",
    "    net = tflearn.input_data(shape=[None, 256])\n",
    "    net = tflearn.fully_connected(net, 10, activation='softmax')\n",
    "    net = tflearn.regression(net, optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "    # fit the model\n",
    "    model = tflearn.DNN(net)\n",
    "    model.fit(train_encoded, train_label, n_epoch=20, validation_set=(cv_encoded, cv_label))\n",
    "\n",
    "    # predict on the training and test dataset\n",
    "    train_prediction = np.array(model.predict(train_encoded))\n",
    "    test_prediction = np.array(model.predict(test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuract: 0.93815\n",
      "Testing Accuract: 0.941\n"
     ]
    }
   ],
   "source": [
    "# get the label in single number case\n",
    "train_true_label = np.argmax(train_label, axis=1)\n",
    "test_true_label = np.argmax(test_label, axis=1)\n",
    "\n",
    "# get the label\n",
    "train_pred_label = np.argmax(train_prediction, axis=1)\n",
    "test_pred_label = np.argmax(test_prediction, axis=1)\n",
    "\n",
    "# calculate the training and testing accuracy\n",
    "train_acc = np.sum(train_pred_label == train_true_label) / len(train_true_label)\n",
    "test_acc = np.sum(test_pred_label == test_true_label) / len(test_true_label)\n",
    "print('Training Accuract:', str(np.round(train_acc, 5)))\n",
    "print('Testing Accuract:', str(np.round(test_acc, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

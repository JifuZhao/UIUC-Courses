{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5e77c665676065fe1f5532f0b897b37c",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This notebook will be collected automatically at **6pm on Monday** from `/home/data_scientist/assignments/Week14` directory on the course JupyterHub server. If you work on this assignment on the course Jupyterhub server, just make sure that you save your work and instructors will pull your notebooks automatically after the deadline. If you work on this assignment locally, the only way to submit assignments is via Jupyterhub, and you have to place the notebook file in the correct directory with the correct file name before the deadline.\n",
    "\n",
    "1. Make sure everything runs as expected. First, restart the kernel (in the menubar, select `Kernel` → `Restart`) and then run all cells (in the menubar, select `Cell` → `Run All`).\n",
    "2. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed by the autograder.\n",
    "3. Do not change the file path or the file name of this notebook.\n",
    "4. Make sure that you save your work (in the menubar, select `File` → `Save and CheckPoint`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3a2a920fc0bb924e383405bdb90850eb",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem 14.3. Spark MLlib\n",
    "\n",
    "In this problem, we will use Spark MLlib to perform a logistic regression on the flight data to determine whether a flight would be delayed or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "438b27313b52bf10cadbee379341c894",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "\n",
    "from nose.tools import (\n",
    "    assert_equal, assert_is_instance,\n",
    "    assert_true, assert_almost_equal\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e1f5217e4ddd480f583703de23206888",
     "grade": false,
     "grade_id": "markdown_1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We run Spark in [local mode](http://spark.apache.org/docs/latest/programming-guide.html#local-vs-cluster-modes) from within our Docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b89f31e49fc9c87324f97bb9c08b5683",
     "grade": false,
     "grade_id": "sparkcontext",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sc = SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3d8c9a4b8598a18cd7c5992ae8bc1c5d",
     "grade": false,
     "grade_id": "markdown_2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We use code similar to the RDD code from the [Introduction to Spark](https://github.com/UI-DataScience/info490-sp16/blob/master/Week14/notebooks/intro2spark.ipynb) notebook to import two columns: `ArrDealy` and `DepDelay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "53291741de7d9b04ea7356d3572457db",
     "grade": false,
     "grade_id": "text_file",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "text_file = sc.textFile('/home/data_scientist/data/2001.csv')\n",
    "\n",
    "data = (\n",
    "    text_file\n",
    "    .map(lambda line: line.split(\",\"))\n",
    "    # 14: ArrDelay, 15: DepDelay\n",
    "    .map(lambda p: (p[14], p[15]))\n",
    "    .filter(lambda line: 'ArrDelay' not in line)\n",
    "    .filter(lambda line: 'NA' not in line)\n",
    "    .map(lambda p: (int(p[0]), int(p[1])))\n",
    "    )\n",
    "\n",
    "len_data = data.count()\n",
    "assert_equal(len_data, 5723673)\n",
    "assert_equal(\n",
    "    data.take(5),\n",
    "    [(-3, -4),\n",
    "     (4, -5),\n",
    "     (23, 11),\n",
    "     (10, -3),\n",
    "     (20, 0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "69ac87bc60bdd40abdf916c40ccb9217",
     "grade": false,
     "grade_id": "markdown_3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "- Write a function that transforms the `ArrDelay` column into binary labels that indicate whether a flight arrived late or not. We define a flight to be delayed if its arrival delay is 15 minutes or more, the same definition used by the FAA (source: [Wikipedia](https://en.wikipedia.org/wiki/Flight_cancellation_and_delay)).\n",
    "\n",
    "- The `DepDelay` column should remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4ae28a25942c8909a3b590181adff7a9",
     "grade": false,
     "grade_id": "to_binary_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def to_binary(rdd):\n",
    "    '''\n",
    "    Transforms the \"ArrDelay\" column into binary labels\n",
    "    that indicate whether a flight arrived late or not.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rdd: A pyspark.rdd.RDD instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pyspark.rdd.PipelinedRDD instance.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9909571aa4cb46d07e1aa514f62347af",
     "grade": false,
     "grade_id": "to_binary_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "binary_labels = to_binary(data)\n",
    "print(binary_labels.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "7c5a65a6c6e710cc654d1ca2ed3300aa",
     "grade": true,
     "grade_id": "to_binary_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(binary_labels, pyspark.rdd.PipelinedRDD)\n",
    "assert_equal(binary_labels.count(), len_data)\n",
    "assert_equal(\n",
    "    binary_labels.take(5),\n",
    "    [(0, -4),\n",
    "     (0, -5),\n",
    "     (1, 11),\n",
    "     (0, -3),\n",
    "     (1, 0)])\n",
    "assert_equal(to_binary(sc.parallelize([(15.0, 490.0)])).first(), (1, 490.0))\n",
    "assert_equal(to_binary(sc.parallelize([(14.9, 490.0)])).first(), (0, 490.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4f6a9088c78775de971b89a73b870c7e",
     "grade": false,
     "grade_id": "markdown_4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Our data must be in a Spark specific data structure called [LabeledPoint](https://spark.apache.org/docs/latest/mllib-data-types.html#labeled-point). So\n",
    "\n",
    "- Write a function that turns a Spark sequence of tuples into a sequence containing LabeledPoint values for each row. The arrival delay should be the label, and the departure delay should be the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "407bd73ec6a1c03d23d91a65c0d0b6a6",
     "grade": false,
     "grade_id": "to_labeled_point_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def to_labeled_point(rdd):\n",
    "    '''\n",
    "    Transforms a Spark sequence of tuples into\n",
    "    a sequence containing LabeledPoint values for each row.\n",
    "    \n",
    "    The arrival delay is the label.\n",
    "    The departure delay is the feature.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rdd: A pyspark.rdd.RDD instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pyspark.rdd.PipelinedRDD instance.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0ac7b52588396909049e7aff68aa7f1c",
     "grade": false,
     "grade_id": "to_labeled_point_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "labeled_point = to_labeled_point(binary_labels)\n",
    "print(labeled_point.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0ba0ead8caf49205c7e5652dbe2fc003",
     "grade": true,
     "grade_id": "to_labeled_point_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(labeled_point, pyspark.rdd.PipelinedRDD)\n",
    "assert_equal(labeled_point.count(), len_data)\n",
    "assert_true(all(isinstance(p, LabeledPoint) for p in labeled_point.take(5)))\n",
    "assert_equal([p.label for p in labeled_point.take(5)], [0.0, 0.0, 1.0, 0.0, 1.0])\n",
    "assert_true(all(\n",
    "    isinstance(p.features, pyspark.mllib.linalg.DenseVector)\n",
    "    for p\n",
    "    in labeled_point.take(5)\n",
    "    ))\n",
    "assert_equal(\n",
    "    [p.label for p in labeled_point.take(5)],\n",
    "    [0.0,\n",
    "     0.0,\n",
    "     1.0,\n",
    "     0.0,\n",
    "     1.0]\n",
    "    )\n",
    "assert_equal(\n",
    "    [p.features.values.tolist() for p in labeled_point.take(5)],\n",
    "    [[-4.0],\n",
    "     [-5.0],\n",
    "     [11.0],\n",
    "     [-3.0],\n",
    "     [0.0]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5352b57b04f6c0f751ee9039098f707c",
     "grade": false,
     "grade_id": "markdown_5",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "- Use [LogisticRegressionWithSGD](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.classification.LogisticRegressionWithSGD) to train a [logistic regression](http://spark.apache.org/docs/latest/mllib-linear-methods.html#logistic-regression) model. \n",
    "- Use 10 iterations. Use default parameters for all other parameters other than `iterations`.\n",
    "- Use the resulting logistic regression model to make predictions on the entire data, and return an RDD of (label, prediction) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "19693dcb87436d0cb28822667bac09b5",
     "grade": false,
     "grade_id": "fit_and_predict_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_and_predict(rdd):\n",
    "    '''\n",
    "    Fits a logistic regression model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rdd: A pyspark.rdd.RDD instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    An RDD of (label, prediction) pairs.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "feefcd17f0a85b8556d765a5556a6749",
     "grade": false,
     "grade_id": "fit_and_predict_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "labels_and_preds = fit_and_predict(labeled_point)\n",
    "print(labels_and_preds.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "3393f7543aff076c6157b8389ffa8a52",
     "grade": true,
     "grade_id": "fit_and_predict_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(labels_and_preds, pyspark.rdd.PipelinedRDD)\n",
    "assert_equal(labels_and_preds.count(), len_data)\n",
    "assert_equal(\n",
    "    labels_and_preds.take(5),\n",
    "    [(0.0, 0.0),\n",
    "     (0.0, 0.0),\n",
    "     (1.0, 1.0),\n",
    "     (0.0, 0.0),\n",
    "     (1.0, 0.0)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b668a1cada1a572cce9a8fcb63912d9e",
     "grade": false,
     "grade_id": "markdown_6",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "- Write a function that computes the accuracy from a Spark sequence of (label, prediction) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "cf32b427eb7b08edc8e24f0bb2163246",
     "grade": false,
     "grade_id": "get_accuracy_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(rdd):\n",
    "    '''\n",
    "    Computes accuracy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rdd: A pyspark.rdd.RDD instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A float.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ca760ae468805a16e6c3cef0aa0a6d32",
     "grade": false,
     "grade_id": "get_accuracy_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "accuracy = get_accuracy(labels_and_preds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "bc663ee524bf0405b49a4d729f63c0a4",
     "grade": true,
     "grade_id": "get_accuracy_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(accuracy, float)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(0.0, 1.0), (1.0, 0.0)])), 0.0)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(0.0, 1.0), (0.0, 0.0)])), 0.5)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(0.0, 0.0), (1.0, 0.0)])), 0.5)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(0.0, 0.0), (1.0, 1.0)])), 1.0)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(1.0, 0.0), (0.0, 1.0), (0.0, 1.0)])), 0.0)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(1.0, 1.0), (0.0, 1.0), (0.0, 1.0)])), 1/3)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(1.0, 1.0), (0.0, 0.0), (0.0, 1.0)])), 2/3)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(1.0, 1.0), (0.0, 0.0), (1.0, 1.0)])), 1.0)\n",
    "assert_almost_equal(accuracy, 0.7503940214613938)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b25a11d968652d1c4fc572ac6c52138a",
     "grade": false,
     "grade_id": "markdown_7",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "We must stop the SparkContext in order to release the spark resources before existing this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "ec8c059e7ca934a0d1fb3342fc042680",
     "grade": false,
     "grade_id": "sc_stop",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

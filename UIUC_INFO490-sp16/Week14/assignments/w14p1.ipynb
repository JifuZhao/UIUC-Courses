{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5e77c665676065fe1f5532f0b897b37c",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This notebook will be collected automatically at **6pm on Monday** from `/home/data_scientist/assignments/Week14` directory on the course JupyterHub server. If you work on this assignment on the course Jupyterhub server, just make sure that you save your work and instructors will pull your notebooks automatically after the deadline. If you work on this assignment locally, the only way to submit assignments is via Jupyterhub, and you have to place the notebook file in the correct directory with the correct file name before the deadline.\n",
    "\n",
    "1. Make sure everything runs as expected. First, restart the kernel (in the menubar, select `Kernel` → `Restart`) and then run all cells (in the menubar, select `Cell` → `Run All`).\n",
    "2. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed by the autograder.\n",
    "3. Do not change the file path or the file name of this notebook.\n",
    "4. Make sure that you save your work (in the menubar, select `File` → `Save and CheckPoint`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "61e78c4bf3fb68605fb28cd743a75b0d",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem 14.1. Spark\n",
    "\n",
    "In this problem, we will perform basic data processing tasks within Spark using the concept of Resilient Distributed Datasets (RDDs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "2f7ff2b12ef6fc2b3bb9285e85b15e97",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e1f5217e4ddd480f583703de23206888",
     "grade": false,
     "grade_id": "markdown_1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We run Spark in [local mode](http://spark.apache.org/docs/latest/programming-guide.html#local-vs-cluster-modes) from within our Docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b89f31e49fc9c87324f97bb9c08b5683",
     "grade": false,
     "grade_id": "sparkcontext",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sc = SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "13de84cd2f235aefe381b8cd3d1e6253",
     "grade": false,
     "grade_id": "markdown_2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We create a new RDD by reading in the data as a text file. We use the ratings data from [MovieLens](http://grouplens.org/datasets/movielens/latest/). See [Week 6 Lesson 1](https://github.com/UI-DataScience/info490-sp16/blob/master/Week6/notebooks/intro2rs.ipynb) for more information on this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "1ee45b253c99ade7600d888249eddf88",
     "grade": false,
     "grade_id": "text_file",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "text_file = sc.textFile('/home/data_scientist/data/ml-latest-small/ratings.csv')\n",
    "\n",
    "assert_is_instance(text_file, pyspark.rdd.RDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ad7a3557854b35bc567150aec81cdff8",
     "grade": false,
     "grade_id": "markdown_3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "- Write a function that creates a new RDD by transforming `text_file` into an RDD with columns of appropriate data types.\n",
    "- The function accepts a `pyspark.rdd.RDD` instance (e.g., `text_file` in the above code cell) and returns another RDD instance, `pyspark.rdd.PipelinedRDD`.\n",
    "- `ratings.csv` contains a header row. Use the `head` command or otherwise to inspect the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "afb3d200ec8bc38a1f0dacf35979ee6a",
     "grade": false,
     "grade_id": "read_ratings_csv_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def read_ratings_csv(rdd):\n",
    "    '''\n",
    "    Creates an RDD by transforming `ratings.csv`\n",
    "    into columns with appropriate data types.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rdd: A pyspark.rdd.RDD instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pyspark.rdd.PipelinedRDD instance.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6ec0d0d794f477bc768b96a7be2645cd",
     "grade": false,
     "grade_id": "read_ratings_csv_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ratings = read_ratings_csv(text_file)\n",
    "print(ratings.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "52092854451a354173e3f5c60d04104a",
     "grade": true,
     "grade_id": "read_ratings_csv_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(ratings, pyspark.rdd.PipelinedRDD)\n",
    "assert_equal(ratings.count(), 105339)\n",
    "assert_equal(len(ratings.first()), 4)\n",
    "assert_equal(\n",
    "    ratings.take(5),\n",
    "    [(1, 16, 4.0, 1217897793),\n",
    "     (1, 24, 1.5, 1217895807),\n",
    "     (1, 32, 4.0, 1217896246),\n",
    "     (1, 47, 4.0, 1217896556),\n",
    "     (1, 50, 4.0, 1217896523)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "3a7468c06abc88823d675e98f71c91d5",
     "grade": false,
     "grade_id": "markdown_4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "For simplicity, we might want to restrict our analysis to only favorable ratings, which, since the movies are rated on a five-star system, we take to mean ratings greater than three. So\n",
    "\n",
    "- Write a function that selects rows whose rating is greater than 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "ab89b5376d0a4d68315b36f8aaf352cc",
     "grade": false,
     "grade_id": "filter_favorable_ratings_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def filter_favorable_ratings(rdd):\n",
    "    '''\n",
    "    Selects rows whose rating is greater than 3.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rdd: A pyspark.rdd.RDD instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pyspark.rdd.PipelinedRDD instance.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7d616abf698d28e0494df5826c368cdc",
     "grade": false,
     "grade_id": "filter_favorable_ratings_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "favorable = filter_favorable_ratings(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "bcdba50617368fe1f68488ea55fa3810",
     "grade": true,
     "grade_id": "filter_favorable_ratings_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(favorable, pyspark.rdd.PipelinedRDD)\n",
    "assert_equal(favorable.count(), 64160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ca7d34c82f0965c26794acc3f87c3311",
     "grade": false,
     "grade_id": "markdown_5",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We might also want to select only those movies that have been reviewed by multiple people.\n",
    "\n",
    "- Write a function that returns the number of reviews for a given movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "79813dd97812e6e8872b9d30a223da02",
     "grade": false,
     "grade_id": "find_n_reviews_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def find_n_reviews(rdd, movie_id):\n",
    "    '''\n",
    "    Finds the number of reviews for a movie.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rdd: A pyspark.rdd.RDD instance.\n",
    "    movie_id: An int.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pyspark.rdd.PipelinedRDD instance.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return n_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "285ee7425162cc4c868edad6edcb1715",
     "grade": false,
     "grade_id": "find_n_reviews_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "n_toy_story = find_n_reviews(favorable, 1)\n",
    "print(n_toy_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ca096cbf7a66c903de652fb9aec7fbc3",
     "grade": true,
     "grade_id": "find_n_review_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(n_toy_story, int)\n",
    "\n",
    "test = [find_n_reviews(favorable, n) for n in range(5)]\n",
    "assert_equal(test, [0, 172, 44, 18, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1f1cbc95d6cc8f4d200a9e134233cb69",
     "grade": false,
     "grade_id": "markdown_6",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "We must stop the SparkContext in order to release the spark resources before existing this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "ec8c059e7ca934a0d1fb3342fc042680",
     "grade": false,
     "grade_id": "sc_stop",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

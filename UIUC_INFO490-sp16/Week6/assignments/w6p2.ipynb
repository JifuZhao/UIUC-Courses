{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1b4d575245740d11397e7543e8d597d8",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This notebook will be collected automatically at **6pm on Monday** from `/home/data_scientist/assignments/Week6` directory on the course JupyterHub server. If you work on this assignment on the course Jupyterhub server, just make sure that you save your work and instructors will pull your notebooks automatically after the deadline. If you work on this assignment locally, the only way to submit assignments is via Jupyterhub, and you have to place the notebook file in the correct directory with the correct file name before the deadline.\n",
    "\n",
    "1. Make sure everything runs as expected. First, restart the kernel (in the menubar, select `Kernel` → `Restart`) and then run all cells (in the menubar, select `Cell` → `Run All`).\n",
    "2. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed by the autograder.\n",
    "3. Do not change the file path or the file name of this notebook.\n",
    "4. Make sure that you save your work (in the menubar, select `File` → `Save and CheckPoint`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6.2. Practical Concepts.\n",
    "\n",
    "In this problem, we explore a number of practical concepts that can be very important in real-world machine learning applications. These concepts include\n",
    "\n",
    "- Feature Scaling\n",
    "- Feature Selection\n",
    "- Pipelining\n",
    "- Cross Validation\n",
    "- Grid Search\n",
    "- Validation/Learning Curves\n",
    "\n",
    "We have already encounted some of these concepts in the previous assignments. For example, we explored cross validation in [Problem 4.2]( https://github.com/UI-DataScience/info490-sp16/blob/master/Week4/assignments/w4p2.ipynb) and feature scaling in [Problem 5.1](https://github.com/UI-DataScience/info490-sp16-private/blob/master/Week5/assignment/w5p1.ipynb), so we won't repeat those concepts in this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "02ad03d3204451cebb33e3cc3f48e911",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_regression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.learning_curve import validation_curve\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_instance, assert_is_not\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal, assert_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the descriptions of the columns [here](http://stat-computing.org/dataexpo/2009/the-data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "71d33dd5d1e8abe950e90eea7f4cb129",
     "grade": false,
     "grade_id": "read_csv",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '/home/data_scientist/data/2001.csv',\n",
    "    encoding='latin-1',\n",
    "    usecols=(1, 2, 3, 5, 7, 13, 15, 16, 18)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we use only 1% percent of flights that departed from ORD. We also convert the `DepDelay` variables to a binary indicator, which we try to predict from the remaining attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ef908c60902475ac288cae735b7e395b",
     "grade": false,
     "grade_id": "local",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "local = df[df['Origin'] == 'ORD'].drop('Origin', axis=1) # we don't need the Origin column anymore.\n",
    "local = local.dropna().reset_index(drop=True)\n",
    "\n",
    "# 1 if a flight was delayed, 0 if not.\n",
    "y = pd.DataFrame((local['DepDelay'] > 0).astype(np.int), columns=['DepDelay'])\n",
    "local = local.drop('DepDelay', axis=1)\n",
    "\n",
    "np.random.seed(0)\n",
    "idx = np.random.choice(len(local), len(local) / 100)\n",
    "X = local.loc[idx, :]\n",
    "y = y.loc[idx, :]\n",
    "\n",
    "del df # we don't need this big data frame anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e1d6c1ae2f5059ccba9e3adc5d21791f",
     "grade": false,
     "grade_id": "scale",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(preprocessing.StandardScaler().fit_transform(X), columns=X.columns)\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "- Use [Recursive Feature Elimination](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html) to determine the most important features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "54cc73c603dbb81e6b38e53a66d42f12",
     "grade": false,
     "grade_id": "select_features_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def select_features(X, y, random_state, kernel='linear', C=1.0, num_attributes=3):\n",
    "    '''\n",
    "    Uses Support Vector Classifier as the estimator to rank features\n",
    "    with Recursive Feature Eliminatin.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A pandas.DataFrame. Attributes.\n",
    "    y: A pandas.DataFrame. Labels.\n",
    "    random_state: A RandomState instance. Used in SVC().\n",
    "    kernel: A string. Used in SVC(). Default: \"linear\".\n",
    "    C: A float. Used in SVC(). Default: 1.0.\n",
    "    num_attributes: An int. The number of features to select in RFE. Default: 3.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 3-tuple of (RFE, np.ndarray, np.ndarray)\n",
    "    model: An RFE instance.\n",
    "    columns: Selected features.\n",
    "    ranking: The feature ranking. Selected features are assigned rank 1.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "            \n",
    "    return model, columns, ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "f28cf2122a758f1b22134ab2f3b769e4",
     "grade": false,
     "grade_id": "select_features_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "rfe, rfe_columns, rfe_ranking = select_features(X, y, check_random_state(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "71d1694bb51df8426d88e8b4fc05a182",
     "grade": true,
     "grade_id": "select_features_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(rfe, RFE)\n",
    "assert_is_instance(rfe_ranking, np.ndarray)\n",
    "\n",
    "assert_is_instance(rfe.estimator, svm.SVC)\n",
    "assert_equal(rfe.estimator.kernel, 'linear')\n",
    "assert_equal(rfe.estimator.C, 1)\n",
    "assert_equal(rfe.n_features_, 3)\n",
    "\n",
    "assert_array_equal(rfe_columns, ['CRSDepTime', 'AirTime', 'Distance'])\n",
    "assert_array_equal(rfe_ranking, [3, 5, 2, 1, 4, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "- Construct a pipeline to employ to select the k best features from a data set along with an SVC classification.\n",
    "\n",
    "Select top 3 features, and use [ANOVA F-value](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif) for the score function. Name the pipe elements \"anova\" and \"svc\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "525734face59ed2603c67fa7c09faa6a",
     "grade": false,
     "grade_id": "pipeline_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def pipeline_anova_svm(X, y, random_state, k=3, kernel='linear'):\n",
    "    '''\n",
    "    Selects top k=3 features with a pipeline that uses ANOVA F-value\n",
    "    and a Support Vector Classifier.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A pandas.DataFrame. Attributes.\n",
    "    y: A pandas.DataFrame. Labels.\n",
    "    random_state: A RandomState instance. Used in SVC().\n",
    "    k: An int. The number of features to select. Default: 3\n",
    "    kernel: A string. Used by SVC(). Default: 'linear'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 2-tuple of (Pipeline, np.ndarray)\n",
    "    model: An ANOVA SVM-C pipeline.\n",
    "    predictions: Classifications predicted by the pipeline.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a731556be67d7f2d45d64e60e895cb61",
     "grade": false,
     "grade_id": "pipeline_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "anova_svm, y_pred = pipeline_anova_svm(X, y, random_state=check_random_state(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "35c25d93623b030d940c1d7a93ebbe97",
     "grade": true,
     "grade_id": "pipeline_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(anova_svm, Pipeline)\n",
    "assert_equal(anova_svm.steps[0][0], 'anova')\n",
    "assert_equal(anova_svm.steps[1][0], 'svc')\n",
    "assert_equal(anova_svm.get_params()['anova__k'], 3)\n",
    "assert_equal(anova_svm.get_params()['svc__kernel'], 'linear')\n",
    "assert_equal(anova_svm.get_params()['svc__C'], 1.0)\n",
    "\n",
    "assert_is_instance(y_pred, np.ndarray)\n",
    "assert_equal(len(y_pred), len(y))\n",
    "assert_array_equal(y_pred[:10], [0, 1, 0, 1, 1, 1, 0, 0, 0, 1])\n",
    "assert_array_equal(y_pred[-10:], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "- Use a [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) object to compute the best value for the C parameter when running the SVC algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "f8fb1ccc736dc9d081c838517f137df2",
     "grade": false,
     "grade_id": "gridsearch_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def grid_search_c(X, y, split_rs, svc_rs, c_vals, test_size=0.2, kernel='linear'):\n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A pandas.DataFrame. Attributes.\n",
    "    y: A pandas.DataFrame. Labels.\n",
    "    split_rs: A RandomState instance. Used in train_test_split().\n",
    "    svc_rs: A RandomState instance. Used in SVC().\n",
    "    c_vals: A np.array. A list of parameter settings to try as vlues.\n",
    "    test_size: A float. Used in train_test_split(). Default: 0.2\n",
    "    kernel: A string. Used by SVC(). Default: 'linear'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A 3-tuple of (GridSearchCV, float, float)\n",
    "    model: A GridSearchCV instance.\n",
    "    best_C: The value of C that gave the highest score.\n",
    "    best_cv_score: Score of best_C on the hold out data.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return model, best_C, best_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9cfd274eeb3d9880b3fa5f8c813b19e5",
     "grade": false,
     "grade_id": "gridsearch_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "clf, best_C, best_cv_score = grid_search_c(\n",
    "    X, y,\n",
    "    split_rs=check_random_state(0),\n",
    "    svc_rs=check_random_state(0),\n",
    "    c_vals=np.logspace(-5, 2, 20)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ecf83872f1b2386b3e8511eb9aafe701",
     "grade": true,
     "grade_id": "gridsearch_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(clf, GridSearchCV)\n",
    "assert_is_instance(clf.estimator, svm.SVC)\n",
    "assert_equal(clf.estimator.C, 1.0)\n",
    "assert_equal(clf.estimator.kernel, 'linear')\n",
    "assert_array_equal(clf.param_grid['C'], np.logspace(-5, 2, 20))\n",
    "\n",
    "assert_almost_equal(best_C, 0.0088586679041008226)\n",
    "assert_almost_equal(best_cv_score, 0.57248348231636226)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Curves\n",
    "\n",
    "- Compute and display the validation curve for SVM-C.\n",
    "\n",
    "Vary the $\\gamma$ parameter for the values in `param_range`. Since `param_range` is on a log scale, the x-axis of your plot should also be on a log scale. Use a 5-fold cross validation. Plot the mean accuracy score for the training set first, and then plot the mean accuracy score for the cross validation data.\n",
    "\n",
    "![](https://raw.githubusercontent.com/UI-DataScience/info490-sp16/master/Week6/assignments/images/valid_curve.png)\n",
    "\n",
    "Note the computation of the data for these curves can take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6893df0f174374fe9b6ad6fd298f2db2",
     "grade": false,
     "grade_id": "validation_curve_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_validation_curve(X, y, param_range):\n",
    "    '''\n",
    "    Computes and displays the validation curve for SVC.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A pandas.DataFrame. Attributes.\n",
    "    y: A pandas.DataFrame. Labels.\n",
    "    param_range: The values of the parameter that will be evaluated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A maplotlib.Axes instance.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "67576483c7a08f40951b88ce41e805be",
     "grade": false,
     "grade_id": "validation_curve_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "param_range = np.logspace(-5, 2, 20)\n",
    "ax_vl = plot_validation_curve(X, y, param_range=param_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6124fc04d639709cc0f390f933b7bb64",
     "grade": true,
     "grade_id": "validation_curve_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(ax_vl, mpl.axes.Axes)\n",
    "\n",
    "x_train, y_train = ax_vl.lines[0].get_xydata().T\n",
    "assert_array_almost_equal(x_train, param_range)\n",
    "assert_array_almost_equal(y_train,\n",
    "    [0.54243086, 0.54243086, 0.54243086, 0.54243086, 0.54243086,\n",
    "     0.54243086, 0.56605497, 0.57600251, 0.58361821, 0.59068994,\n",
    "     0.60133712, 0.61648984, 0.64842962, 0.71518516, 0.83804752,\n",
    "     0.96510729, 0.99417159, 0.9976687 , 0.99914521, 0.99945604]\n",
    "    )\n",
    "\n",
    "x_valid, y_valid = ax_vl.lines[1].get_xydata().T\n",
    "assert_array_almost_equal(x_valid, param_range)\n",
    "assert_array_almost_equal(y_valid,\n",
    "    [0.54243115, 0.54243115, 0.54243115, 0.54243115, 0.54243115,\n",
    "     0.54243115, 0.55796924, 0.57630816, 0.57600243, 0.57507124,\n",
    "     0.58160071, 0.58221941, 0.57444867, 0.56636448, 0.55579968,\n",
    "     0.55548719, 0.55113646, 0.54740541, 0.54709292, 0.54802604]\n",
    "    )\n",
    "\n",
    "assert_is_not(len(ax_vl.title.get_text()), 0,\n",
    "    msg=\"Your plot doesn't have a title.\")\n",
    "assert_is_not(ax_vl.xaxis.get_label_text(), '',\n",
    "    msg=\"Change the x-axis label to something more descriptive.\")\n",
    "assert_is_not(ax_vl.yaxis.get_label_text(), '',\n",
    "    msg=\"Change the y-axis label to something more descriptive.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
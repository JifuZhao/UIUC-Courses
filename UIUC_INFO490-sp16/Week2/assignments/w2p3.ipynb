{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "delete_for_peer_review": "true",
    "nbgrader": {
     "checksum": "dba7d6748d9eb21d0f527ced81b30810",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This notebook will be collected automatically at **6pm on Monday** from `/home/data_scientist/assignment/Week2` directory on the course JupyterHub server. If you work on this assignment on the course Jupyterhub server, just make sure that you save your work and instructors will pull your notebooks automatically after the deadline. If you work on this assignment locally, the only way to submit assignments is via Jupyterhub, and you have to place the notebook file in the correct directory with the correct file name before the deadline.\n",
    "\n",
    "1. Make sure everything runs as expected. First, restart the kernel (in the menubar, select `Kernel` → `Restart`) and then run all cells (in the menubar, select `Cell` → `Run All`).\n",
    "2. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed by the autograder.\n",
    "3. Do not change the file path or the file name of this notebook.\n",
    "4. Make sure that you save your work (in the menubar, select `File` → `Save and CheckPoint`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.3. Logistic Regression\n",
    "\n",
    "In this problem, we will fit a logistic regression model on day of the week and air carriers to predict whether a flight is delayed or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4b1514db4e9a50fb1bf848b77b7d0e8c",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "    \n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from nose.tools import assert_equal\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal\n",
    "from pandas.util.testing import assert_frame_equal\n",
    "\n",
    "sns.set(style=\"white\", font_scale=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the columns `DayOfWeek` and `UniqueCarrier` as attributes and `DepDelay` as the target prediction. For simplicity, we will only use the flights that departed from O'Hare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b8e26d3163c955e5a2514faa95fd07f3",
     "grade": false,
     "grade_id": "read_csv",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "filename = '/home/data_scientist/data/2001.csv'\n",
    "\n",
    "usecols = (3, 8, 15, 17)\n",
    "columns = ['DayOfWeek', 'UniqueCarrier', 'DepDelay', 'Origin']\n",
    "\n",
    "all_data = pd.read_csv(filename, header=0, na_values=['NA'], usecols=usecols, names=columns).dropna()\n",
    "\n",
    "local = all_data.loc[all_data['Origin'] == 'ORD'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print print out the first few columns.\n",
    "\n",
    "```python\n",
    ">>> print(local.head())\n",
    "```\n",
    "\n",
    "```\n",
    "      DayOfWeek UniqueCarrier  DepDelay Origin\n",
    "1855          2            US        -1    ORD\n",
    "1856          3            US        -4    ORD\n",
    "1857          4            US        -3    ORD\n",
    "1858          5            US        -3    ORD\n",
    "1859          6            US        -4    ORD\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "bbff04c484acca0872ce134a0479d5a6",
     "grade": false,
     "grade_id": "print_local_head",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(local.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will using logistic regression on the `DayOfWeek` and `UniqueCarrier` columns to predict whether a flight is delayed or not. However, logistic regression is for predicting **binary** outcomes and `DepDelay` is not binary. So our first task will be to convert this column into binary numbers.\n",
    "\n",
    "## Convert DepDelay to binary\n",
    "\n",
    "- Write a function named `convert_to_binary()` that converts a specific column of a DataFrame into 0's or 1's using the `cutoff` parameter. See the function doctsring for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "8e7d578415ec7b37bd7bc479d9c7823e",
     "grade": false,
     "grade_id": "convert_to_binary_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_binary(df, column, cutoff):\n",
    "    '''\n",
    "    Adds a new column in Pandas.DataFrame \"df\".\n",
    "    \n",
    "    The returned DataFrame as one more column than \"df\".\n",
    "    The name of this column is in the form \"column_binary\".\n",
    "    For example, if \"column\" is \"DepDelay\", the name of the extra column\n",
    "    in the returned DataFrame is \"DepDelay_binary\".\n",
    "    \n",
    "    We assume that df[column] contains only ints or floats.\n",
    "    If df[column] < cutoff, df[column_binary] is 0.\n",
    "    If df[column] >= cutoff, df[column_binary] is 1.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: A Pandas.DataFrame.\n",
    "    column: A string.\n",
    "    cutoff: An int.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A Pandas.DataFrame.\n",
    "    '''\n",
    "    #####################\n",
    "    # YOUR CODE HERE\n",
    "    #####################\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a flight to be late if its departure delay is more than or equal to 5 minutes, and on-time if its departure delay is less than 5 minutes.\n",
    "\n",
    "```python\n",
    ">>> local = convert_to_binary(local, 'DepDelay', 5)\n",
    ">>> print(local.tail(10))\n",
    "```\n",
    "\n",
    "```\n",
    "         DayOfWeek UniqueCarrier  DepDelay Origin  DepDelay_binary\n",
    "5960735          6            DL         4    ORD                0\n",
    "5960736          7            DL         7    ORD                1\n",
    "5960737          1            DL        -2    ORD                0\n",
    "5960738          2            DL        -3    ORD                0\n",
    "5960739          3            DL         0    ORD                0\n",
    "5960740          4            DL        58    ORD                1\n",
    "5960741          5            DL         1    ORD                0\n",
    "5960742          6            DL         0    ORD                0\n",
    "5960743          7            DL        -8    ORD                0\n",
    "5960744          1            DL        -3    ORD                0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "47be0bfab219d96faf8c7c929578d2c3",
     "grade": false,
     "grade_id": "print_local_tail",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "local = convert_to_binary(local, 'DepDelay', 5)\n",
    "print(local.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructors will use some simple unit tests to see if your function works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "760775997867e52af7488980d1a56dc8",
     "grade": true,
     "grade_id": "convert_to_binary_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame({\n",
    "    'a': list(range(-5, 5)),\n",
    "    'b': list(range(10))\n",
    "    })\n",
    "\n",
    "test1 = convert_to_binary(df0, 'a', 0)\n",
    "answer1 = df0.join(pd.DataFrame({'a_binary': [0] * 5 + [1] * 5}))\n",
    "assert_frame_equal(test1, answer1)\n",
    "\n",
    "test2 = convert_to_binary(df0, 'b', 4)\n",
    "answer2 = df0.join(pd.DataFrame({'b_binary': [0] * 4 + [1] * 6}))\n",
    "assert_frame_equal(test2, answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert categorical variables to dummy indicator variables\n",
    "\n",
    "`DayOfWeek` and `UniqueCarrier` are categorical variables, while we need binary indicator variables to perform logistic regression.\n",
    "\n",
    "- Use [pandas.get_dummies()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) to write a function named `add_dummy()` that transforms categorical variables into binary indicator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "9fc88c2bf62d7927c4a6d5801fb3391a",
     "grade": false,
     "grade_id": "add_dummy_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def add_dummy(df, add_columns, keep_columns):\n",
    "    '''\n",
    "    Transforms categorical variables of add_columns into binary indicator variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: A pandas.DataFrame\n",
    "    add_columns: A list of strings\n",
    "    keep_columns: A list of strings\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pandas.DataFrame\n",
    "    '''\n",
    "    #####################\n",
    "    # YOUR CODE HERE\n",
    "    #####################\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should have only binary indicators in all columns.\n",
    "\n",
    "```python\n",
    ">>> data = add_dummy(local, add_columns=['DayOfWeek', 'UniqueCarrier'], keep_columns=['DepDelay_binary'])\n",
    ">>> print(data.head())\n",
    "```\n",
    "\n",
    "```\n",
    "      DepDelay_binary  DayOfWeek_1  DayOfWeek_2  DayOfWeek_3  DayOfWeek_4  \\\n",
    "1855                0            0            1            0            0   \n",
    "1856                0            0            0            1            0   \n",
    "1857                0            0            0            0            1   \n",
    "1858                0            0            0            0            0   \n",
    "1859                0            0            0            0            0   \n",
    "\n",
    "      DayOfWeek_5  DayOfWeek_6  DayOfWeek_7  UniqueCarrier_AA  \\\n",
    "1855            0            0            0                 0   \n",
    "1856            0            0            0                 0   \n",
    "1857            0            0            0                 0   \n",
    "1858            1            0            0                 0   \n",
    "1859            0            1            0                 0   \n",
    "\n",
    "      UniqueCarrier_AS  UniqueCarrier_CO  UniqueCarrier_DL  UniqueCarrier_HP  \\\n",
    "1855                 0                 0                 0                 0   \n",
    "1856                 0                 0                 0                 0   \n",
    "1857                 0                 0                 0                 0   \n",
    "1858                 0                 0                 0                 0   \n",
    "1859                 0                 0                 0                 0   \n",
    "\n",
    "      UniqueCarrier_MQ  UniqueCarrier_NW  UniqueCarrier_TW  UniqueCarrier_UA  \\\n",
    "1855                 0                 0                 0                 0   \n",
    "1856                 0                 0                 0                 0   \n",
    "1857                 0                 0                 0                 0   \n",
    "1858                 0                 0                 0                 0   \n",
    "1859                 0                 0                 0                 0   \n",
    "\n",
    "      UniqueCarrier_US  \n",
    "1855                 1  \n",
    "1856                 1  \n",
    "1857                 1  \n",
    "1858                 1  \n",
    "1859                 1  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "37e470bf86ecf061da777380dc022c9b",
     "grade": false,
     "grade_id": "print_data_head",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data = add_dummy(local, add_columns=['DayOfWeek', 'UniqueCarrier'], keep_columns=['DepDelay_binary'])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6c814d096c9cac67eabb9b80b4888ecb",
     "grade": true,
     "grade_id": "add_dummy_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame({\n",
    "    'a': ['a'] * 3,\n",
    "    'b': [1] * 3,\n",
    "    'c': [c for c in 'abc'],\n",
    "    'd': list(range(3))\n",
    "    })\n",
    "\n",
    "test1 = add_dummy(df0, add_columns=['c'], keep_columns=['a'])\n",
    "answer1 = pd.DataFrame({\n",
    "    'a': ['a'] * 3,\n",
    "    'c_a': [1., 0., 0.], 'c_b': [0., 1., 0.], 'c_c': [0., 0., 1.]\n",
    "    })\n",
    "assert_frame_equal(test1, answer1)\n",
    "\n",
    "test2 = add_dummy(df0, add_columns=['c', 'd'], keep_columns=['b'])\n",
    "answer2 = pd.DataFrame({\n",
    "    'b': [1] * 3,\n",
    "    'c_a': [1., 0., 0.], 'c_b': [0., 1., 0.], 'c_c': [0., 0., 1.],\n",
    "    'd_0': [1., 0., 0.], 'd_1': [0., 1., 0.], 'd_2': [0., 0., 1.]\n",
    "    })\n",
    "\n",
    "assert_frame_equal(test2, answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add intercept\n",
    "\n",
    "The [Logit()](http://statsmodels.sourceforge.net/0.6.0/generated/statsmodels.discrete.discrete_model.Logit.html) function doesn't include intercept by default and we have to manualy add the intercept.\n",
    "\n",
    "- Write a function named `add_intercept()` that adds an extra column named `Intercept` with all 1's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "020019a54bb0515127c0c811e72da84a",
     "grade": false,
     "grade_id": "add_intercept_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def add_intercept(df):\n",
    "    '''\n",
    "    Appends to \"df\" an \"Intercept\" column whose values are all 1.0.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: A pandas.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pandas.DataFrame\n",
    "    '''\n",
    "    #####################\n",
    "    # YOUR CODE HERE\n",
    "    #####################\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if there is now an `Intercept` column.\n",
    "\n",
    "```python\n",
    ">>> data = add_intercept(data)\n",
    ">>> print(data['Intercept'].head())\n",
    "```\n",
    "\n",
    "```\n",
    "1855    1\n",
    "1856    1\n",
    "1857    1\n",
    "1858    1\n",
    "1859    1\n",
    "Name: Intercept, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9242f3c5c7e6caeee612a78ed6626ebb",
     "grade": false,
     "grade_id": "print_intercept_head",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data = add_intercept(data)\n",
    "print(data['Intercept'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "8ca9339dc6a3974390aba26003df531a",
     "grade": true,
     "grade_id": "add_intercept_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame({'a': [c for c in 'abcde']})\n",
    "\n",
    "test1 = add_intercept(df0)\n",
    "answer1 = df0.join(pd.DataFrame({'Intercept': [1.] * 5}))\n",
    "\n",
    "assert_frame_equal(test1, answer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: fit\\_logistic()\n",
    "\n",
    "- Use statsmodels [Logit()](http://blog.yhat.com/posts/logistic-regression-and-python.html) to fit a logistic regression model to the columns in `train_columns`. Use (non-regularized) maximum likelihood with the default parameters (no optional parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e7b1a483febcf0ff0f884d6b3673df10",
     "grade": false,
     "grade_id": "fit_logistic_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_logitistic(df, train_columns, test_column):\n",
    "    '''\n",
    "    Fits a logistic regression model on \"train_columns\" to predict \"test_column\".\n",
    "    \n",
    "    The function returns a tuple of (model ,result).\n",
    "    \"model\" is an instance of Logit(). \"result\" is the result of Logit.fit() method.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_columns: A list of strings\n",
    "    test_column: A string\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (model, result)\n",
    "    model: An object of type statsmodels.discrete.discrete_model.Logit\n",
    "    result: An object of type statsmodels.discrete.discrete_model.BinaryResultsWrapper\n",
    "    '''\n",
    "    #####################\n",
    "    # YOUR CODE HERE\n",
    "    #####################\n",
    "\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we exclue `DayOfWeek_1` and `UniqueCarrier_AA` from our fit to prevent [multicollinearity](https://en.wikipedia.org/wiki/Multicollinearity#Remedies_for_multicollinearity).\n",
    "\n",
    "```python\n",
    ">>> model, result = fit_logitistic(data, train_columns=train_columns, test_column='DepDelay_binary')\n",
    "```\n",
    "\n",
    "```\n",
    "Optimization terminated successfully.\n",
    "         Current function value: 0.589094\n",
    "         Iterations 5\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> print(result.summary())\n",
    "```\n",
    "\n",
    "```\n",
    "                           Logit Regression Results                           \n",
    "==============================================================================\n",
    "Dep. Variable:        DepDelay_binary   No. Observations:               321227\n",
    "Model:                          Logit   Df Residuals:                   321211\n",
    "Method:                           MLE   Df Model:                           15\n",
    "Date:                Thu, 21 Jan 2016   Pseudo R-squ.:                0.005735\n",
    "Time:                        22:05:38   Log-Likelihood:            -1.8923e+05\n",
    "converged:                       True   LL-Null:                   -1.9032e+05\n",
    "                                        LLR p-value:                     0.000\n",
    "====================================================================================\n",
    "                       coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
    "------------------------------------------------------------------------------------\n",
    "DayOfWeek_2         -0.1574      0.015    -10.479      0.000        -0.187    -0.128\n",
    "DayOfWeek_3          0.0164      0.015      1.113      0.266        -0.012     0.045\n",
    "DayOfWeek_4          0.2148      0.014     14.911      0.000         0.187     0.243\n",
    "DayOfWeek_5          0.2059      0.014     14.274      0.000         0.178     0.234\n",
    "DayOfWeek_6          0.0229      0.015      1.514      0.130        -0.007     0.053\n",
    "DayOfWeek_7          0.1085      0.015      7.397      0.000         0.080     0.137\n",
    "UniqueCarrier_AS    -0.3596      0.134     -2.679      0.007        -0.623    -0.096\n",
    "UniqueCarrier_CO    -0.0101      0.030     -0.339      0.735        -0.069     0.048\n",
    "UniqueCarrier_DL     0.5507      0.024     22.889      0.000         0.504     0.598\n",
    "UniqueCarrier_HP     0.8619      0.039     22.121      0.000         0.786     0.938\n",
    "UniqueCarrier_MQ     0.0906      0.012      7.502      0.000         0.067     0.114\n",
    "UniqueCarrier_NW     0.2597      0.025     10.572      0.000         0.212     0.308\n",
    "UniqueCarrier_TW     0.3749      0.036     10.343      0.000         0.304     0.446\n",
    "UniqueCarrier_UA     0.1901      0.010     19.987      0.000         0.172     0.209\n",
    "UniqueCarrier_US     0.2573      0.027      9.632      0.000         0.205     0.310\n",
    "Intercept           -1.1426      0.012    -94.960      0.000        -1.166    -1.119\n",
    "====================================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a8fecbebbfb116f413be9df92942fd07",
     "grade": false,
     "grade_id": "fit_logistic_columns",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "train_columns = [ ### 'DayofWeek_1' # do not include this\n",
    "        'DayOfWeek_2', 'DayOfWeek_3', 'DayOfWeek_4',\n",
    "        'DayOfWeek_5', 'DayOfWeek_6', 'DayOfWeek_7',\n",
    "        ### 'UniqueCarrierAA' # do not include this\n",
    "        'UniqueCarrier_AS', 'UniqueCarrier_CO', 'UniqueCarrier_DL',\n",
    "        'UniqueCarrier_HP', 'UniqueCarrier_MQ', 'UniqueCarrier_NW',\n",
    "        'UniqueCarrier_TW', 'UniqueCarrier_UA', 'UniqueCarrier_US',\n",
    "        'Intercept'\n",
    "        ]\n",
    "\n",
    "model, result = fit_logitistic(data, train_columns=train_columns, test_column='DepDelay_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "dd63a296a0f8587184c324b995d0c462",
     "grade": false,
     "grade_id": "print_result_summary",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "fa17a420e9ec29a6ff1ac30b2c92190a",
     "grade": true,
     "grade_id": "fit_logistic_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(isinstance(model, statsmodels.discrete.discrete_model.Logit), True)\n",
    "assert_equal(isinstance(result, statsmodels.discrete.discrete_model.BinaryResultsWrapper), True)\n",
    "\n",
    "assert_equal(model.exog_names, train_columns)\n",
    "assert_equal(model.endog_names, 'DepDelay_binary')\n",
    "\n",
    "assert_array_equal(model.exog, data[train_columns].values)\n",
    "assert_array_equal(model.endog, data['DepDelay_binary'].values)\n",
    "\n",
    "test_conf_int = result.conf_int()\n",
    "answer_conf_int = pd.DataFrame(\n",
    "    index=train_columns,\n",
    "    data={\n",
    "        0: np.array([\n",
    "            -0.18681953, -0.01247828,  0.18652782,  0.17760447, -0.00675086,\n",
    "            0.07974488, -0.6227236 , -0.06873794,  0.50352299,  0.78551841,\n",
    "            0.06694527,  0.21153022,  0.30383117,  0.17150234,  0.20497387,\n",
    "            -1.166157  ]),\n",
    "        1: np.array([\n",
    "            -0.12794527,  0.04524193,  0.24298324,  0.23413964,  0.05254801,\n",
    "            0.13724129, -0.09649653,  0.04848345,  0.59783265,  0.93824414,\n",
    "            0.11429806,  0.30780938,  0.44591082,  0.20879553,  0.30969833,\n",
    "            -1.11899193])\n",
    "        }\n",
    "    )\n",
    "assert_frame_equal(test_conf_int, answer_conf_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the probability of flights being delayed is higher on Thursdays (`DayOfWeek_4`) and Fridays(`DayOfWeek_5`). In terms of carriers, `HP` an `MQ` airlines are more likely to be delayed than others.\n",
    "\n",
    "Does this result make sense? Let calculate the mean of `DepDelay` for each day of the week. We see that Thursday and Friday have the highest mean values.\n",
    "\n",
    "```python\n",
    ">>> print(local.groupby('DayOfWeek').mean().sort_values(by='DepDelay', ascending=False))\n",
    "```\n",
    "\n",
    "```\n",
    "            DepDelay  DepDelay_binary\n",
    "DayOfWeek                            \n",
    "4          11.419251         0.311135\n",
    "5          11.306297         0.309324\n",
    "7          10.244282         0.288786\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "fa2a3dcfec38d1c78faab170925d71f3",
     "grade": false,
     "grade_id": "print_day_groupby",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(local.groupby('DayOfWeek').mean().sort_values(by='DepDelay', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for `UniqueCarrier`, and HP and DL airline indeed have the highest mean departure delay.\n",
    "\n",
    "```python\n",
    ">>> print(local.groupby('UniqueCarrier').mean().sort_values(by='DepDelay', ascending=False))\n",
    "```\n",
    "\n",
    "```\n",
    "               DayOfWeek   DepDelay  DepDelay_binary\n",
    "UniqueCarrier                                       \n",
    "HP              3.973684  18.245494         0.444845\n",
    "DL              3.972141  11.719453         0.370235\n",
    "UA              3.953615  11.027225         0.291036\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6db243fab957aebc84981ba2c43c50a8",
     "grade": false,
     "grade_id": "print_delay_groupby",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(local.groupby('UniqueCarrier').mean().sort_values(by='DepDelay', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "44834f8493e8387c102e29525e571c0b",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This notebook will be collected automatically at **6pm on Monday** from `/home/data_scientist/assignments/Week9` directory on the course JupyterHub server. If you work on this assignment on the course Jupyterhub server, just make sure that you save your work and instructors will pull your notebooks automatically after the deadline. If you work on this assignment locally, the only way to submit assignments is via Jupyterhub, and you have to place the notebook file in the correct directory with the correct file name before the deadline.\n",
    "\n",
    "1. Make sure everything runs as expected. First, restart the kernel (in the menubar, select `Kernel` → `Restart`) and then run all cells (in the menubar, select `Cell` → `Run All`).\n",
    "2. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed by the autograder.\n",
    "3. Do not change the file path or the file name of this notebook.\n",
    "4. Make sure that you save your work (in the menubar, select `File` → `Save and CheckPoint`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "917ac9ed82b79b3ac4fd2cf65c3c608a",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem 9.1. NLP: Basic Concepts.\n",
    "\n",
    "In this problem, we explore the basic concepts of part of speech (POS) tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "e0376f07ae23fb13b34d659c968f0df7",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import nltk\n",
    "import pprint\n",
    "\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "from nltk.tag import DefaultTagger, UnigramTagger\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_instance, assert_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d643d52a5785d3b8395ac08aa3b99fd1",
     "grade": false,
     "grade_id": "markdown_1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We use _Alice's Adventures in Wonderland_ by Lewis Carroll, freely available from _Project Gutenberg_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e1d8f1a4c962f13d2ce72b6ef94d3b37",
     "grade": false,
     "grade_id": "download_text",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "resp = requests.get('http://www.gutenberg.org/cache/epub/11/pg11.txt')\n",
    "text = resp.text\n",
    "print(text[:1000])\n",
    "\n",
    "assert_is_instance(text, str)\n",
    "assert_equal(len(text), 167516)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f092c8d895ac87adc2c8eb5bdec57d2b",
     "grade": false,
     "grade_id": "markdown_2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Tokenize\n",
    "\n",
    "- Tokenize the text by words by using `word_tokenize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b3158a7e4ff4f965d620d91854e9a33b",
     "grade": false,
     "grade_id": "tokenize_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''\n",
    "    Tokenizes the text by words.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: A string.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of strings.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "1049f6b99f2ac5a8a621c71c9ae1e4dd",
     "grade": false,
     "grade_id": "tokenize_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "word_tokens = tokenize(text)\n",
    "print('{0} words in course description'.format(len(word_tokens)))\n",
    "print(40*'-')\n",
    "print(word_tokens[:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "032485258474ea43dd9951840bbb35d1",
     "grade": true,
     "grade_id": "tokenize_test",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(word_tokens, list)\n",
    "assert_true(all(isinstance(t, str) for t in word_tokens))\n",
    "assert_equal(len(word_tokens), 36719)\n",
    "assert_equal(word_tokens[:5], ['\\ufeffProject', 'Gutenberg', \"'s\", 'Alice', \"'s\"])\n",
    "assert_equal(word_tokens[-5:], ['hear', 'about', 'new', 'eBooks', '.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6b61b744bb36e83abd036642f3a06707",
     "grade": false,
     "grade_id": "markdown_3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Collocations\n",
    "\n",
    "- Build bigram collocations by using the pointwise mutual information (PMI). Return the best 10 bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "030b9bd4ab1eb0011a53df62981fa4a8",
     "grade": false,
     "grade_id": "find_best_bigrams_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def find_best_bigrams(tokens):\n",
    "    '''\n",
    "    Builds collocations by using the pointwise mutual information (PMI).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tokens: A list of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of tuples of (str, str).\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "685fd50c690e6f7d4f02c8c01838c9b1",
     "grade": false,
     "grade_id": "find_best_bigrams_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "top_bigrams = find_best_bigrams(word_tokens)\n",
    "\n",
    "print('Best {0} bi-grams in text (WP Tokenizer)'.format(10))\n",
    "print(50*'-')\n",
    "\n",
    "ppf = pprint.PrettyPrinter(indent=2, depth=2, width=80, compact=False)\n",
    "ppf.pprint(top_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "01a774b43b2e0c0e34e47d7f2e91e0c9",
     "grade": true,
     "grade_id": "find_best_bigrams_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(\n",
    "    top_bigrams,\n",
    "    [('#', '11'), (\"'Cheshire\", 'Puss'), (\"'IT\", 'DOES'), (\"'ORANGE\", 'MARMALADE'), (\"'Ou\", 'est'),\n",
    "     (\"'Rule\", 'Forty-two'), (\"'Seven\", 'jogged'), (\"'With\", 'extras'), (\"'any\", 'shrimp'), (\"'than\", 'waste')]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0850ae3cc87f05f708458fd4feef57cf",
     "grade": false,
     "grade_id": "markdown_4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## DefaultTagger\n",
    "\n",
    "- Use `DefaultTagger` to associate a tag of our choosing (the `tag` parameter) with words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "1f90833c6003fa1a4fbf5b1a1d468dd5",
     "grade": false,
     "grade_id": "tag_words_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tag_words(words, tag):\n",
    "    '''\n",
    "    Associates a tag with words.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    words: A list of strings.\n",
    "    tag: A str.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of tuples of (str, str)\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "842a8306e01c0bd24af2fd5c9c4adc41",
     "grade": false,
     "grade_id": "tag_words_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tags = tag_words(word_tokens, 'INFO')\n",
    "print('Tagged text (WP Tokenizer)')\n",
    "print(50*'-')\n",
    "pp = pprint.PrettyPrinter(indent=2, depth=2, width=80, compact=True)\n",
    "pp.pprint(tags[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "011b1ef08284ce4759f7cba48c12fb38",
     "grade": true,
     "grade_id": "tag_words_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(tags, list)\n",
    "assert_equal(len(tags), 36719)\n",
    "for i, t in enumerate(tags):\n",
    "    assert_is_instance(t, tuple)\n",
    "    assert_equal(len(t), 2)\n",
    "    assert_is_instance(t[0], str)\n",
    "    assert_is_instance(t[1], str)\n",
    "    assert_equal(t[0], word_tokens[i])\n",
    "    assert_equal(t[1], 'INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8ce24a22699a5108627910367e2a700b",
     "grade": false,
     "grade_id": "markdown_5",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Part of Speech Tagging\n",
    "\n",
    "- Use a PerceptronTagger to create Part of Speech (PoS) tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a11757d1120c38bdf7b0fdf38d4e1b6c",
     "grade": false,
     "grade_id": "tag_pos_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tag_pos(words):\n",
    "    '''\n",
    "    Creates Part of Speech tags.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    words: A list of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of tuples of (str, str)\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "8f7ee272139a238d4a349174cb4073ec",
     "grade": false,
     "grade_id": "tag_pos_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pos_tags = tag_pos(word_tokens)\n",
    "\n",
    "print('PoS tagged text (WP Tokenizer/Univesal Tagger)')\n",
    "print(60*'-')\n",
    "\n",
    "ppf.pprint(pos_tags[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "3350235c74b7a86fbb3f3fe57d0fc565",
     "grade": true,
     "grade_id": "tag_pos_test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(len(pos_tags), len(word_tokens))\n",
    "assert_equal(\n",
    "    pos_tags[:15],\n",
    "    [('\\ufeffProject', 'JJ'), ('Gutenberg', 'NNP'),\n",
    "     (\"'s\", 'POS'), ('Alice', 'NNP'),\n",
    "     (\"'s\", 'POS'), ('Adventures', 'NNS'),\n",
    "     ('in', 'IN'), ('Wonderland', 'NNP'),\n",
    "     (',', ','), ('by', 'IN'),\n",
    "     ('Lewis', 'NNP'), ('Carroll', 'NNP'),\n",
    "     ('This', 'DT'), ('eBook', 'NN'),\n",
    "     ('is', 'VBZ')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3a255b65079798e9fcfebaade4299ce7",
     "grade": false,
     "grade_id": "markdown_6",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Penn Treebank\n",
    "\n",
    "- Tokenize and tag unigrams in `text` by using `UnigramTagger` and a Penn Treebank tagged sentence and word tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "8eb1730a36da217174aac69409f7dd35",
     "grade": false,
     "grade_id": "tag_penn_answer",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tag_penn(words):\n",
    "    '''\n",
    "    Tokenizes text by using a Penn Treebank tagged sentence and word tokenizer.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    words: A list of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of tuples of (str, str)\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e6d7f7a37f917b3982fb13f3a00a881d",
     "grade": false,
     "grade_id": "tag_penn_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "b_tags = tag_penn(word_tokens)\n",
    "\n",
    "print('Penn Treebank tagged text (WP Tokenizer)')\n",
    "print(60*'-')\n",
    "\n",
    "ppf.pprint(b_tags[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b2ecbdf5a09c24864b834a0d79914eb0",
     "grade": true,
     "grade_id": "tag_penn_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(len(b_tags), len(word_tokens))\n",
    "assert_equal(\n",
    "    b_tags[:15],\n",
    "    [('\\ufeffProject', None), ('Gutenberg', None),\n",
    "     (\"'s\", 'POS'), ('Alice', None),\n",
    "     (\"'s\", 'POS'), ('Adventures', None),\n",
    "     ('in', 'IN'), ('Wonderland', None),\n",
    "     (',', ','), ('by', 'IN'),\n",
    "     ('Lewis', 'NNP'), ('Carroll', None),\n",
    "     ('This', 'DT'), ('eBook', None),\n",
    "     ('is', 'VBZ')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7c2a6e55c35a8f1ea23f547555cb4302",
     "grade": false,
     "grade_id": "markdown_7",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Linking Taggers\n",
    "\n",
    "- Link the Penn Treebank Corpus tagger with our earlier Default tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "1f7d00fc101d8b374d6a04a12c9b0ae3",
     "grade": false,
     "grade_id": "tag_linked_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tag_linked(words, default_tag='INFO'):\n",
    "    '''\n",
    "    Tokenizes text by using a Penn Treebank tagged sentence and word tokenizers.\n",
    "    Uses DefaultTagger to assign \"default_tag\" to any element missed by Penn Treebank tagger.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    words: A list of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of tuples of (str, str)\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "041a0f981d12469610d6c13bd4e703f0",
     "grade": false,
     "grade_id": "tag_linked_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "linked_tags = tag_linked(word_tokens)\n",
    "print('Penn Treebank tagged text (WP Tokenizer/Linked Tagger)')\n",
    "print(60*'-')\n",
    "\n",
    "ppf.pprint(linked_tags[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "80a83890eb01a8e5ad4904339824c23e",
     "grade": true,
     "grade_id": "tag_linked_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(len(linked_tags), len(word_tokens))\n",
    "assert_equal(\n",
    "    linked_tags[:15],\n",
    "    [('\\ufeffProject', 'INFO'), ('Gutenberg', 'INFO'),\n",
    "     (\"'s\", 'POS'), ('Alice', 'INFO'),\n",
    "     (\"'s\", 'POS'), ('Adventures', 'INFO'),\n",
    "     ('in', 'IN'), ('Wonderland', 'INFO'),\n",
    "     (',', ','), ('by', 'IN'),\n",
    "     ('Lewis', 'NNP'), ('Carroll', 'INFO'),\n",
    "     ('This', 'DT'), ('eBook', 'INFO'),\n",
    "     ('is', 'VBZ')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cab64368fd013cf60da2e085fbd5432d",
     "grade": false,
     "grade_id": "markdown_8",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Tagged Text Extraction\n",
    "\n",
    "- Use regular expressions to restrict tokens in the text to Nouns, Verbs, Adjectives, and Adverbs. Return a tuple of PoS tags and the extracted terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "cb558a74ad6be41e7c6dad519804282e",
     "grade": false,
     "grade_id": "extract_tags_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_tags(words):\n",
    "    '''\n",
    "    Restricts tokens in the text to Nouns, Verbs, Adjectives, and Adverbs.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    words: A list of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (pos_tags, terms)\n",
    "    pos_tags: A list of tuples of (str, str).\n",
    "    terms: A list of strings.\n",
    "           Terms extracted with regex.\n",
    "           Nouns, verbs, adjectives, or adverbs.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return pos_tags, terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9aaa60ef8f629f13b4a319b36b4cf1a0",
     "grade": false,
     "grade_id": "extract_tags_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pos_tags, terms = extract_tags(word_tokens)\n",
    "\n",
    "print('POS tagged text (WP Tokenizer)')\n",
    "print(60*'-')\n",
    "pp.pprint(pos_tags[:15])\n",
    "print(60*'-')\n",
    "print('POS tagged text (WP Tokenizer/RegEx applied)')\n",
    "print(60*'-')\n",
    "pp.pprint(terms[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "3a8c858b2cc526e18031fd447b667fea",
     "grade": true,
     "grade_id": "extract_tags_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(len(pos_tags), len(word_tokens))\n",
    "assert_equal(\n",
    "    pos_tags[:15],\n",
    "    [('\\ufeffProject', 'JJ'), ('Gutenberg', 'NNP'), (\"'s\", 'POS'),\n",
    "     ('Alice', 'NNP'), (\"'s\", 'POS'), ('Adventures', 'NNS'), ('in', 'IN'),\n",
    "     ('Wonderland', 'NNP'), (',', ','), ('by', 'IN'), ('Lewis', 'NNP'),\n",
    "     ('Carroll', 'NNP'), ('This', 'DT'), ('eBook', 'NN'), ('is', 'VBZ')]\n",
    "    )\n",
    "assert_true((len(terms) == 16448) | (len(terms) == 16447))\n",
    "assert_equal(\n",
    "    terms[:15],\n",
    "    ['\\ufeffProject', 'Gutenberg', 'Alice', 'Adventures', 'Wonderland', 'Lewis',\n",
    "     'Carroll', 'eBook', 'is', 'use', 'anyone', 'anywhere', 'cost', 'almost',\n",
    "     'restrictions']\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
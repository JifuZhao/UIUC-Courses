{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "44834f8493e8387c102e29525e571c0b",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This notebook will be collected automatically at **6pm on Monday** from `/home/data_scientist/assignments/Week9` directory on the course JupyterHub server. If you work on this assignment on the course Jupyterhub server, just make sure that you save your work and instructors will pull your notebooks automatically after the deadline. If you work on this assignment locally, the only way to submit assignments is via Jupyterhub, and you have to place the notebook file in the correct directory with the correct file name before the deadline.\n",
    "\n",
    "1. Make sure everything runs as expected. First, restart the kernel (in the menubar, select `Kernel` → `Restart`) and then run all cells (in the menubar, select `Cell` → `Run All`).\n",
    "2. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed by the autograder.\n",
    "3. Do not change the file path or the file name of this notebook.\n",
    "4. Make sure that you save your work (in the menubar, select `File` → `Save and CheckPoint`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cff737ab04ed5f48f39a33ba2b9ead9e",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem 9.2. NLP: Topic Modeling.\n",
    "\n",
    "In this problem, we explore the concept of topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b8b06cd33532f50387012a5f45ba491e",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import check_random_state\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_instance, assert_true\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a630cc19372c4e42474625136a001138",
     "grade": false,
     "grade_id": "markdown_1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We use the twenty newsgroup data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "129bdcdf3b926ea610045a749bf95b13",
     "grade": false,
     "grade_id": "20newsgroups",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "train = fetch_20newsgroups(\n",
    "    data_home='/home/data_scientist/data/textdm', \n",
    "    subset='train',\n",
    "    shuffle=True,\n",
    "    random_state=check_random_state(0),\n",
    "    remove=('headers', 'footers', 'quotes')\n",
    "    )\n",
    "\n",
    "test = fetch_20newsgroups(\n",
    "    data_home='/home/data_scientist/data/textdm', \n",
    "    subset='test',\n",
    "    shuffle=True,\n",
    "    random_state=check_random_state(0),\n",
    "    remove=('headers', 'footers', 'quotes')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9021cc7d91c1aba4875327bd7f61746a",
     "grade": false,
     "grade_id": "markdown_2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Document term matrix\n",
    "\n",
    "- Use TfidfVectorizer to create a document term matrix for both `train['data']` and `test['data']`.\n",
    "- Use English stop words.\n",
    "- Use unigrams and bigrams.\n",
    "- Ignore terms that have a document frequency strictly lower than 2.\n",
    "- Build a vocabulary that only consider the top 20,000 features ordered by term frequency across the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "1aba9e4eff2b9c7a699ecee3576b3f90",
     "grade": false,
     "grade_id": "get_document_term_matrix_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_document_term_matrix(train_data, test_data):\n",
    "    '''\n",
    "    Uses TfidfVectorizer to create a document term matrix for \"train_data\" and \"test_data\".\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    train_data: A list of strings\n",
    "    test_data:A list of strings\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 3-tuple of (model, train_matrix, test_matrix).\n",
    "    model: A TfidfVectorizer instance\n",
    "    train_matrix: A scipy.csr_matrix\n",
    "    test_matrix: A scipy.csr_matrix\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return model, train_matrix, test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "223df1d07ede85ba51041e4d98fec8cf",
     "grade": false,
     "grade_id": "get_document_term_matrix_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "cv, train_data, test_data = get_document_term_matrix(train['data'], test['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7d661a19c0ddad54657b6626ffaa6bc2",
     "grade": true,
     "grade_id": "get_document_term_matrix_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(cv, TfidfVectorizer)\n",
    "assert_is_instance(train_data, csr_matrix)\n",
    "assert_is_instance(test_data, csr_matrix)\n",
    "assert_equal(cv.stop_words, 'english')\n",
    "assert_equal(cv.ngram_range, (1, 2))\n",
    "assert_equal(cv.min_df, 2)\n",
    "assert_equal(cv.max_features, 20000)\n",
    "assert_equal(train_data.data.size, 680499)\n",
    "assert_array_almost_equal(\n",
    "    train_data.data[:5],\n",
    "    [0.04590546,  0.05614672,  0.05849851,  0.05614672,  0.06487626]\n",
    "    )\n",
    "assert_equal(test_data.data.size, 415292)\n",
    "assert_array_almost_equal(\n",
    "    test_data.data[:5],\n",
    "    [0.16046961,  0.3429567 ,  0.2124038 ,  0.28698678,  0.22300288]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0c94a4f3e3244ae3a1e134a7913a332c",
     "grade": false,
     "grade_id": "markdown_3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Non-negative matrix factorization\n",
    "\n",
    "- Apply non-negative matrix factorization (NMF) to compute topics in `train_data`.\n",
    "- Use 60 topics.\n",
    "- Normalize the transformed data to have unit probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "188fa2676fd89866b68f4f4d857d59b8",
     "grade": false,
     "grade_id": "apply_nmf_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_nmf(data, random_state):\n",
    "    '''\n",
    "    Applies non-negative matrix factorization (NMF) to compute topics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A csr_matrix\n",
    "    random_state: A RandomState instance for NMF\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (nmf, transformed_data)\n",
    "    nmf: An sklearn.NMF instance\n",
    "    transformed_data: A numpy.ndarray\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return nmf, transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6a9f2025b751ca3ba045d8e3187b3eed",
     "grade": false,
     "grade_id": "apply_nmf_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "nmf, td_norm = apply_nmf(train_data, random_state=check_random_state(0))\n",
    "\n",
    "# We use a DataFrame to simplify the collecting of the data for display.\n",
    "df = pd.DataFrame(td_norm)\n",
    "df.fillna(value=0, inplace=True)\n",
    "df['label'] = pd.Series(train['target'])\n",
    "\n",
    "df_label = df.groupby('label').mean()\n",
    "df_label['names'] = pd.Series(train['target_names'], dtype=\"category\")\n",
    "\n",
    "# we display only final 5 columns for brevity (we have 61 columns)\n",
    "print(df_label.ix[:, -5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b19231929eda937cec95f6c5bdd8da7d",
     "grade": true,
     "grade_id": "apply_nmf_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(nmf, NMF)\n",
    "assert_is_instance(td_norm, np.ndarray)\n",
    "assert_equal(nmf.n_components, 60)\n",
    "assert_equal(nmf.max_iter, 200)\n",
    "assert_equal(td_norm.shape, (11314, 60))\n",
    "assert_array_almost_equal(\n",
    "    td_norm[0, :5],\n",
    "    [0.        ,  0.00421649,  0.        ,  0.120597  ,  0.00141566]\n",
    "    )\n",
    "assert_array_almost_equal(\n",
    "    td_norm[-1, -5:],\n",
    "    [ 0.05955216,  0.        ,  0.00094186,  0.        ,  0.06290102]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "611cafc53e947fa1dddb9dd3fc6dfadd",
     "grade": false,
     "grade_id": "mardkwon_4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Topic-based Classification\n",
    "\n",
    "- Train a Random Forest classifier on the topics in the training data sample of the twenty newsgroup data set.\n",
    "- Use default parameters for the random forest classifier. Don't forget to set the `random_state` parameter.\n",
    "- Compute the topics, by using the previously created NMF model, for the test data and compute classifications from these topic models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "28b3804dfe1b863bc9dd57062b2f400c",
     "grade": false,
     "grade_id": "classify_topics_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def classify_topics(nmf, X_train, y_train, X_test, random_state):\n",
    "    '''\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    nmf: An sklearn.NMF model.\n",
    "    X_train: A numpy array.\n",
    "    y_train: A numpy array.\n",
    "    X_test: A scipy csr_matrix.\n",
    "    random_state: A RandomState instance for Random Forest Classifier.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (clf, y_pred)\n",
    "    clf: A RandomForestClassifier instance.\n",
    "    y_pred: A numpy array.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return clf, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "23c2e6fe8c633a0f8a8d7d40fd8faa4a",
     "grade": false,
     "grade_id": "markdown_5",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The resulting classification report and confusion matrix are shown to demonstrate the quality of this classification method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "367e566f2d270d4f4e8201a0dd9caaf0",
     "grade": false,
     "grade_id": "classify_topics_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "clf, ts_preds = classify_topics(\n",
    "    nmf, nmf.transform(train_data), train['target'], test_data, check_random_state(0)\n",
    "    )\n",
    "print(classification_report(test['target'], ts_preds, target_names=test['target_names']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "0cf1b763d75f579c4d14bd3354fafacb",
     "grade": true,
     "grade_id": "classify_topics_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(clf, RandomForestClassifier)\n",
    "assert_is_instance(ts_preds, np.ndarray)\n",
    "assert_equal(len(ts_preds), len(test['target']))\n",
    "assert_array_equal(ts_preds[:5], [8, 1, 16, 15, 6])\n",
    "assert_array_equal(ts_preds[-5:], [7, 9, 3, 1, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7f851ecfea4ac3fe4befe936948cb928",
     "grade": false,
     "grade_id": "markdown_6",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Topic Modeling with Gensim\n",
    "\n",
    "- Use the gensim library to perform topic modeling of the twenty newsgroup data. First transform a sparse matrix into a gensim corpus, and then construct a vocabulary dictionary. Finally, create a  Latent Dirichlet allocation (LDA) model with 20 topics for the newsgroup text, and return 5 most significant words for each topic.\n",
    "- You should specify three parameters in `LdaModel()`: `corpus`, `id2word`, and `num_topics`. Use default values for all other paramters. Ignore any warnings about `passes` or `iterations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "385f5d7f073cbf54b7205c1b9b6f2a46",
     "grade": false,
     "grade_id": "get_topics_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_topics(cv, train_data):\n",
    "    '''\n",
    "    Uses gensim to perform topic modeling.\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    cv: A TfidfVectorizer instance.\n",
    "    train_data: A scipy csr_matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of strings (functions of the most important terms in each topic).\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a59f5f881e6e96f699813e444c0ba77d",
     "grade": false,
     "grade_id": "get_topics_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "topics = get_topics(cv, train_data)\n",
    "\n",
    "for idx, (lst, val) in enumerate(topics):\n",
    "    print('Topic {0}'.format(idx))\n",
    "    print(35*('-'))\n",
    "    for i, z in lst:\n",
    "        print('    {0:20s}: {1:5.4f}'.format(z, i))\n",
    "    print(35*('-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a9979dc296f99568d488105aa65a8bdb",
     "grade": true,
     "grade_id": "get_topics_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(topics, list)\n",
    "assert_equal(len(topics), 20)\n",
    "\n",
    "for topic, score in topics:\n",
    "    assert_is_instance(topic, list)\n",
    "    assert_is_instance(score, float)\n",
    "    assert_equal(len(topic), 5)\n",
    "    for v, k in topic:\n",
    "        assert_is_instance(k, str)\n",
    "        assert_is_instance(v, float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
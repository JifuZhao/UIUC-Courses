{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "44834f8493e8387c102e29525e571c0b",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This notebook will be collected automatically at **6pm on Monday** from `/home/data_scientist/assignments/Week9` directory on the course JupyterHub server. If you work on this assignment on the course Jupyterhub server, just make sure that you save your work and instructors will pull your notebooks automatically after the deadline. If you work on this assignment locally, the only way to submit assignments is via Jupyterhub, and you have to place the notebook file in the correct directory with the correct file name before the deadline.\n",
    "\n",
    "1. Make sure everything runs as expected. First, restart the kernel (in the menubar, select `Kernel` → `Restart`) and then run all cells (in the menubar, select `Cell` → `Run All`).\n",
    "2. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed by the autograder.\n",
    "3. Do not change the file path or the file name of this notebook.\n",
    "4. Make sure that you save your work (in the menubar, select `File` → `Save and CheckPoint`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cff737ab04ed5f48f39a33ba2b9ead9e",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem 9.2. NLP: Topic Modeling.\n",
    "\n",
    "In this problem, we explore the concept of topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b8b06cd33532f50387012a5f45ba491e",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import check_random_state\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_instance, assert_true\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a630cc19372c4e42474625136a001138",
     "grade": false,
     "grade_id": "markdown_1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We use the twenty newsgroup data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "129bdcdf3b926ea610045a749bf95b13",
     "grade": false,
     "grade_id": "20newsgroups",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "train = fetch_20newsgroups(\n",
    "    data_home='/home/data_scientist/data/textdm', \n",
    "    subset='train',\n",
    "    shuffle=True,\n",
    "    random_state=check_random_state(0),\n",
    "    remove=('headers', 'footers', 'quotes')\n",
    "    )\n",
    "\n",
    "test = fetch_20newsgroups(\n",
    "    data_home='/home/data_scientist/data/textdm', \n",
    "    subset='test',\n",
    "    shuffle=True,\n",
    "    random_state=check_random_state(0),\n",
    "    remove=('headers', 'footers', 'quotes')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9021cc7d91c1aba4875327bd7f61746a",
     "grade": false,
     "grade_id": "markdown_2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Document term matrix\n",
    "\n",
    "- Use TfidfVectorizer to create a document term matrix for both `train['data']` and `test['data']`.\n",
    "- Use English stop words.\n",
    "- Use unigrams and bigrams.\n",
    "- Ignore terms that have a document frequency strictly lower than 2.\n",
    "- Build a vocabulary that only consider the top 20,000 features ordered by term frequency across the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "1aba9e4eff2b9c7a699ecee3576b3f90",
     "grade": false,
     "grade_id": "get_document_term_matrix_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_document_term_matrix(train_data, test_data):\n",
    "    '''\n",
    "    Uses TfidfVectorizer to create a document term matrix for \"train_data\" and \"test_data\".\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    train_data: A list of strings\n",
    "    test_data:A list of strings\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 3-tuple of (model, train_matrix, test_matrix).\n",
    "    model: A TfidfVectorizer instance\n",
    "    train_matrix: A scipy.csr_matrix\n",
    "    test_matrix: A scipy.csr_matrix\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    model = TfidfVectorizer(stop_words = 'english',\n",
    "                            ngram_range=(1, 2),\n",
    "                            min_df=2,\n",
    "                            max_features=20000)\n",
    "                     \n",
    "    train_matrix = model.fit_transform(train_data)\n",
    "    test_matrix = model.transform(test_data)\n",
    "    \n",
    "    return model, train_matrix, test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "223df1d07ede85ba51041e4d98fec8cf",
     "grade": false,
     "grade_id": "get_document_term_matrix_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "cv, train_data, test_data = get_document_term_matrix(train['data'], test['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7d661a19c0ddad54657b6626ffaa6bc2",
     "grade": true,
     "grade_id": "get_document_term_matrix_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(cv, TfidfVectorizer)\n",
    "assert_is_instance(train_data, csr_matrix)\n",
    "assert_is_instance(test_data, csr_matrix)\n",
    "assert_equal(cv.stop_words, 'english')\n",
    "assert_equal(cv.ngram_range, (1, 2))\n",
    "assert_equal(cv.min_df, 2)\n",
    "assert_equal(cv.max_features, 20000)\n",
    "assert_equal(train_data.data.size, 680499)\n",
    "assert_array_almost_equal(\n",
    "    train_data.data[:5],\n",
    "    [0.04590546,  0.05614672,  0.05849851,  0.05614672,  0.06487626]\n",
    "    )\n",
    "assert_equal(test_data.data.size, 415292)\n",
    "assert_array_almost_equal(\n",
    "    test_data.data[:5],\n",
    "    [0.16046961,  0.3429567 ,  0.2124038 ,  0.28698678,  0.22300288]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0c94a4f3e3244ae3a1e134a7913a332c",
     "grade": false,
     "grade_id": "markdown_3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Non-negative matrix factorization\n",
    "\n",
    "- Apply non-negative matrix factorization (NMF) to compute topics in `train_data`.\n",
    "- Use 60 topics.\n",
    "- Normalize the transformed data to have unit probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "188fa2676fd89866b68f4f4d857d59b8",
     "grade": false,
     "grade_id": "apply_nmf_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_nmf(data, random_state):\n",
    "    '''\n",
    "    Applies non-negative matrix factorization (NMF) to compute topics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A csr_matrix\n",
    "    random_state: A RandomState instance for NMF\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (nmf, transformed_data)\n",
    "    nmf: An sklearn.NMF instance\n",
    "    transformed_data: A numpy.ndarray\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    nmf = NMF(n_components=60, max_iter=200, random_state=random_state).fit(data)\n",
    "    td = nmf.transform(data)\n",
    "    transformed_data = normalize(td, norm='l1', axis=1)\n",
    "    \n",
    "    return nmf, transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "bb8661b4ac2fa4a913f92dd86fff2d47",
     "grade": false,
     "grade_id": "apply_nmf_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alt.atheism</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120597</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003139</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics</th>\n",
       "      <td>0.037898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.033312</td>\n",
       "      <td>0.019869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.os.ms-windows.misc</th>\n",
       "      <td>0.012951</td>\n",
       "      <td>0.207267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.057188</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.ibm.pc.hardware</th>\n",
       "      <td>0.253397</td>\n",
       "      <td>0.015348</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017412</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.sys.mac.hardware</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.641944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x</th>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014806</td>\n",
       "      <td>0.367371</td>\n",
       "      <td>0.019263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>misc.forsale</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005670</td>\n",
       "      <td>0.048850</td>\n",
       "      <td>0.579381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083633</td>\n",
       "      <td>0.001053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.autos</th>\n",
       "      <td>0.044051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.motorcycles</th>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104846</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.sport.baseball</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042552</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.675968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.sport.hockey</th>\n",
       "      <td>0.007178</td>\n",
       "      <td>0.057966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044383</td>\n",
       "      <td>0.020401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028229</td>\n",
       "      <td>0.038843</td>\n",
       "      <td>0.032829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017458</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.crypt</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059774</td>\n",
       "      <td>0.022716</td>\n",
       "      <td>0.011545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168861</td>\n",
       "      <td>0.018223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.141698</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.electronics</th>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007209</td>\n",
       "      <td>0.035532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134462</td>\n",
       "      <td>0.033779</td>\n",
       "      <td>0.012454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007737</td>\n",
       "      <td>0.288122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.med</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012459</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.space</th>\n",
       "      <td>0.026780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.534881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049695</td>\n",
       "      <td>0.032267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.religion.christian</th>\n",
       "      <td>0.008090</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.018644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055271</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.politics.guns</th>\n",
       "      <td>0.135704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061471</td>\n",
       "      <td>0.334120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023017</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.politics.mideast</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038932</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090331</td>\n",
       "      <td>0.325750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.politics.misc</th>\n",
       "      <td>0.027812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283583</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.religion.misc</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.198373</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0         1         2         3         4   \\\n",
       "label                                                                        \n",
       "alt.atheism               0.000000  0.004216  0.000000  0.120597  0.001416   \n",
       "comp.graphics             0.037898  0.000000  0.000000  0.209269  0.000000   \n",
       "comp.os.ms-windows.misc   0.012951  0.207267  0.000000  0.000000  0.000000   \n",
       "comp.sys.ibm.pc.hardware  0.253397  0.015348  0.003114  0.000000  0.241721   \n",
       "comp.sys.mac.hardware     0.000000  0.000000  0.000000  0.641944  0.000000   \n",
       "comp.windows.x            0.002888  0.004130  0.000000  0.000000  0.048298   \n",
       "misc.forsale              0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "rec.autos                 0.044051  0.000000  0.000000  0.000000  0.149592   \n",
       "rec.motorcycles           0.000880  0.000000  0.004938  0.002977  0.001808   \n",
       "rec.sport.baseball        0.000000  0.000000  0.000000  0.004005  0.000000   \n",
       "rec.sport.hockey          0.007178  0.057966  0.000000  0.000000  0.000000   \n",
       "sci.crypt                 0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "sci.electronics           0.000492  0.000000  0.000000  0.000000  0.006378   \n",
       "sci.med                   0.000000  0.000000  0.000900  0.000000  0.000000   \n",
       "sci.space                 0.026780  0.000000  0.000000  0.000000  0.000000   \n",
       "soc.religion.christian    0.008090  0.010245  0.000000  0.006528  0.005192   \n",
       "talk.politics.guns        0.135704  0.000000  0.217073  0.000000  0.000000   \n",
       "talk.politics.mideast     0.000000  0.000000  0.000000  0.038932  0.005279   \n",
       "talk.politics.misc        0.027812  0.000000  0.000000  0.004852  0.003961   \n",
       "talk.religion.misc        0.000000  0.000000  0.000000  0.009120  0.000000   \n",
       "\n",
       "                                5         6         7         8         9   \\\n",
       "label                                                                        \n",
       "alt.atheism               0.010014  0.000491  0.000000  0.000000  0.000000   \n",
       "comp.graphics             0.000000  0.000000  0.003670  0.000000  0.012231   \n",
       "comp.os.ms-windows.misc   0.000000  0.000000  0.002893  0.057188  0.007003   \n",
       "comp.sys.ibm.pc.hardware  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "comp.sys.mac.hardware     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "comp.windows.x            0.000000  0.000000  0.000000  0.006685  0.000000   \n",
       "misc.forsale              0.000000  0.086419  0.000000  0.007352  0.000000   \n",
       "rec.autos                 0.000000  0.000000  0.030260  0.000000  0.000000   \n",
       "rec.motorcycles           0.000000  0.003660  0.000000  0.000000  0.000000   \n",
       "rec.sport.baseball        0.000000  0.009396  0.000000  0.042552  0.012623   \n",
       "rec.sport.hockey          0.000000  0.000000  0.000000  0.044383  0.020401   \n",
       "sci.crypt                 0.000000  0.059774  0.022716  0.011545  0.000000   \n",
       "sci.electronics           0.000000  0.007209  0.035532  0.000000  0.000000   \n",
       "sci.med                   0.071784  0.000000  0.000000  0.000000  0.000000   \n",
       "sci.space                 0.000000  0.000000  0.000000  0.000000  0.534881   \n",
       "soc.religion.christian    0.000000  0.000000  0.000000  0.012259  0.018644   \n",
       "talk.politics.guns        0.061471  0.334120  0.000000  0.000000  0.000000   \n",
       "talk.politics.mideast     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "talk.politics.misc        0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "talk.religion.misc        0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                            ...           50        51        52        53  \\\n",
       "label                       ...                                              \n",
       "alt.atheism                 ...     0.000000  0.000000  0.001455  0.000000   \n",
       "comp.graphics               ...     0.000000  0.000000  0.000000  0.000000   \n",
       "comp.os.ms-windows.misc     ...     0.000000  0.015903  0.000000  0.000000   \n",
       "comp.sys.ibm.pc.hardware    ...     0.000000  0.000000  0.109778  0.000000   \n",
       "comp.sys.mac.hardware       ...     0.000000  0.000000  0.000000  0.000000   \n",
       "comp.windows.x              ...     0.003866  0.000000  0.000000  0.002701   \n",
       "misc.forsale                ...     0.005670  0.048850  0.579381  0.000000   \n",
       "rec.autos                   ...     0.000000  0.000000  0.000000  0.000000   \n",
       "rec.motorcycles             ...     0.000000  0.000000  0.067102  0.000000   \n",
       "rec.sport.baseball          ...     0.000000  0.000000  0.000000  0.000000   \n",
       "rec.sport.hockey            ...     0.028229  0.038843  0.032829  0.000000   \n",
       "sci.crypt                   ...     0.000000  0.168861  0.018223  0.000000   \n",
       "sci.electronics             ...     0.000000  0.134462  0.033779  0.012454   \n",
       "sci.med                     ...     0.000000  0.000000  0.000000  0.000000   \n",
       "sci.space                   ...     0.001837  0.000000  0.000000  0.000000   \n",
       "soc.religion.christian      ...     0.000000  0.000000  0.078329  0.000000   \n",
       "talk.politics.guns          ...     0.000000  0.000000  0.000000  0.000000   \n",
       "talk.politics.mideast       ...     0.000000  0.000000  0.000000  0.000000   \n",
       "talk.politics.misc          ...     0.000000  0.000000  0.022432  0.000000   \n",
       "talk.religion.misc          ...     0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                54        55        56        57        58  \\\n",
       "label                                                                        \n",
       "alt.atheism               0.000000  0.000000  0.434272  0.000000  0.003139   \n",
       "comp.graphics             0.034581  0.000000  0.005427  0.003008  0.033312   \n",
       "comp.os.ms-windows.misc   0.000000  0.000000  0.000000  0.059286  0.000000   \n",
       "comp.sys.ibm.pc.hardware  0.000000  0.034120  0.000000  0.000000  0.017412   \n",
       "comp.sys.mac.hardware     0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "comp.windows.x            0.000000  0.013505  0.000000  0.014806  0.367371   \n",
       "misc.forsale              0.000000  0.007527  0.009420  0.000000  0.083633   \n",
       "rec.autos                 0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "rec.motorcycles           0.000000  0.000000  0.002896  0.000000  0.104846   \n",
       "rec.sport.baseball        0.000000  0.675968  0.000000  0.000000  0.000000   \n",
       "rec.sport.hockey          0.000000  0.000000  0.017458  0.002639  0.000000   \n",
       "sci.crypt                 0.001284  0.000000  0.000000  0.002301  0.141698   \n",
       "sci.electronics           0.000000  0.000000  0.000000  0.000000  0.007737   \n",
       "sci.med                   0.000000  0.000000  0.000000  0.000000  0.012459   \n",
       "sci.space                 0.000000  0.003723  0.000000  0.000000  0.049695   \n",
       "soc.religion.christian    0.000000  0.000000  0.000000  0.000000  0.055271   \n",
       "talk.politics.guns        0.000000  0.000000  0.000000  0.000000  0.023017   \n",
       "talk.politics.mideast     0.000000  0.000000  0.000000  0.090331  0.325750   \n",
       "talk.politics.misc        0.018021  0.000000  0.009741  0.000000  0.283583   \n",
       "talk.religion.misc        0.000000  0.000490  0.000000  0.001880  0.198373   \n",
       "\n",
       "                                59  \n",
       "label                               \n",
       "alt.atheism               0.000000  \n",
       "comp.graphics             0.019869  \n",
       "comp.os.ms-windows.misc   0.000000  \n",
       "comp.sys.ibm.pc.hardware  0.000000  \n",
       "comp.sys.mac.hardware     0.000000  \n",
       "comp.windows.x            0.019263  \n",
       "misc.forsale              0.001053  \n",
       "rec.autos                 0.000000  \n",
       "rec.motorcycles           0.000000  \n",
       "rec.sport.baseball        0.001574  \n",
       "rec.sport.hockey          0.000000  \n",
       "sci.crypt                 0.000000  \n",
       "sci.electronics           0.288122  \n",
       "sci.med                   0.000000  \n",
       "sci.space                 0.032267  \n",
       "soc.religion.christian    0.000000  \n",
       "talk.politics.guns        0.000000  \n",
       "talk.politics.mideast     0.000000  \n",
       "talk.politics.misc        0.000000  \n",
       "talk.religion.misc        0.000000  \n",
       "\n",
       "[20 rows x 60 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf, td_norm = apply_nmf(train_data, random_state=check_random_state(0))\n",
    "\n",
    "# We use a DataFrame to simplify the collecting of the data for display.\n",
    "df = pd.DataFrame(td_norm)\n",
    "df.fillna(value=0, inplace=True)\n",
    "df['label'] = pd.Series(train['target_names'], dtype=\"category\")\n",
    "\n",
    "df.groupby('label').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b19231929eda937cec95f6c5bdd8da7d",
     "grade": true,
     "grade_id": "apply_nmf_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(nmf, NMF)\n",
    "assert_is_instance(td_norm, np.ndarray)\n",
    "assert_equal(nmf.n_components, 60)\n",
    "assert_equal(nmf.max_iter, 200)\n",
    "assert_equal(td_norm.shape, (11314, 60))\n",
    "assert_array_almost_equal(\n",
    "    td_norm[0, :5],\n",
    "    [0.        ,  0.00421649,  0.        ,  0.120597  ,  0.00141566]\n",
    "    )\n",
    "assert_array_almost_equal(\n",
    "    td_norm[-1, -5:],\n",
    "    [ 0.05955216,  0.        ,  0.00094186,  0.        ,  0.06290102]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "611cafc53e947fa1dddb9dd3fc6dfadd",
     "grade": false,
     "grade_id": "mardkwon_4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Topic-based Classification\n",
    "\n",
    "- Train a Random Forest classifier on the topics in the training data sample of the twenty newsgroup data set.\n",
    "- Use default parameters for the random forest classifier. Don't forget to set the `random_state` parameter.\n",
    "- Compute the topics, by using the previously created NMF model, for the test data and compute classifications from these topic models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "28b3804dfe1b863bc9dd57062b2f400c",
     "grade": false,
     "grade_id": "classify_topics_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def classify_topics(nmf, X_train, y_train, X_test, random_state):\n",
    "    '''\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    nmf: An sklearn.NMF model.\n",
    "    X_train: A numpy array.\n",
    "    y_train: A numpy array.\n",
    "    X_test: A scipy csr_matrix.\n",
    "    random_state: A RandomState instance for Random Forest Classifier.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (clf, y_pred)\n",
    "    clf: A RandomForestClassifier instance.\n",
    "    y_pred: A numpy array.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    clf = RandomForestClassifier(random_state=random_state).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(nmf.transform(X_test))\n",
    "    \n",
    "    return clf, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "23c2e6fe8c633a0f8a8d7d40fd8faa4a",
     "grade": false,
     "grade_id": "markdown_5",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The resulting classification report and confusion matrix are shown to demonstrate the quality of this classification method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c99f938210b1f9448cbbc735244c7d28",
     "grade": false,
     "grade_id": "classify_topics_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.26      0.34      0.29       319\n",
      "           comp.graphics       0.38      0.52      0.44       389\n",
      " comp.os.ms-windows.misc       0.45      0.47      0.46       394\n",
      "comp.sys.ibm.pc.hardware       0.47      0.49      0.48       392\n",
      "   comp.sys.mac.hardware       0.52      0.51      0.52       385\n",
      "          comp.windows.x       0.62      0.57      0.59       395\n",
      "            misc.forsale       0.73      0.69      0.71       390\n",
      "               rec.autos       0.42      0.66      0.52       396\n",
      "         rec.motorcycles       0.66      0.62      0.64       398\n",
      "      rec.sport.baseball       0.52      0.52      0.52       397\n",
      "        rec.sport.hockey       0.65      0.61      0.63       399\n",
      "               sci.crypt       0.66      0.59      0.62       396\n",
      "         sci.electronics       0.38      0.31      0.34       393\n",
      "                 sci.med       0.61      0.56      0.58       396\n",
      "               sci.space       0.63      0.60      0.62       394\n",
      "  soc.religion.christian       0.54      0.66      0.59       398\n",
      "      talk.politics.guns       0.50      0.51      0.51       364\n",
      "   talk.politics.mideast       0.80      0.67      0.73       376\n",
      "      talk.politics.misc       0.27      0.19      0.22       310\n",
      "      talk.religion.misc       0.16      0.06      0.08       251\n",
      "\n",
      "             avg / total       0.52      0.52      0.52      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf, ts_preds = classify_topics(\n",
    "    nmf, nmf.transform(train_data), train['target'], test_data, check_random_state(0)\n",
    "    )\n",
    "print(classification_report(test['target'], ts_preds, target_names=test['target_names']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "77a6ea4ce316f11e02281be410cccdfd",
     "grade": true,
     "grade_id": "classify_topics_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(clf, RandomForestClassifier)\n",
    "assert_is_instance(ts_preds, np.ndarray)\n",
    "assert_equal(len(ts_preds), len(test['target']))\n",
    "assert_array_equal(ts_preds[:5], [8, 1, 16, 15, 6])\n",
    "assert_array_equal(ts_preds[-5:], [7, 9, 3, 1, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7f851ecfea4ac3fe4befe936948cb928",
     "grade": false,
     "grade_id": "markdown_6",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Topic Modeling with Gensim\n",
    "\n",
    "- Use the gensim library to perform topic modeling of the twenty newsgroup data. First transform a sparse matrix into a gensim corpus, and then construct a vocabulary dictionary. Finally, create a  Latent Dirichlet allocation (LDA) model with 20 topics for the newsgroup text, and return 5 most significant words for each topic.\n",
    "- You should specify three parameters in `LdaModel()`: `corpus`, `id2word`, and `num_topics`. Use default values for all other paramters. Ignore any warnings about `passes` or `iterations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "385f5d7f073cbf54b7205c1b9b6f2a46",
     "grade": false,
     "grade_id": "get_topics_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_topics(cv, train_data):\n",
    "    '''\n",
    "    Uses gensim to perform topic modeling.\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    cv: A TfidfVectorizer instance.\n",
    "    train_data: A scipy csr_matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of strings (functions of the most important terms in each topic).\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    td_gensim = Sparse2Corpus(train_data)\n",
    "    \n",
    "    tmp_dct = dict((idv, word) for word, idv in cv.vocabulary_.items())\n",
    "    dct = Dictionary.from_corpus(td_gensim, id2word=tmp_dct)\n",
    "    \n",
    "    lda_gs = LdaModel(corpus=td_gensim, id2word=dct, num_topics=20)\n",
    "    \n",
    "    topics = lda_gs.top_topics(corpus=td_gensim, num_words=5)\n",
    "    \n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a59f5f881e6e96f699813e444c0ba77d",
     "grade": false,
     "grade_id": "get_topics_run",
     "locked": true,
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "-----------------------------------\n",
      "    franchises          : 0.0009\n",
      "    386sx               : 0.0009\n",
      "    373                 : 0.0008\n",
      "    clutch              : 0.0008\n",
      "    announcing          : 0.0008\n",
      "-----------------------------------\n",
      "Topic 1\n",
      "-----------------------------------\n",
      "    macx                : 0.0034\n",
      "    health insurance    : 0.0033\n",
      "    graeme              : 0.0033\n",
      "    jpwu45              : 0.0032\n",
      "    coptic church       : 0.0032\n",
      "-----------------------------------\n",
      "Topic 2\n",
      "-----------------------------------\n",
      "    lineup              : 0.0073\n",
      "    loosely             : 0.0057\n",
      "    11th                : 0.0055\n",
      "    0t                  : 0.0054\n",
      "    cpsr                : 0.0052\n",
      "-----------------------------------\n",
      "Topic 3\n",
      "-----------------------------------\n",
      "    kingdom heaven      : 0.0017\n",
      "    bread               : 0.0017\n",
      "    9y                  : 0.0017\n",
      "    anti semitic        : 0.0016\n",
      "    claremont           : 0.0016\n",
      "-----------------------------------\n",
      "Topic 4\n",
      "-----------------------------------\n",
      "    ivy league          : 0.0022\n",
      "    kirk                : 0.0021\n",
      "    bad people          : 0.0021\n",
      "    ftp machines        : 0.0021\n",
      "    504                 : 0.0019\n",
      "-----------------------------------\n",
      "Topic 5\n",
      "-----------------------------------\n",
      "    accidentally        : 0.0024\n",
      "    brutally            : 0.0024\n",
      "    hw                  : 0.0022\n",
      "    investigated        : 0.0022\n",
      "    exhaustive          : 0.0022\n",
      "-----------------------------------\n",
      "Topic 6\n",
      "-----------------------------------\n",
      "    441                 : 0.0050\n",
      "    lethal              : 0.0047\n",
      "    hardware            : 0.0046\n",
      "    747                 : 0.0042\n",
      "    injector            : 0.0042\n",
      "-----------------------------------\n",
      "Topic 7\n",
      "-----------------------------------\n",
      "    foley               : 0.0047\n",
      "    flawless            : 0.0043\n",
      "    like                : 0.0042\n",
      "    lou                 : 0.0042\n",
      "    communist party     : 0.0041\n",
      "-----------------------------------\n",
      "Topic 8\n",
      "-----------------------------------\n",
      "    israelites          : 0.0038\n",
      "    calmed              : 0.0034\n",
      "    leaf                : 0.0033\n",
      "    195                 : 0.0033\n",
      "    absurd              : 0.0032\n",
      "-----------------------------------\n",
      "Topic 9\n",
      "-----------------------------------\n",
      "    jobs summer         : 0.0050\n",
      "    did good            : 0.0046\n",
      "    24 bits             : 0.0045\n",
      "    603                 : 0.0044\n",
      "    examples            : 0.0044\n",
      "-----------------------------------\n",
      "Topic 10\n",
      "-----------------------------------\n",
      "    eternal damnation   : 0.0058\n",
      "    breakers            : 0.0046\n",
      "    diagrams            : 0.0045\n",
      "    206                 : 0.0044\n",
      "    buddhism            : 0.0043\n",
      "-----------------------------------\n",
      "Topic 11\n",
      "-----------------------------------\n",
      "    economic growth     : 0.0041\n",
      "    b8f mr              : 0.0038\n",
      "    buf bufsiz          : 0.0035\n",
      "    latest              : 0.0034\n",
      "    camps               : 0.0034\n",
      "-----------------------------------\n",
      "Topic 12\n",
      "-----------------------------------\n",
      "    284                 : 0.0037\n",
      "    beers               : 0.0032\n",
      "    entry title         : 0.0032\n",
      "    extending           : 0.0031\n",
      "    encrypting          : 0.0031\n",
      "-----------------------------------\n",
      "Topic 13\n",
      "-----------------------------------\n",
      "    caere               : 0.0055\n",
      "    carried             : 0.0047\n",
      "    bolshevik           : 0.0045\n",
      "    argentina           : 0.0043\n",
      "    clinton             : 0.0042\n",
      "-----------------------------------\n",
      "Topic 14\n",
      "-----------------------------------\n",
      "    kth se              : 0.0062\n",
      "    deal                : 0.0054\n",
      "    hull                : 0.0046\n",
      "    3169                : 0.0046\n",
      "    homework            : 0.0045\n",
      "-----------------------------------\n",
      "Topic 15\n",
      "-----------------------------------\n",
      "    30 20               : 0.0048\n",
      "    headaches           : 0.0046\n",
      "    iftccu talk         : 0.0044\n",
      "    catalog             : 0.0044\n",
      "    converts            : 0.0042\n",
      "-----------------------------------\n",
      "Topic 16\n",
      "-----------------------------------\n",
      "    005                 : 0.0053\n",
      "    100mhz              : 0.0045\n",
      "    jmd                 : 0.0044\n",
      "    cs utah             : 0.0043\n",
      "    bombers             : 0.0043\n",
      "-----------------------------------\n",
      "Topic 17\n",
      "-----------------------------------\n",
      "    _q                  : 0.0060\n",
      "    canon               : 0.0056\n",
      "    labour              : 0.0054\n",
      "    follower            : 0.0051\n",
      "    1w                  : 0.0048\n",
      "-----------------------------------\n",
      "Topic 18\n",
      "-----------------------------------\n",
      "    held responsible    : 0.0043\n",
      "    218                 : 0.0042\n",
      "    anytime             : 0.0038\n",
      "    ingres              : 0.0038\n",
      "    119                 : 0.0037\n",
      "-----------------------------------\n",
      "Topic 19\n",
      "-----------------------------------\n",
      "    decoder             : 0.0071\n",
      "    jsc nasa            : 0.0068\n",
      "    abolished           : 0.0064\n",
      "    coupe               : 0.0062\n",
      "    gordon              : 0.0061\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "topics = get_topics(cv, train_data)\n",
    "\n",
    "for idx, (lst, val) in enumerate(topics):\n",
    "    print('Topic {0}'.format(idx))\n",
    "    print(35*('-'))\n",
    "    for i, z in lst:\n",
    "        print('    {0:20s}: {1:5.4f}'.format(z, i))\n",
    "    print(35*('-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a9979dc296f99568d488105aa65a8bdb",
     "grade": true,
     "grade_id": "get_topics_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(topics, list)\n",
    "assert_equal(len(topics), 20)\n",
    "\n",
    "for topic, score in topics:\n",
    "    assert_is_instance(topic, list)\n",
    "    assert_is_instance(score, float)\n",
    "    assert_equal(len(topic), 5)\n",
    "    for v, k in topic:\n",
    "        assert_is_instance(k, str)\n",
    "        assert_is_instance(v, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

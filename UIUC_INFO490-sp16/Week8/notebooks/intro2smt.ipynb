{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<DIV ALIGN=CENTER>\n",
    "\n",
    "# Introduction to Social Media: Twitter\n",
    "## Professor Robert J. Brunner\n",
    "  \n",
    "</DIV>  \n",
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "When looking for data to use for text data processing, one of the more\n",
    "popular data sources is [Twitter][tw]. In this Notebook, we introduce\n",
    "the Twitter API, and demonstrate how to use the Twitter API from within\n",
    "a Python gram to acquire and process tweets, or Twitter messages. First,\n",
    "we review the mechanisms by which an application authenticates with\n",
    "Twitter. Next, we discuss different techniques for interacting with the\n",
    "twitter data stream by using the twitter API. Finally, we construct a\n",
    "tweet sentiment analysis pipeline before applying this pipeline to new\n",
    "tweets from a specific user.\n",
    "\n",
    "-----\n",
    "[tw]: https://www.twitter.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python and Twitter\n",
    "\n",
    "To work with the Twitter API from within a Python program, we need a\n",
    "Python library that wraps the official [Twitter API][twapi]. There are a\n",
    "number of different Python libraries that provide this capability, we\n",
    "will use the [tweepy][tpy] library, which is fairly popular and provides\n",
    "a fairly complete interface.\n",
    "\n",
    "The full Twitter API is large and robust (and continuous to evolve),\n",
    "for this course we will restrict our attention to several basic\n",
    "concepts, namely authenticating to Twitter, searching for Tweets, and\n",
    "digesting the messages.\n",
    "\n",
    "----\n",
    "[twapi]: https://dev.twitter.com\n",
    "[tpy]: http://www.tweepy.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tweepy as tw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-----\n",
    "\n",
    "## Reading Twitter Data\n",
    "\n",
    "To read twitter data, you need to first need to be a registered Twitter\n",
    "user and you need to create a new _Twitter Application_ in order to\n",
    "obtain credentials for connecting to Twitter and querying to the\n",
    "Twitter data. You create (and later manage) Twitter applications by\n",
    "visting the [Twitter Application Management](https://apps.twitter.com)\n",
    "website.\n",
    "\n",
    "![Twitter App Sign-in](images/twitter-app-signin.png)\n",
    "\n",
    "At this point you need to authenticate with Twitter, if you are already\n",
    "logged in to Twitter on your computer (for instance by using the Twitter\n",
    "website) you should already be authenticated. If you are not\n",
    "authenticated, click the _sign in_ link to be directed to the Twitter\n",
    "signin page where you can enter your credentials (if you do not have\n",
    "Twitter credentials, you will need to obtain a Twitter account to\n",
    "proceed).\n",
    "\n",
    "![Twitter Sign-in](images/twitter-signin.png)\n",
    "\n",
    "After you have been authenticated, you will be redirected to the Twitter\n",
    "apps page. If you have never created a Twitter application, you will\n",
    "have nothing listed. To create a new application, press the _Create New\n",
    "App_ button, as shown in the following screenshot.\n",
    "\n",
    "![Twitter Create App](images/twitter-create.png)\n",
    "\n",
    "This will open up the Twitter _Create an application_ webpage, where you\n",
    "need to supply some basic information for your Twitter application such\n",
    "as an application name, description, and website.\n",
    "\n",
    "![Twitter Application details](images/twitter-appdetails.png)\n",
    "\n",
    "Scroll to the bottom of this webpage where the **Developer Agreement**\n",
    "is located. Following this agreement, is a check box that you should\n",
    "click to signify you agree to be bound by the agreement (of course you\n",
    "should read this to be sure you do _agree_ with it first). Following\n",
    "this, press the _Create your Twitter application_ button as shown in the\n",
    "following screenshot.\n",
    "\n",
    "![Twitter Agree](images/twitter-agree.png)\n",
    "\n",
    "This will create your new application, and provide you with your\n",
    "application webpage, which will be similar to the following screenshot.\n",
    "\n",
    "![Twitter Apppage](images/twitter-apppage.png)\n",
    "\n",
    "While you can control a number of application features from this\n",
    "webpage, the most important tasks to complete include:\n",
    "\n",
    "1. Change your application to _read-only_ in case it is set to\n",
    "read-write.\n",
    "\n",
    "2. Obtain the application **Consumer Key** and **Consumer Secret**.\n",
    "\n",
    "3. Obtain your personal **Access Token** and **Access Token Secret**.\n",
    "\n",
    "You should change your application read-only to ensure you don't\n",
    "accidentally send data out to Twitter. You change this by selecting the\n",
    "_Permissions_ tab and selecting _Read only_, shown in the following\n",
    "screenshot. To save this setting, scroll down this webpage and click the\n",
    "_Update Settings_ button at the bottom of the page.\n",
    "\n",
    "![Twitter Read Only Setting](images/twitter-ro.png)\n",
    "\n",
    "These credentials can be found by selecting the _Keys and Access Tokens_\n",
    "tab, and scrolling down appropriately as shown in the following two\n",
    "screenshots.\n",
    "\n",
    "![Twitter Consumer Application Credentials](images/twitter-consume.png)\n",
    "\n",
    "![Twitter User Credentials](images/twitter-access.png)\n",
    "\n",
    "<font color='red'>Warning: Never share these credentials with others or\n",
    "they will be able to fully impersonate you on Twitter!</font>\n",
    "\n",
    "You can directly copy these credentials into your Notebook, or,\n",
    "alternatively, save them into a file (for example by opening a terminal\n",
    "window and using `vim` to create a text file. In the rest of this\n",
    "Notebook, I demonstrate this functionality by using my credentials,\n",
    "which I have saved into a file called`twitter.cred'. In this empty file,\n",
    "which is in your github repository, I have saved the following four\n",
    "credentials in order:\n",
    "\n",
    "1. Access Token\n",
    "2. Access Token Secret\n",
    "3. Consumer Key\n",
    "4. Consumer Secret\n",
    "\n",
    "You can inform `git` to ignore changes in the `twitter.cred` file by\n",
    "using the folloqing command:\n",
    "\n",
    "```bash\n",
    "git update-index --assume-unchanged Week8/notebooks/twitter.cred \n",
    "```\n",
    "\n",
    "The following code cell demonstrates how these credentials are read from\n",
    "the file and used to properly authenticate our application with Twitter.\n",
    "\n",
    "-----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter Screen Name:  ProfBrunner\n",
      "Twitter Follower Count:  149\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "\n",
    "# Order: Access Token, Access Token Secret, Consumer Key, Consumer SecretAccess\n",
    "\n",
    "with open(\"twitter.cred\", 'r') as fin:\n",
    "    for line in fin:\n",
    "        if line[0] != '#': # Not a comment line\n",
    "            tokens.append(line.rstrip('\\n'))\n",
    "\n",
    "auth = tw.OAuthHandler(tokens[2], tokens[3])\n",
    "auth.set_access_token(tokens[0], tokens[1])\n",
    "\n",
    "api = tw.API(auth)\n",
    "\n",
    "user = api.me()\n",
    "\n",
    "print(\"Twitter Screen Name: \", user.screen_name)\n",
    "print(\"Twitter Follower Count: \", user.followers_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "If the previous code cell runs without an error, you have successfully\n",
    "connected to twitter. If you are new to twitter and are not following\n",
    "anyone, you can instead display the user information for a different\n",
    "Twitter user. For example, the following code would display my Twitter\n",
    "information.\n",
    "\n",
    "```python\n",
    "user = api.get_user('ProfBrunner')\n",
    "```\n",
    "\n",
    "Replacing `ProfBrunner` with any valid Twitter user id will display\n",
    "their information. You can find examples by looking at those Twitter\n",
    "users you (or `ProfBrunner`) follow. Or, alternatively, you could chose\n",
    "a specific twitter account; for example, to analyze the _NY Times_\n",
    "twitter account you would use the following statement:\n",
    "\n",
    "```python\n",
    "user = api.get_user('NYTimes')\n",
    "```\n",
    "\n",
    "This is demonstrated in the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter Screen Name:  nytimes\n",
      "Twitter Follower Count:  25167044\n",
      "\n",
      "This user follows:\n",
      "--------------\n",
      "emrosenberg\n",
      "azamsahmed\n",
      "BenWeiserNYT\n",
      "Wesley_Morris\n",
      "Yamiche\n",
      "ChanellePrice\n",
      "TwitterMoments\n",
      "poniewozik\n",
      "thunderwooddd\n",
      "migold\n",
      "timrace\n",
      "NYT_IR\n",
      "SciFleur\n",
      "geminiimatt\n",
      "mbeditor\n",
      "gregfwinter\n",
      "meredith_levien\n",
      "mmcintire\n",
      "mccarthyryanj\n",
      "MikaylaBouchard\n"
     ]
    }
   ],
   "source": [
    "user = api.get_user('nytimes')\n",
    "\n",
    "print(\"Twitter Screen Name: \", user.screen_name)\n",
    "print(\"Twitter Follower Count: \", user.followers_count)\n",
    "\n",
    "print(\"\\nThis user follows:\\n--------------\")\n",
    "for friend in user.friends():\n",
    "    print(friend.screen_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At any point, you can return to your Twitter application management\n",
    "webpage to view your new application. You can now view and manage your\n",
    "existing application, or create a new application as shown in the\n",
    "following screenshot.\n",
    "\n",
    "![Twitter new app management](images/twitter-manage.png)\n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Student Activity\n",
    "\n",
    "To run the Twitter application in the preceding cells, you will need to register your own Twitter Application. To do so, complete the following steps.\n",
    "\n",
    "1. Create a New Twitter application.\n",
    "\n",
    "2. Save your Twitter credentials and Application credentials into the\n",
    "provided `twitter.cred` file.\n",
    "\n",
    "3. Run the _tweepy_ sample code to connect to Twitter and display your\n",
    "Twitter user information.\n",
    "\n",
    "Finally, try running the preceding code, but for someone famous (if you do not know the twitter handle for someone famous, google will be your friend). \n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Tweets\n",
    "\n",
    "Once you have authenticated with Twitter, you can begin to [search the\n",
    "Twitter stream][stw] for tweets of interest. The easiest method to get started\n",
    "is to being with your own (or another specific Twitter user's) own\n",
    "Twitter feed. To access your own Twitter feed, you can simply use your\n",
    "`home_timeline` to retrieve your own Tweets or Tweets from those whom\n",
    "you follow. This is demonstrated in the following code cell, where we\n",
    "display the `text` values from the ten most recent Tweets from our\n",
    "timeline.\n",
    "\n",
    "-----\n",
    "[stw]: https://dev.twitter.com/rest/public/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In other words, it's a really good result for Cruz, but also somewhere we might expect him to do relatively well.\n",
      "FWIW, Waldo County, Maine, which Cruz apparently won big, was more favorable to Paul and Santorum in 2012 than the state average.\n",
      "RT @AERatterree: @realDonaldTrump Waldo Co. #Maine #MEGOPcaucus result #Trump2016☑ #MEpolitics\n",
      "\n",
      "Cruz 356\n",
      "Trump 220\n",
      "Kasich 75\n",
      "Rubio 54 https…\n",
      "RT @johnmyleswhite: The problems with NHST are largely the problems of applying any technique that makes strong assumptions that end users …\n",
      "People are underestimating the importance of Illinois &amp; Missouri on Mar. 15, which are winner-take-most states.\n",
      "Kansas, Kentucky, Louisiana and Maine are not just four states in alphabetical order. They're also voting today. https://t.co/fPdHRJK8QI\n",
      "University of Illinois Research Park Aerial Tour, take a tour with a drone filmed video @uiresearchpark https://t.co/pdFcs1NsFJ via @YouTube\n",
      "RT @fstonenyc: The data strongly suggest that USA Today and Universal have been ripping off the NYT crossword puzzle for years. https://t.c…\n",
      "USA Today has probably been plagiarizing crossword puzzles from The New York Times. https://t.co/gybFb1pGdl\n",
      "RT @ollie: a plagiarism scandal is unfolding in the crossword world. our scoop: https://t.co/ESGdwQ9wv2 https://t.co/3tEj9Guj6l\n"
     ]
    }
   ],
   "source": [
    "for tweet in tw.Cursor(api.home_timeline).items(10):\n",
    "    # Process a single status\n",
    "    print(tweet.text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Searching\n",
    "\n",
    "Twitter also provides the capability to search for specific tweets by\n",
    "using the Tweepy [`search` method][twse]. In this method, you supply a\n",
    "query string (and optional arguments) and are returned a list of Tweets.\n",
    "The query string should follow the [Twitter Search API][tsa], but\n",
    "basically you can search for specific text in a string by using the text\n",
    "of interest, you can search for a person by using the `@` character\n",
    "followed by their Twitter username, and hashtags by using the `#`\n",
    "character followed by the tag text.\n",
    "\n",
    "-----\n",
    "\n",
    "[twse]: http://docs.tweepy.org/en/stable/api.html#API.search\n",
    "[tsa]: https://dev.twitter.com/rest/public/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet ID: 706101392902135808\n",
      "Tweeted by  wmdogar\n",
      "Created at  2016-03-05 12:57:45\n",
      "Location:  Twitter Web Client\n",
      "Tweet Text:  RT @ddalyie: Interesting and provocative as ever  Desmond Brennan , if a tad more wackier than usual :-) https://t.co/ZYexfbQpN3\n",
      "-------------------------\n",
      "Tweet ID: 706093281185275908\n",
      "Tweeted by  jeshir99\n",
      "Created at  2016-03-05 12:25:31\n",
      "Location:  Twitter for iPhone\n",
      "Tweet Text:  RT @ddalyie: Interesting and provocative as ever  Desmond Brennan , if a tad more wackier than usual :-) https://t.co/ZYexfbQpN3\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hash Tage search: term = '#python'\n",
    "# User search: term = '@nytimes'\n",
    "# Keyword search: term = 'data science'\n",
    "# Keyword and Sentiment: term ='data science :)' # Positive attitute\n",
    "\n",
    "term ='data science :)'\n",
    "num_tweets = 5\n",
    "\n",
    "for tweet in tw.Cursor(api.search, q=term).items(num_tweets):\n",
    "    # Process a single status\n",
    "    print(\"Tweet ID:\", tweet.id)\n",
    "    print('Tweeted by ', tweet.user.screen_name)\n",
    "    print(\"Created at \",tweet.created_at)\n",
    "    print(\"Location: \",tweet.source)\n",
    "    print('Tweet Text: ', tweet.text)\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "We can view the available attributes to display by using Python `dir`\n",
    "method to perform introspection. In the following code cell we\n",
    "explicitly remove _class_ methods to minimize the display list and focus\n",
    "on the items of interest. After this, we display the Tweet in its raw\n",
    "JSON format by accessing the `_json` attribute.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ '_max_id', '_since_id', 'append', 'clear', 'completed_in', 'copy', 'count',\n",
      "  'extend', 'ids', 'index', 'insert', 'max_id', 'next_results', 'parse', 'pop',\n",
      "  'query', 'refresh_url', 'remove', 'reverse', 'since_id', 'sort']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2, depth=2, width=80, compact=True)\n",
    "\n",
    "tweets = api.search(q='ProfBrunner', rpp=1)\n",
    "\n",
    "pp.pprint([att for att in dir(tweets) if '__' not in att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ '_api', '_json', 'author', 'contributors', 'coordinates', 'created_at',\n",
      "  'destroy', 'entities', 'favorite', 'favorite_count', 'favorited', 'geo', 'id',\n",
      "  'id_str', 'in_reply_to_screen_name', 'in_reply_to_status_id',\n",
      "  'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str',\n",
      "  'is_quote_status', 'lang', 'metadata', 'parse', 'parse_list', 'place',\n",
      "  'retweet', 'retweet_count', 'retweeted', 'retweets', 'source', 'source_url',\n",
      "  'text', 'truncated', 'user']\n"
     ]
    }
   ],
   "source": [
    "# Pick a single tweet to analyze\n",
    "\n",
    "tweet = tweets[1]\n",
    "pp.pprint([att for att in dir(tweet) if '__' not in att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'contributors': None,\n",
      "  'coordinates': None,\n",
      "  'created_at': 'Sun Feb 28 22:54:23 +0000 2016',\n",
      "  'entities': {'hashtags': [], 'symbols': [], 'urls': [], 'user_mentions': []},\n",
      "  'favorite_count': 6,\n",
      "  'favorited': False,\n",
      "  'geo': None,\n",
      "  'id': 704077214724333569,\n",
      "  'id_str': '704077214724333569',\n",
      "  'in_reply_to_screen_name': None,\n",
      "  'in_reply_to_status_id': None,\n",
      "  'in_reply_to_status_id_str': None,\n",
      "  'in_reply_to_user_id': None,\n",
      "  'in_reply_to_user_id_str': None,\n",
      "  'is_quote_status': False,\n",
      "  'lang': 'en',\n",
      "  'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
      "  'place': None,\n",
      "  'retweet_count': 2,\n",
      "  'retweeted': False,\n",
      "  'source': '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web '\n",
      "            'Client</a>',\n",
      "  'text': 'I received an interesting email today, it started off:\\n'\n",
      "          '\\n'\n",
      "          '\"Dear Astrology Advisors,\"\\n'\n",
      "          '\\n'\n",
      "          'Never saw it coming.',\n",
      "  'truncated': False,\n",
      "  'user': { 'contributors_enabled': False,\n",
      "            'created_at': 'Wed Dec 04 20:23:34 +0000 2013',\n",
      "            'default_profile': True,\n",
      "            'default_profile_image': False,\n",
      "            'description': '',\n",
      "            'entities': {...},\n",
      "            'favourites_count': 4,\n",
      "            'follow_request_sent': False,\n",
      "            'followers_count': 149,\n",
      "            'following': False,\n",
      "            'friends_count': 16,\n",
      "            'geo_enabled': False,\n",
      "            'has_extended_profile': False,\n",
      "            'id': 2230450843,\n",
      "            'id_str': '2230450843',\n",
      "            'is_translation_enabled': False,\n",
      "            'is_translator': False,\n",
      "            'lang': 'en',\n",
      "            'listed_count': 1,\n",
      "            'location': 'The Flat Universe',\n",
      "            'name': 'Robert J. Brunner',\n",
      "            'notifications': False,\n",
      "            'profile_background_color': 'C0DEED',\n",
      "            'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
      "            'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
      "            'profile_background_tile': False,\n",
      "            'profile_image_url': 'http://pbs.twimg.com/profile_images/420327169387012096/cuhS-W0C_normal.jpeg',\n",
      "            'profile_image_url_https': 'https://pbs.twimg.com/profile_images/420327169387012096/cuhS-W0C_normal.jpeg',\n",
      "            'profile_link_color': '0084B4',\n",
      "            'profile_sidebar_border_color': 'C0DEED',\n",
      "            'profile_sidebar_fill_color': 'DDEEF6',\n",
      "            'profile_text_color': '333333',\n",
      "            'profile_use_background_image': True,\n",
      "            'protected': False,\n",
      "            'screen_name': 'ProfBrunner',\n",
      "            'statuses_count': 316,\n",
      "            'time_zone': None,\n",
      "            'url': 'http://t.co/AU8imfZzFq',\n",
      "            'utc_offset': None,\n",
      "            'verified': False}}\n"
     ]
    }
   ],
   "source": [
    "# We can display the message data in JSON format\n",
    "\n",
    "pp.pprint(tweet._json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Trending\n",
    "\n",
    "Twitter tracks tweet data to identify topics or people that are being\n",
    "frequently mentioned, which is known as [_trending_][twtr]. The Twitter\n",
    "API enables an application to obtain a list of currently trending\n",
    "topics. These topics include metadata that can be used to learn more\n",
    "about trending topics. One component of the metadata is the physical\n",
    "location of the trending topic. This location is encoded as a\n",
    "[**WOEID**][woeid], which is a Yahoo developed standard that is short\n",
    "for _where on the earth ID_. In the first code cell below, we\n",
    "demonstrate obtaining the locations of currently trending topics before\n",
    "displaying these physical locations. In the second code cell, we display\n",
    "the complete metadata for one location, which can be used to obtain a\n",
    "list of trending topics for a particular location on Earth, via the\n",
    "WOEID. Note that since trending topics change, this Notebook will\n",
    "provide different results when run at different times.\n",
    "\n",
    "----\n",
    "[twtr]: https://dev.twitter.com/rest/reference/get/trends/available\n",
    "[woeid]: https://developer.yahoo.com/geo/geoplanet/guide/concepts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOEID Code (2972): Winnipeg, Canada\n",
      "WOEID Code (3369): Ottawa, Canada\n",
      "WOEID Code (3444): Quebec, Canada\n",
      "WOEID Code (3534): Montreal, Canada\n",
      "WOEID Code (4118): Toronto, Canada\n",
      "WOEID Code (8676): Edmonton, Canada\n",
      "WOEID Code (8775): Calgary, Canada\n",
      "WOEID Code (9807): Vancouver, Canada\n",
      "WOEID Code (12723): Birmingham, United Kingdom\n",
      "WOEID Code (12903): Blackpool, United Kingdom\n",
      "WOEID Code (13383): Bournemouth, United Kingdom\n",
      "WOEID Code (13911): Brighton, United Kingdom\n",
      "WOEID Code (13963): Bristol, United Kingdom\n",
      "WOEID Code (15127): Cardiff, United Kingdom\n",
      "WOEID Code (17044): Coventry, United Kingdom\n",
      "WOEID Code (18114): Derby, United Kingdom\n",
      "WOEID Code (19344): Edinburgh, United Kingdom\n",
      "WOEID Code (21125): Glasgow, United Kingdom\n",
      "WOEID Code (25211): Hull, United Kingdom\n"
     ]
    }
   ],
   "source": [
    "# Returns a JSON object that contains (a large number of) locations \n",
    "# that are currently trending.\n",
    "\n",
    "top_display = 20\n",
    "trending = api.trends_available()\n",
    "\n",
    "# We skip first value, which is entry for the World in JSON.\n",
    "for trend in trending[1:top_display]:\n",
    "    print('WOEID Code ({2:d}): {0}, {1}'.format(trend['name'], \\\n",
    "                                                trend['country'], trend['woeid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'country': 'United Kingdom',\n",
      "  'countryCode': 'GB',\n",
      "  'name': 'Blackpool',\n",
      "  'parentid': 23424975,\n",
      "  'placeType': {'code': 7, 'name': 'Town'},\n",
      "  'url': 'http://where.yahooapis.com/v1/place/12903',\n",
      "  'woeid': 12903}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(trending[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK Trends\n",
      "----------\n",
      "  Mahrez\n",
      "  #SaturdayNightTakeaway\n",
      "  #NUFC\n",
      "  #MakeABandOrSongAboutTheUK\n",
      "  Everton\n",
      "  #AMVCA2016\n",
      "  #5daysTilDangerouswoman\n",
      "  Martinez\n",
      "  Coquelin\n",
      "  Vicarage Road\n"
     ]
    }
   ],
   "source": [
    "# We can use a WOEID to find location specific trends.\n",
    "# Here we use the WOEID for the UK (from previous example)\n",
    "\n",
    "top_display = 10\n",
    "\n",
    "print(\"UK Trends\")\n",
    "print(10*'-')\n",
    "\n",
    "for trends in api.trends_place(id = 23424975):\n",
    "    for trend in trends[\"trends\"][:top_display]:\n",
    "        print(\"  {0:s}\".format(trend[\"name\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Student Activity\n",
    "\n",
    "In the preceding cells, we used the twitter API to obtain tweets and to\n",
    "identify trending topics. Now that you have run the Notebook, try making\n",
    "the following changes.\n",
    "\n",
    "1. Pick a particular twitter user and search their twitter stream.\n",
    "2. Pick a different location from the trending topics location list, and\n",
    "identify trending topics from a different WOEID.\n",
    "\n",
    "-----\n",
    "## Twitter text analysis\n",
    "\n",
    "We can now develop a text analysis project that uses twitter data. To\n",
    "simplify the application, we will use the NLTK twitter corpus.\n",
    "Otherwise, we would need a separate notebook to obtain the necessary\n",
    "tweets (because of the twitter rate limitation). The [NLTK twitter\n",
    "corpus][ntw] includes thirty thousand tweets retrieved from the twitter\n",
    "streaming API, the data have been cached on our course JupyterHub\n",
    "server. The tweets were explicitly selected from a recent election in\n",
    "the United Kingdom and one-third of them have been classified into\n",
    "positive or negative (with equal numbers of each). With these tweets, we\n",
    "can build a classification pipeline to perform sentiment analysis on\n",
    "twitter data.\n",
    "\n",
    "In the following code cells, we first obtain the tweets, build the numpy\n",
    "arrays for our classification pipeline, before constructing and testing\n",
    "this simple sentiment analysis text analysis application.\n",
    "\n",
    "-----\n",
    "[ntw]: http://www.nltk.org/howto/twitter.html#Using-a-Tweet-Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 Positive Tweets\n",
      "5000 Negative Tweets\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "tws = nltk.corpus.twitter_samples\n",
    "\n",
    "pos_tweets = np.array(tws.strings('positive_tweets.json'))\n",
    "neg_tweets = np.array(tws.strings('negative_tweets.json'))\n",
    "\n",
    "pos_labels = np.ones(pos_tweets.shape[0])\n",
    "neg_labels = np.zeros(neg_tweets.shape[0])\n",
    "\n",
    "targets = np.concatenate((pos_labels, neg_labels), axis=0)\n",
    "data = np.concatenate((pos_tweets, neg_tweets), axis = 0)\n",
    "\n",
    "print('{0} Positive Tweets'.format(pos_tweets.shape[0]))\n",
    "print('{0} Negative Tweets'.format(neg_tweets.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "We will employ 75% of the data for training, with 25% held out for\n",
    "validation. The classification pipeline will use a simply tokenizer to\n",
    "build a document-term matrix before applying a Naive Bayes classifier.\n",
    "The tokenizer will use _English_ stop words, will convert the text to\n",
    "all lowercase, and includes both unigrams and bigrams. Overall, this\n",
    "simple classification pipeline gives reasonable results.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, targets, test_size=0.25, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Positive       0.73      0.79      0.76      1240\n",
      "   Negative       0.78      0.71      0.74      1260\n",
      "\n",
      "avg / total       0.75      0.75      0.75      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "tools = [('cv', CountVectorizer()), ('nb', MultinomialNB())]\n",
    "pclf = Pipeline(tools)\n",
    "\n",
    "\n",
    "# Lowercase, English Stop Words, and unigrams and bigrams.\n",
    "pclf.set_params(cv__stop_words = 'english', \\\n",
    "                cv__ngram_range=(1,2), \\\n",
    "                cv__lowercase=True)\n",
    "\n",
    "pclf.fit(x_train, y_train)\n",
    "y_pred = pclf.predict(x_test)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names = ['Positive', 'Negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Blind Testing\n",
    "\n",
    "We can use the remaining twenty thousand tweets in the NLTK corpus for\n",
    "blind testing. We first obtain the tweets as a numpy array, before\n",
    "applying our sentiment analysis pipeline. Finally, we display the\n",
    "relative numbers of positive and negative classifications and we display\n",
    "examples of both positive and negative classified tweets.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unknown_tweets = np.array(tws.strings('tweets.20150430-223406.json'))\n",
    "unknown_pred = pclf.predict(unknown_tweets)\n",
    "\n",
    "unknown_pos = unknown_tweets[unknown_pred == 1]\n",
    "unknown_neg = unknown_tweets[unknown_pred == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 tweets to classify.\n",
      "8508 tweets classified as positive.\n",
      "11492 tweets classified as negative.\n",
      "---------------------------------------------------------------------------\n",
      "Sample Positve Tweet:\n",
      "---------------------------------------------------------------------------\n",
      "\"David Cameron: smooth, smiley but unconvincing\" #bbcqt http://t.co/mJ2ZkX1TjB\n",
      "---------------------------------------------------------------------------\n",
      "Sample Negatve Tweet:\n",
      "---------------------------------------------------------------------------\n",
      "RT @DouglasDaniel: Miliband's new line 'if you don't vote Labour in Scotland I will punish you by letting the Tories in'.\n"
     ]
    }
   ],
   "source": [
    "tweet_idx = 101\n",
    "\n",
    "print('{0} tweets to classify.'.format(unknown_tweets.shape[0]))\n",
    "print('{0} tweets classified as positive.'.format(unknown_pos.shape[0]))\n",
    "print('{0} tweets classified as negative.'.format(unknown_neg.shape[0]))\n",
    "\n",
    "print(75*'-')\n",
    "print('Sample Positve Tweet:')\n",
    "print(75*'-')\n",
    "print(unknown_pos[tweet_idx])\n",
    "\n",
    "print(75*'-')\n",
    "print('Sample Negatve Tweet:')\n",
    "print(75*'-')\n",
    "print(unknown_neg[tweet_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Classifying new Tweets\n",
    "\n",
    "We can now combine everything covered in this notebook in order to apply\n",
    "our trained sentiment analysis pipeline on new twitter data. For this,\n",
    "we pick _random_ user, in this case CNN Political Twitter Feed (note\n",
    "this wasn't completely random. The training data was obtained from a\n",
    "similar feeds). We first obtain tweets from this user before creating\n",
    "the numpy arrays to use with our scikit learn classifier. Finally, we\n",
    "display the results of this sentiment analysis classifier. Note, since\n",
    "the tweets will change over time, the results presented in this Notebook\n",
    "will also change.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtained a sample of 95 tweets\n"
     ]
    }
   ],
   "source": [
    "newtweets = api.user_timeline(screen_name='@CNNPolitics', include_rts=False, count=100)\n",
    "                           \n",
    "print('We obtained a sample of {0} tweets'.format(len(newtweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "for tweet in newtweets:\n",
    "    messages.append(tweet.text)\n",
    "    \n",
    "new_tweets = np.array(messages)\n",
    "new_pred = pclf.predict(new_tweets)\n",
    "\n",
    "new_pos = new_tweets[new_pred == 1]\n",
    "new_neg = new_tweets[new_pred == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 tweets to classify.\n",
      "66 tweets classified as positive.\n",
      "29 tweets classified as negative.\n",
      "---------------------------------------------------------------------------\n",
      "Sample Positve Tweet:\n",
      "---------------------------------------------------------------------------\n",
      "The Obama administration plans to release a drone program \"playbook\" https://t.co/FlpD691YiW https://t.co/gyOsd8IH71\n",
      "---------------------------------------------------------------------------\n",
      "Sample Negatve Tweet:\n",
      "---------------------------------------------------------------------------\n",
      ".@MittRomney: Trump is likely the GOP nominee, but a contested convention is \"realistic\" https://t.co/jj5cS4uBbX https://t.co/YdJHLWtd4A\n"
     ]
    }
   ],
   "source": [
    "tweet_idx = 13\n",
    "\n",
    "print('{0} tweets to classify.'.format(new_tweets.shape[0]))\n",
    "print('{0} tweets classified as positive.'.format(new_pos.shape[0]))\n",
    "print('{0} tweets classified as negative.'.format(new_neg.shape[0]))\n",
    "\n",
    "print(75*'-')\n",
    "print('Sample Positve Tweet:')\n",
    "print(75*'-')\n",
    "print(new_pos[tweet_idx])\n",
    "\n",
    "print(75*'-')\n",
    "print('Sample Negatve Tweet:')\n",
    "print(75*'-')\n",
    "print(new_neg[tweet_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Student Activity\n",
    "\n",
    "In the preceding cells, we build a sentiment analysis classification\n",
    "pipeline by using the NLTK corpus before applying it to new tweets.Now\n",
    "that you have run the Notebook, try making the following changes.\n",
    "\n",
    "1. Modify the pipeline parameters, for example, apply stemming, change\n",
    "the `max_features`, or the number of n-grams. Can you improve the\n",
    "classification results on the validation data?\n",
    "\n",
    "2. Change the type of classification algorithm (e.g., random forest or\n",
    "SVC with regularization). Can you improve the classification results on\n",
    "the validation data?\n",
    "\n",
    "3. Using your new classification pipeline, examine the performance on\n",
    "the current twitter user. Look at other tweets, does the performance\n",
    "improve?\n",
    "\n",
    "4. Try classifying tweets from a different user, either an _election_\n",
    "type feed or a popular figure. By looking at select tweets and their\n",
    "classification, comment on how your classifier performs?\n",
    "\n",
    "Finally, why do you think the classification pipeline performs in the\n",
    "manner that is does (i.e., why are some tweets classified\n",
    "negative/positive)? Feel free to use the class forums.\n",
    "\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

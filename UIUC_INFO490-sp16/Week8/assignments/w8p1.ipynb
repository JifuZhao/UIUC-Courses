{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "008110cfa873947a912f27dbe067e82f",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This notebook will be collected automatically at **6pm on Monday** from `/home/data_scientist/assignments/Week8` directory on the course JupyterHub server. If you work on this assignment on the course Jupyterhub server, just make sure that you save your work and instructors will pull your notebooks automatically after the deadline. If you work on this assignment locally, the only way to submit assignments is via Jupyterhub, and you have to place the notebook file in the correct directory with the correct file name before the deadline.\n",
    "\n",
    "1. Make sure everything runs as expected. First, restart the kernel (in the menubar, select `Kernel` → `Restart`) and then run all cells (in the menubar, select `Cell` → `Run All`).\n",
    "2. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed by the autograder.\n",
    "3. Do not change the file path or the file name of this notebook.\n",
    "4. Make sure that you save your work (in the menubar, select `File` → `Save and CheckPoint`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cb39d60f94e0b9402b161812a2f4f207",
     "grade": false,
     "grade_id": "markdown_1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem 8.1. Social Media: Email\n",
    "\n",
    "In this problem, we first explore parsing a simple email, and develop a text classification pipeline from a public email corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "2395bad6e6f75d4a6ff5764853af96f5",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import email as em\n",
    "from email import policy\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_instance, assert_true\n",
    "from numpy.testing import assert_array_equal, assert_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fb9ad07c8cd07786440b413122d35475",
     "grade": false,
     "grade_id": "markdown_2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Email header\n",
    "\n",
    "- Write a function that extracts the header information (`to`, `from`, and `subject` fields) from a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "31c831405660885122a750a9425952bf",
     "grade": false,
     "grade_id": "read_header_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def read_header(filename):\n",
    "    '''\n",
    "    Extracts email header from a text file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: A string.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 3-tuple of (msg_to, msg_from, subject).\n",
    "    \n",
    "    msg_to: A string. The \"To\" field of the email header.\n",
    "    msg_from: A string. The \"From\" field.\n",
    "    subject: A string. The \"subject\".\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return msg_to, msg_from, subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7aad39d161298937c91fd7f9f0395d2c",
     "grade": false,
     "grade_id": "read_header_run_1",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "email1 = '/home/data_scientist/data/email/ham/00001.1a31cc283af0060967a233d26548a6ce'\n",
    "to1, from1, subject1 = read_header(email1)\n",
    "print('To:', to1)\n",
    "print('From:', from1)\n",
    "print('Subject:', subject1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9ba7a36e7ea108cfaa0fd5a26710c79f",
     "grade": true,
     "grade_id": "reader_header_test_1",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(to1, 'Chris Garrigues <cwg-dated-1030314468.7c7c85@DeepEddy.Com>')\n",
    "assert_equal(from1, 'Robert Elz <kre@munnari.OZ.AU>')\n",
    "assert_equal(subject1, 'Re: New Sequences Window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b51a2e17d80ea5d8a42157b699afad7e",
     "grade": false,
     "grade_id": "read_header_run_2",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "email2 = '/home/data_scientist/data/email/spam/00001.317e78fa8ee2f54cd4890fdc09ba8176'\n",
    "to2, from2, subject2 = read_header(email2)\n",
    "print('To:', to2)\n",
    "print('From:', from2)\n",
    "print('Subject:', subject2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c4b660dc3299aeddd8fd9fab7aa4cf3f",
     "grade": true,
     "grade_id": "reader_header_test_2",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(to2, 'ilug@linux.ie')\n",
    "assert_equal(from2, 'Start Now <startnow2002@hotmail.com>')\n",
    "assert_equal(subject2, '[ILUG] STOP THE MLM INSANITY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0d83534258629576c7cfb6c6c9ecf8ff",
     "grade": false,
     "grade_id": "markdown_3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Payload\n",
    "\n",
    "- Write a function named `get_payload()` that iterates through each file in a directory specified by the `path` parameter and returns a list of emails. The function only reads in files in a specified range. For example, if `start` is 500 and `end` is 999, the function reads all emails from the 500th email (in the order as determined by `os.walk()`) to the 999th email, inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ebdc3fe69d5ad773a1dfa27fcd6b30c6",
     "grade": false,
     "grade_id": "get_payload_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_payload(path, start, end):\n",
    "    '''\n",
    "    Iterates through each file in a directory and reads emails.\n",
    "    \n",
    "    Paremters\n",
    "    ---------\n",
    "    path: A string.\n",
    "    start: An int.\n",
    "    end: An int.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of strings.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "260c50b611055cb071f2cd39f6906c00",
     "grade": false,
     "grade_id": "get_payload_run_ham",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ham = get_payload('/home/data_scientist/data/email/ham', start=500, end=999)\n",
    "print(ham[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a9036e49d6a490ed5b7fa646e0f68a2e",
     "grade": true,
     "grade_id": "get_payload_test_1",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(ham, list)\n",
    "assert_true(all(isinstance(h, str) for h in ham))\n",
    "assert_equal(len(ham), 500)\n",
    "assert_true(ham[0].startswith('Ad Aware sometimes helps too.'))\n",
    "assert_true(ham[-1].startswith('On 10 Aug 2002, Gary Lawrence Murphy wrote:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7edaaac8116a602666d175c6601ecac4",
     "grade": false,
     "grade_id": "get_payload_run_spam",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "spam = get_payload('/home/data_scientist/data/email/spam', start=500, end=999)\n",
    "print(spam[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ffb99ce895af08602add506ca5f9255d",
     "grade": true,
     "grade_id": "get_payload_test_2",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(spam, list)\n",
    "assert_true(all(isinstance(s, str) for s in spam))\n",
    "assert_equal(len(spam), 500)\n",
    "assert_true(spam[0].startswith('Dear Sirs,\\nWe know your esteemed company in beach towels'))\n",
    "assert_true(spam[-1].startswith('Hi,\\n\\nI\\'m a college dropout.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bf2d735750933932c60e7f046cedac57",
     "grade": false,
     "grade_id": "markdown_4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Convert list to Numpy array\n",
    "\n",
    "- Convert `ham` and `spam` to Numpy arrays and return them as `pos_emails` and `neg_emails`, respectively. Return Numpy arrays for the labels, where each `ham` is labeled 1 and each `spam` 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "58d1f9d2556f1f7e34feb750ed1a1fcd",
     "grade": false,
     "grade_id": "list_to_array_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def list_to_array(ham, spam):\n",
    "    '''\n",
    "    Converts a list of emails to Numpy array and labels them.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ham: A list of strings.\n",
    "    spam: A lsit of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 4-tuple of (pos_emails, neg_emails, pos_labels, neg_labels)\n",
    "    All Numpy arrays.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return pos_emails, neg_emails, pos_labels, neg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "97c0dba16c2c6ea9f42dd16f8488a4f8",
     "grade": false,
     "grade_id": "list_to_array_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pos_emails, neg_emails, pos_labels, neg_labels = list_to_array(ham, spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "80ebebd6eadec178f9b61c719cf292fe",
     "grade": true,
     "grade_id": "list_to_array_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(pos_emails, np.ndarray)\n",
    "assert_is_instance(neg_emails, np.ndarray)\n",
    "assert_is_instance(pos_labels, np.ndarray)\n",
    "assert_is_instance(neg_labels, np.ndarray)\n",
    "assert_array_equal(pos_emails, ham)\n",
    "assert_array_equal(neg_emails, spam)\n",
    "assert_array_equal(pos_labels, [1] * len(ham))\n",
    "assert_array_equal(neg_labels, [0] * len(spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3255a2007fdefbb3dc647b6566ad7b56",
     "grade": false,
     "grade_id": "markdown_5",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Create training and test sets\n",
    "\n",
    "- Create four new arrays from our email data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "0242ed93c769762dda54c711c9485944",
     "grade": false,
     "grade_id": "train_test_split_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(pos_emails, neg_emails, pos_labels, neg_labels, split_value):\n",
    "    '''\n",
    "    Creates four arrays from emails and labels by using \"split_value\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pos_emails: A numpy array of strings.\n",
    "    neg_emails: A numpy array of strings.\n",
    "    pos_labels: A numpy array of ints or floats.\n",
    "    neg_labels: A numpy array of ints or floats.\n",
    "    split_value: An int.\n",
    "                 If split_value is 300, the training set will consist of the first\n",
    "                 300 emails in pos_emails plus the first 300 emails in neg_emails,\n",
    "                 and the rest of the emails go into the test set.\n",
    "                 \n",
    "    Returns\n",
    "    -------\n",
    "    A 4-tuple of (X_train, X_test, y_train, y_test)\n",
    "    All numpy arrays.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2f9987bd64bbf3f8df9e106e3a8c9910",
     "grade": false,
     "grade_id": "train_test_split_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    pos_emails, neg_emails, pos_labels, neg_labels, split_value=400\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2f26f624ce755e3f97a16b113d54cd43",
     "grade": true,
     "grade_id": "train_test_split_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(X_train, np.ndarray)\n",
    "assert_is_instance(X_test, np.ndarray)\n",
    "assert_is_instance(y_train, np.ndarray)\n",
    "assert_is_instance(y_test, np.ndarray)\n",
    "assert_array_equal(X_train[:400], pos_emails[:400])\n",
    "assert_array_equal(X_train[400:], neg_emails[:400])\n",
    "assert_array_equal(X_test[:len(pos_emails) - 400], pos_emails[400:])\n",
    "assert_array_equal(X_test[len(pos_emails) - 400:], neg_emails[400:])\n",
    "assert_array_equal(y_train[:400], pos_labels[:400])\n",
    "assert_array_equal(y_train[400:], neg_labels[:400])\n",
    "assert_array_equal(y_test[:len(pos_labels) - 400], pos_labels[400:])\n",
    "assert_array_equal(y_test[len(pos_labels) - 400:], neg_labels[400:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dba3e7677448cc02cef393d092ad2319",
     "grade": false,
     "grade_id": "markdown_6",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The following cell deletes the original two numpy email arrays to reduce memory requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "79cf2c28b8c1a856e8e92f5ac9dc2e50",
     "grade": false,
     "grade_id": "xdel",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Remove the original two numpy arrays\n",
    "%xdel pos_emails\n",
    "%xdel neg_emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b80b8eb5a3c018edb3a8069024d24656",
     "grade": false,
     "grade_id": "markdown_7",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Spam classification\n",
    "\n",
    "- Use unigrams and bigrams,\n",
    "- Build a pipeline by using TfidfVectorizer and LinearSVC,\n",
    "- Name the first step tf and the second step svc,\n",
    "- Use default parameters for both TfidfVectorizer and LinearSVC, and\n",
    "- Use English stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "076115631f99292e9d5173f7a2b468fe",
     "grade": false,
     "grade_id": "fit_and_predict_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_and_predict(X_train, y_train, X_test, random_state):\n",
    "    '''\n",
    "    Creates a document term matrix and uses SVM classifier to make document classifications.\n",
    "    Uses English stop words.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: A list of strings.\n",
    "    y_train: A list of strings.\n",
    "    X_test: A list of strings.\n",
    "    random_state: A np.random.RandomState instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (clf, y_pred)\n",
    "    clf: A Pipeline instance.\n",
    "    y_pred: A numpy array.    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return clf, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "06e780aa420a918928f96de38f6a0c02",
     "grade": false,
     "grade_id": "fit_and_predict_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "clf, y_pred = fit_and_predict(X_train, y_train, X_test, random_state=check_random_state(0))\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"SVC prediction accuracy = {0:5.1f}%\".format(100.0 * score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b2e3519399f51dd399ffa3a6e528f604",
     "grade": true,
     "grade_id": "fit_and_predict_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(clf, Pipeline)\n",
    "assert_is_instance(y_pred, np.ndarray)\n",
    "tf = clf.named_steps['tf']\n",
    "assert_is_instance(tf, TfidfVectorizer)\n",
    "assert_is_instance(clf.named_steps['svc'], LinearSVC)\n",
    "assert_equal(tf.ngram_range, (1, 2))\n",
    "assert_equal(tf.stop_words, 'english')\n",
    "assert_equal(len(y_pred), len(y_test))\n",
    "assert_array_equal(y_pred[:10], [1] * 10)\n",
    "assert_array_equal(y_pred[-10:], [0] * 10)\n",
    "assert_almost_equal(score, 1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
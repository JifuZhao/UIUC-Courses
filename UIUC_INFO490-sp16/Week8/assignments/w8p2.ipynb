{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "008110cfa873947a912f27dbe067e82f",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This notebook will be collected automatically at **6pm on Monday** from `/home/data_scientist/assignments/Week8` directory on the course JupyterHub server. If you work on this assignment on the course Jupyterhub server, just make sure that you save your work and instructors will pull your notebooks automatically after the deadline. If you work on this assignment locally, the only way to submit assignments is via Jupyterhub, and you have to place the notebook file in the correct directory with the correct file name before the deadline.\n",
    "\n",
    "1. Make sure everything runs as expected. First, restart the kernel (in the menubar, select `Kernel` → `Restart`) and then run all cells (in the menubar, select `Cell` → `Run All`).\n",
    "2. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed by the autograder.\n",
    "3. Do not change the file path or the file name of this notebook.\n",
    "4. Make sure that you save your work (in the menubar, select `File` → `Save and CheckPoint`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "32beb22e4a2dfcbf4dbbbc17da9f704e",
     "grade": false,
     "grade_id": "markdown_1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem 8.2. Social Media: Twitter\n",
    "\n",
    "In this problem, we will use the twitter API to extract a set of tweets, and perform a sentiment analysis on twitter data to classify tweets as positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6811defb28e16a211a301ded40078d25",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import tweepy as tw\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_instance, assert_true, assert_almost_equal\n",
    "from numpy.testing import assert_array_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "faff6c4671d3b888d1dcbbf1d6e9a92b",
     "grade": false,
     "grade_id": "markdown_2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Twitter Application\n",
    "\n",
    "- Create a Twitter Application, and save the credentials into a file at `/home/data_scientist/Week8/notebooks/twitter.cred`. \n",
    "\n",
    "`twitter.cred` must have the following four credentials in order on separate lines:\n",
    "\n",
    "```\n",
    "Access Token\n",
    "Access Token Secret\n",
    "Consumer Key\n",
    "Consumer Secret\n",
    "```\n",
    "\n",
    "Once you have stored your credientials, run the following code cells (you don't have to write any code in this section) and check if you are able to use the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "79304f86ea6479e3c2e4d320d1560f66",
     "grade": false,
     "grade_id": "connect_twitter_api",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def connect_twitter_api(cred_file):\n",
    "    \n",
    "    # Order: Access Token, Access Token Secret, Consumer Key, Consumer SecretAccess\n",
    "    with open(cred_file) as fin:\n",
    "        tokens = [line.rstrip('\\n') for line in fin if not line.startswith('#')]\n",
    "\n",
    "    auth = tw.OAuthHandler(tokens[2], tokens[3])\n",
    "    auth.set_access_token(tokens[0], tokens[1])\n",
    "\n",
    "    return tw.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "3a79d987091e21c83b1b999fa3dc81d7",
     "grade": true,
     "grade_id": "connect_twitter_api_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Do NOT change file path or name of twitter.cred\n",
    "api = connect_twitter_api('/home/data_scientist/Week8/notebooks/twitter.cred')\n",
    "assert_equal(api.get_user('katyperry').screen_name, 'katyperry')\n",
    "assert_equal(api.get_user('justinbieber').created_at.strftime('%Y %m %d %H %M %S'), '2009 03 28 16 41 22')\n",
    "assert_equal(api.get_user('BarackObama').name, 'Barack Obama')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1d9cdba64cf91a7d047230ff0a3d4fce",
     "grade": false,
     "grade_id": "markdown_3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Positive and negative tweets\n",
    "\n",
    "We will first train a model on the NLTK twitter corpus, and use it to classify a set of tweets fetched from the Twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "d002abeed67f6272d912c396f745bd8b",
     "grade": false,
     "grade_id": "import_twitter_samples",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples as tws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "782ef32210576f371203bf83f90e8c9a",
     "grade": false,
     "grade_id": "markdown_4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "- Write a function that creates a training set from the NLTK twitter corpus. Positive tweets are in `positive_tweets.json`, while negative tweets are in `negative_tweets.json`. The `data` and `targets` ararys should be one-dimensional numpy arrays, where the first half are the positive tweets and the second half are the negative tweets. Every positive tweets should be assigned a numerical label of 1 in `targets`, and negative tweets 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0c42bc0d65a4eedcc456aba24fcc2d47",
     "grade": false,
     "grade_id": "get_pos_neg_tweets_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_pos_neg_tweets(corpus):\n",
    "    '''\n",
    "    Creates a training set from twitter_samples corpus.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus: The nltk.corpus.twitter_samples corpus.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (data, targets)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "8202a842ed2430cffe38e04a04a2d178",
     "grade": false,
     "grade_id": "get_pos_neg_tweets_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data, targets = get_pos_neg_tweets(tws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "1c988473cbb272cb7889830add6da847",
     "grade": true,
     "grade_id": "get_pos_neg_tweets_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(data, np.ndarray)\n",
    "assert_is_instance(targets, np.ndarray)\n",
    "assert_equal(len(data), 10000)\n",
    "assert_equal(len(targets), 10000)\n",
    "assert_array_equal(\n",
    "    data[:5],\n",
    "    [\n",
    "        '#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top '\n",
    "            'engaged members in my community this week :)',\n",
    "        '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234'\n",
    "            ' and we will be able to assist you :) Many thanks!',\n",
    "        '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing '\n",
    "            'track. When are you in Scotland?!',\n",
    "        '@97sides CONGRATS :)',\n",
    "        'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark '\n",
    "            'on my fb profile :) in 15 days'\n",
    "        ]\n",
    "    )\n",
    "assert_array_equal(\n",
    "    data[5000:5005],\n",
    "    [\n",
    "        'hopeless for tmr :(',\n",
    "        \"Everything in the kids section of IKEA is so cute. Shame I'm nearly 19 in \"\n",
    "            \"2 months :(\",\n",
    "        '@Hegelbon That heart sliding into the waste basket. :(',\n",
    "        '“@ketchBurning: I hate Japanese call him \"bani\" :( :(”\\n\\nMe too',\n",
    "        'Dang starting next week I have \"work\" :('\n",
    "        ]\n",
    "    )\n",
    "assert_array_equal(targets[:5000], [1] * 5000)\n",
    "assert_array_equal(targets[5000:], [0] * 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b1cde131e5d8089c74bc8d1595289786",
     "grade": false,
     "grade_id": "markdown_5",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Training\n",
    "\n",
    "We train on 80% of the data, and test the performance on the remaining 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "817bc70c856a9e6c753e28af0b2d550f",
     "grade": false,
     "grade_id": "train_test_split",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, targets, test_size=0.2, random_state=check_random_state(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "17473b9f25df5a489a8e098ce8606b3b",
     "grade": false,
     "grade_id": "markdown_6",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "- Use unigrams, bigrams, and trigrams.\n",
    "- Build a pipeline by using TfidfVectorizer and LinearSVC,\n",
    "- Name the first step tf and the second step svc,\n",
    "- Use default parameters for both TfidfVectorizer and LinearSVC, and\n",
    "- Use English stop words,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "758576674e3b65877125d8c7656bd1e1",
     "grade": false,
     "grade_id": "train_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def train(X_train, y_train, X_test, random_state):\n",
    "    '''\n",
    "    Creates a document term matrix and uses SVM classifier to make document classifications.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: A list of strings.\n",
    "    y_train: A list of strings.\n",
    "    X_test: A list of strings.\n",
    "    random_state: A np.random.RandomState instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (clf, y_pred)\n",
    "    clf: A Pipeline instance.\n",
    "    y_pred: A numpy array.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return clf, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b8d9209d4055b7024dfbe605a0a8c7dd",
     "grade": false,
     "grade_id": "train_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "clf, y_pred = train(X_train, y_train, X_test, random_state=check_random_state(0))\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print(\"SVC prediction accuracy = {0:5.1f}%\".format(100.0 * score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "79e3417f4bbe57e002b13e4a470867c3",
     "grade": true,
     "grade_id": "train_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(clf, Pipeline)\n",
    "assert_is_instance(y_pred, np.ndarray)\n",
    "tf = clf.named_steps['tf']\n",
    "assert_is_instance(tf, TfidfVectorizer)\n",
    "assert_is_instance(clf.named_steps['svc'], LinearSVC)\n",
    "assert_equal(tf.stop_words, 'english')\n",
    "assert_equal(tf.ngram_range, (1, 3))\n",
    "assert_equal(len(y_pred), len(y_test))\n",
    "assert_array_equal(y_pred[:10], [0, 1, 1, 0, 1, 0, 0, 0, 1, 1])\n",
    "assert_array_equal(y_pred[-10:], [0, 0, 1, 1, 1, 0, 0, 1, 1, 0])\n",
    "assert_almost_equal(score, 0.76400000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6f3aaf149b7904802390c61294af0b97",
     "grade": false,
     "grade_id": "markdown_7",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## User timeline\n",
    "\n",
    "- Use Tweepy's [user_timeline()](http://docs.tweepy.org/en/latest/api.html#API.user_timeline) to extract 20 tweets from a specified user. Specify the `max_id` parameter for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "cefb36e8679270c22d7e8b34137faa0e",
     "grade": false,
     "grade_id": "get_timeline_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_timeline(user, max_id):\n",
    "    '''\n",
    "    Fetches 20 tweets from \"user\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    user: A string. The ID or screen name of a Twitter user.\n",
    "    max_id: An int. Returns only statuses with an ID less than\n",
    "            (that is, older than) or equal to the specified ID.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of integers.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "272643b1c7458a4801ee7e03ac53d808",
     "grade": false,
     "grade_id": "get_timeline_run_1",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "timeline1 = get_timeline('HillaryClinton', max_id=705395196817702912)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "d1cc1bbbb77adb61523a53990cc434be",
     "grade": false,
     "grade_id": "get_timeline_run_2",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "timeline2 = get_timeline('realDonaldTrump', max_id=705362027901009921)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "13de7bc722c2cffcef049c00c72b97e8",
     "grade": true,
     "grade_id": "get_timeline_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(\n",
    "    [t.id for t in timeline1],\n",
    "    [705395196817702912, 705176659457085440, 705176341877014528, 705160472727830528,\n",
    "     705143770640044032, 705131896305541120, 705129859941584896, 705099211285667840,\n",
    "     705075594451505153, 705061640031567872, 705029404641009664, 704887859514318848,\n",
    "     704881748207861760, 704878458619498496, 704871605265047552, 704862926671249408,\n",
    "     704856851721146369, 704851986966036480, 704850687641985024, 704849583160082434]\n",
    "    )\n",
    "assert_equal(\n",
    "    [t.id for t in timeline2],\n",
    "    [705362027901009921, 705358901349388289, 705357122859614209, 705354682886201348,\n",
    "     705352657234481152, 705235874632638464, 705234524012224512, 705230846249324544,\n",
    "     705229104426176514, 705227593205878784, 705213112463577088, 705179512254951424,\n",
    "     705174403164860416, 705174362530430976, 705173204948656129, 705170546003218432,\n",
    "     705149907183738880, 705148300064907265, 705119106052308992, 705102512718782465])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f77dde16a13bbde32a6c5dcd43e10cbd",
     "grade": false,
     "grade_id": "markdown_8",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Make predictions\n",
    "\n",
    "- Use the SVM classifier to classify each tweet in timeline as a positive tweet or a negative tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "bffb4cd0f3e5330590836792b3572df4",
     "grade": false,
     "grade_id": "predict_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict(clf, timeline):\n",
    "    '''\n",
    "    Uses a classifier (\"clf\") to classify each tweet in\n",
    "    \"timeline\" as a positive tweet or a negative tweet.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    clf: A Pipeline instance.\n",
    "    timeline: A tweepy.models.ResultSet instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A numpy array.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "dc3424163b17c51de2334787fb060a10",
     "grade": false,
     "grade_id": "predict_run_1",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pred1 = predict(clf, timeline1)\n",
    "print('{} has {} positive tweets and {} negative tweets.'.format(\n",
    "    'Hillary Clinton', (pred1 == 1).sum(), (pred1 == 0).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "58c293bdbf857761893fa70e1243cd80",
     "grade": true,
     "grade_id": "predict_test_1",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(pred1, np.ndarray)\n",
    "assert_array_equal(\n",
    "     pred1,\n",
    "     [1., 0., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
    "      1., 1., 1., 1., 0., 1., 1., 1., 1., 0.]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "264cf842f06175390f0d4a5f45ce0e98",
     "grade": false,
     "grade_id": "predict_run_2",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pred2 = predict(clf, timeline2)\n",
    "print('{} has {} positive tweets and {} negative tweets.'.format(\n",
    "    'Donald Trump', (pred2 == 1).sum(), (pred2 == 0).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "89eec53d8b5817db49670575b1f50525",
     "grade": true,
     "grade_id": "predict_test_2",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(pred2, np.ndarray)\n",
    "assert_array_equal(\n",
    "     pred2,\n",
    "     [0., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
    "      1., 1., 0., 0., 1., 0., 0., 1., 1., 1.]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

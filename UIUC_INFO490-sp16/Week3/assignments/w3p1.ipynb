{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2bfe5ed8b49c3cce14972ef1c05ac66c",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This notebook will be collected automatically at **6pm on Monday** from `/home/data_scientist/assignments/Week3` directory on the course JupyterHub server. If you work on this assignment on the course Jupyterhub server, just make sure that you save your work and instructors will pull your notebooks automatically after the deadline. If you work on this assignment locally, the only way to submit assignments is via Jupyterhub, and you have to place the notebook file in the correct directory with the correct file name before the deadline.\n",
    "\n",
    "1. Make sure everything runs as expected. First, restart the kernel (in the menubar, select `Kernel` → `Restart`) and then run all cells (in the menubar, select `Cell` → `Run All`).\n",
    "2. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed by the autograder.\n",
    "3. Do not change the file path or the file name of this notebook.\n",
    "4. Make sure that you save your work (in the menubar, select `File` → `Save and CheckPoint`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3.1. Supervised Learning: Nearest Neighbor\n",
    "\n",
    "In this problem, we will use $k$-Nearest Neighbors to see if we can use machine learning techniques to predict departure delays at the O'Hare airport (ORD). For simplicity, we will use only six attributes: `Month`, `DayofMonth`, `DayOfWeek`, `CRSDepTime`, `CRSArrTime`, and `Distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "3d2f296c2e3bd7f55d81ee74f5ce8a80",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nose.tools import assert_equal, assert_in, assert_is_not\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal\n",
    "from pandas.util.testing import assert_frame_equal, assert_index_equal\n",
    "\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the 2001 on-time airline performance data set. We import the following columns:\n",
    "\n",
    "- Column 1: Month, 1-12\n",
    "- Column 2: DayofMonth, 1-31\n",
    "- Column 3: DayOfWeek, 1 (Monday) - 7 (Sunday)\n",
    "- Column 5: CRSDepTime, scheduled departure time (local, hhmm)\n",
    "- Column 7: CRSArrTime, scheduled arrival time (local, hhmm)\n",
    "- Column 15: DepDelay, departure delay, in minutes\n",
    "- Column 16: Origin, origin IATA airport code\n",
    "- Column 18: Distance, in miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "15933b32d937a27e7ed55255ac5a9d6b",
     "grade": false,
     "grade_id": "read_csv",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '/home/data_scientist/data/2001.csv',\n",
    "    encoding='latin-1',\n",
    "    usecols=(1, 2, 3, 5, 7, 15, 16, 18)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use only the flights that departed from ORD. We define a flight to be delayed if its departure delay is 15 minutes or more, the same definition used by the FAA (source: [Wikipedia](https://en.wikipedia.org/wiki/Flight_cancellation_and_delay))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "67d48679239012aa77f7a056cdbb66c1",
     "grade": false,
     "grade_id": "local",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "local = df[df['Origin'] == 'ORD']\n",
    "local = local.drop('Origin', axis=1) # we don't need the Origin column anymore.\n",
    "local['Delayed'] = (local['DepDelay'] >= 15).astype(np.int) # 1 if a flight was delayed, 0 if not.\n",
    "local = local.drop('DepDelay', axis=1).dropna() # we don't need the DepDelay column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the first few columns and see what we'll be working with.\n",
    "\n",
    "```python\n",
    ">>> print(local.head(5))\n",
    "```\n",
    "\n",
    "```\n",
    "      Month  DayofMonth  DayOfWeek  CRSDepTime  CRSArrTime  Distance  Delayed\n",
    "6367      1           1          1         951        1235       599        0\n",
    "6368      1           2          2         951        1235       599        0\n",
    "6369      1           3          3         951        1235       599        0\n",
    "6370      1           4          4         951        1235       599        1\n",
    "6371      1           5          5         951        1235       599        0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a21dce3e8525d5c0130ef5fcc3f26831",
     "grade": false,
     "grade_id": "print_local_head",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(local.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split\n",
    "\n",
    "Write a function named `split()` that takes a DataFrame as its first argument and returns a 4-tuple of DataFrames. The second argument `test_column` specifies which column should be used as a label (`Delayed` in our case). All remaining columns except `test_column` should be used for training. In other words, the returned DataFrames `y_train` and `y_test` both have only one column, `test_column`, and `X_train` and `X_test` contain all columns in `df` minus `test_column`.\n",
    "\n",
    "Don't forget that we have to pass an instance of `check_random_state()` to the `train_test_split()` function for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "44c0df76f1074c13ffd6881436ca5487",
     "grade": false,
     "grade_id": "split_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def split(df, test_column, test_size, random_state):\n",
    "    '''\n",
    "    Uses sklearn.train_test_split to split \"df\" into a testing set and a test set.\n",
    "    The \"test_columns\" lists the column that we are trying to predict.\n",
    "    All columns in \"df\" except \"test_columns\" will be used for training.\n",
    "    The \"test_size\" should be between 0.0 and 1.0 and represents the proportion of the\n",
    "    dataset to include in the test split.\n",
    "    The \"random_state\" parameter is used in sklearn.train_test_split.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: A pandas.DataFrame\n",
    "    test_columns: A list of strings\n",
    "    test_size: A float\n",
    "    random_state: A numpy.random.RandomState instance\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 4-tuple of pandas.DataFrames\n",
    "    '''\n",
    "    ##################\n",
    "    # YOUR CODE HERE\n",
    "    ##################\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will split `local` into a training set (used for training our model), a validation set (used for determining hyperparameters), and a test set (used for evaluating our model's performance). We can use the `split` function twice with different `test_size` to split `local` into training:validation:test = 60:20:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "987a8bc8546d4c20dc33f73e2cb79908",
     "grade": false,
     "grade_id": "split_run_test",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_valid, X_test, y_train_valid, y_test = split(\n",
    "    df=local,\n",
    "    test_column=['Delayed'],\n",
    "    test_size=0.2,\n",
    "    random_state=check_random_state(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code cell, we test if the returned DataFrames have the correct columns and lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "21367aa2868ebe1b7455a01bbb1b5081",
     "grade": true,
     "grade_id": "split_test_1",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(isinstance(X_train_valid, pd.DataFrame), True)\n",
    "assert_equal(isinstance(X_test, pd.DataFrame), True)\n",
    "assert_equal(isinstance(y_train_valid, pd.DataFrame), True)\n",
    "assert_equal(isinstance(y_test, pd.DataFrame), True)\n",
    "\n",
    "assert_equal(len(X_train_valid) - np.round(len(local) * 0.8) <= 1, True)\n",
    "assert_equal(len(X_test) - np.round(len(local) * 0.2) <= 1, True)\n",
    "assert_equal(len(y_train_valid) - np.round(len(local) * 0.8) <= 1, True)\n",
    "assert_equal(len(y_test) - np.round(len(local) * 0.2) <= 1, True)\n",
    "\n",
    "assert_index_equal(X_train_valid.columns, local.columns.drop('Delayed'))\n",
    "assert_index_equal(X_test.columns, local.columns.drop('Delayed'))\n",
    "assert_equal(y_train_valid.columns, pd.Index(['Delayed']))\n",
    "assert_equal(y_test.columns, pd.Index(['Delayed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split `X_train_valid` and `y_train_valid` (80% of `local`) by using `test_size = 0.25`, which makes `X_train` and `y_train` 60% of `local`, and `X_valid` and `y_valid` 20 % of `local`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "210c9434dc883f8803ec6ee17392c9e5",
     "grade": false,
     "grade_id": "split_run_valid",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = split(\n",
    "    df=X_train_valid.join(y_train_valid),\n",
    "        test_column=['Delayed'],\n",
    "    test_size=0.25,\n",
    "    random_state=check_random_state(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already checked the types of returned values and the columns, so now we only check the lengths and indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "eb0c8c414ef439bf5c916f4c35766950",
     "grade": true,
     "grade_id": "split_test_2",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(len(X_train) - np.round(len(local) * 0.6) <= 1, True)\n",
    "assert_equal(len(X_valid) - np.round(len(local) * 0.2) <= 1, True)\n",
    "assert_equal(len(y_train) - np.round(len(local) * 0.6) <= 1, True)\n",
    "assert_equal(len(X_valid) - np.round(len(local) * 0.2) <= 1, True)\n",
    "\n",
    "assert_index_equal(X_train.index[:5], pd.Int64Index([5903153, 1200840, 4524718, 2419368, 4017270]))\n",
    "assert_index_equal(X_valid.index[:5], pd.Int64Index([722372, 3342898, 4673529,  896758, 1744337]))\n",
    "assert_index_equal(y_train.index, X_train.index)\n",
    "assert_index_equal(y_valid.index, X_valid.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize\n",
    "\n",
    "Note that the six columns we want to use for training have different scales.\n",
    "\n",
    "```python\n",
    ">>> print(local.min())\n",
    "```\n",
    "\n",
    "```\n",
    "Month           1\n",
    "DayofMonth      1\n",
    "DayOfWeek       1\n",
    "CRSDepTime    530\n",
    "CRSArrTime      1\n",
    "Distance       67\n",
    "Delayed         0\n",
    "dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a811845a6baf4c61fd8ea431471e25ac",
     "grade": false,
     "grade_id": "print_local_min",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(local.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> print(local.max())\n",
    "```\n",
    "\n",
    "```\n",
    "Month           12\n",
    "DayofMonth      31\n",
    "DayOfWeek        7\n",
    "CRSDepTime    2245\n",
    "CRSArrTime    2359\n",
    "Distance      4243\n",
    "Delayed          1\n",
    "dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6560db2ac3dff9aab736aec493f57fa8",
     "grade": false,
     "grade_id": "print_local_max",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(local.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we apply the machine learning technique, we should standardize the features. One way to do this is to rescale the range of features to [0, 1]:\n",
    "\n",
    "$$x' = \\frac{x - \\text{min}(x)}{\\text{max}(x)-\\text{min}(x)}$$\n",
    "\n",
    "where $x$ is an original value, $x'$ is the normalized value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "e7d8fd359d70c84718a8d926ec1a7ca6",
     "grade": false,
     "grade_id": "normalize_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    '''\n",
    "    Takes a dataframe and normlizes features to be in range [0, 1].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: A pandas.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pandas.DataFrame\n",
    "    '''\n",
    "    ##################\n",
    "    # YOUR CODE HERE\n",
    "    ##################\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our function by printing out the minimum and maximum values.\n",
    "\n",
    "```python\n",
    ">>> X_train_normal, X_valid_normal = map(normalize, [X_train, X_valid])\n",
    ">>> print(X_train_normal.min())\n",
    "```\n",
    "\n",
    "```\n",
    "Month         0\n",
    "DayofMonth    0\n",
    "DayOfWeek     0\n",
    "CRSDepTime    0\n",
    "CRSArrTime    0\n",
    "Distance      0\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> print(X_train_normal.max())\n",
    "```\n",
    "\n",
    "```\n",
    "Month         1\n",
    "DayofMonth    1\n",
    "DayOfWeek     1\n",
    "CRSDepTime    1\n",
    "CRSArrTime    1\n",
    "Distance      1\n",
    "dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "774309bea9f0ec3b7b636587fa1a71fb",
     "grade": false,
     "grade_id": "print_normal_min",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_normal, X_valid_normal = map(normalize, [X_train, X_valid])\n",
    "print(X_train_normal.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2b9ab7790f31cac663e09e4991ff97d9",
     "grade": false,
     "grade_id": "print_normal_max",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(X_train_normal.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "80a7b3b740be71a1b3d4daa9aac7a0a1",
     "grade": true,
     "grade_id": "normalize_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame({\n",
    "    'a': [0, 1, 2, 3, 4],\n",
    "    'b': [-50, -20, 10, 45, 50],\n",
    "    'c': [-200, 450, 100, 500, -500]\n",
    "    })\n",
    "\n",
    "test1 = normalize(df0)\n",
    "answer1 = pd.DataFrame({\n",
    "    'a': [0., 0.25, 0.5, 0.75, 1.],\n",
    "    'b': [0., 0.3, 0.6, 0.95, 1.],\n",
    "    'c': [0.3, 0.95, 0.6, 1., 0.]\n",
    "    })\n",
    "assert_frame_equal(test1, answer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a k-Nearest Neighbors model\n",
    "\n",
    "Now that we have standardized the training and validation sets, we are finally ready to apply the $k$-Nearest Neighbors algorithm. We will break it down into small steps.\n",
    "\n",
    "First, write a function named `train_knn()` that fits a $k$-Nearest Neighbors on the training data and returns the trained model (an `sklearn.neighbors.KNeighborsClassifier` object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "8fef1488dd0aecad94102f57b0737e35",
     "grade": false,
     "grade_id": "train_knn_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def train_knn(X, y, n_neighbors):\n",
    "    '''\n",
    "    Fits a $k$-Nearest Neighbors on the training data.\n",
    "    Returns the trained model (an `sklearn.neighbors.KNeighborsClassifier` object).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A pandas.DataFrame. Training attributes.\n",
    "    y: A pandas.DataFrame. Truth labels.\n",
    "    n_neighbors: Number of neighbors to use in kNN.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    An sklearn.neighbors.KNeighborsClassifier object.\n",
    "    '''\n",
    "    ##################\n",
    "    # YOUR CODE HERE\n",
    "    ##################\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7eb23e2e3749ea44dc5d97772928e37c",
     "grade": true,
     "grade_id": "train_knn_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_X_train = pd.DataFrame({\n",
    "    'a': np.random.rand(100),\n",
    "    'b': np.random.rand(100)\n",
    "    })\n",
    "test_y_train = pd.DataFrame({\n",
    "    'y': np.floor(np.random.rand(100) * 2)\n",
    "    })\n",
    "\n",
    "test2 = train_knn(test_X_train, test_y_train, 1)\n",
    "\n",
    "assert_equal(isinstance(test2, neighbors.KNeighborsClassifier), True)\n",
    "assert_equal(test2.n_neighbors, 1)\n",
    "assert_array_almost_equal(test2._fit_X, test_X_train)\n",
    "assert_array_equal(test2._y, test_y_train.values.ravel())\n",
    "\n",
    "# test with different n_neighbors\n",
    "test3 = train_knn(test_X_train, test_y_train, 5)\n",
    "assert_equal(test3.n_neighbors, 5)\n",
    "assert_array_almost_equal(test3._fit_X, test_X_train)\n",
    "assert_array_equal(test3._y, test_y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "Write a function named `predict_knn()` that fits an `sklearn.neighbors.KNeighborsClassifier` model on `X` and returns a **pandas.DataFrame** of predicted values. Note that sklearn's `predict()` function will return a Numpy array even if you pass in a DataFrame. You should convert this array to a DataFrame because we will compare the predictions with `y_test` which is a DataFrame. Alternatively, you may choose to convert all DataFrames to arrays and work with arrays. You just have to be consistent with data types, and we simply choose to prefer DataFrames here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "1ea62cc52afabc1edd5c043e46b609b4",
     "grade": false,
     "grade_id": "predict_knn_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_knn(model, X):\n",
    "    '''\n",
    "    Fits an `sklearn.neighbors.KNeighborsClassifier` model on `X` and\n",
    "    returns a `numpy.ndarray` of predicted values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: An sklearn.neighbors.KNeighborsClassifier object.\n",
    "    X: pandas.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pandas.DataFrame. Has one column \"Delayed\".\n",
    "    '''\n",
    "    ##################\n",
    "    # YOUR CODE HERE\n",
    "    ##################\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b015f761cf4ca9b6c1347b37e930745b",
     "grade": true,
     "grade_id": "predict_knn_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test4_model = train_knn(X_train, y_train, 1)\n",
    "test4 = predict_knn(test4_model, X_valid)[:10]\n",
    "answer4 = pd.DataFrame({\n",
    "    'Delayed': [1, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
    "    })\n",
    "\n",
    "assert_equal(isinstance(test4, pd.DataFrame), True)\n",
    "assert_frame_equal(test4, answer4)\n",
    "\n",
    "test5_model = train_knn(X_train, y_train, 3)\n",
    "test5 = predict_knn(test5_model, X_valid)[:10]\n",
    "answer5 = pd.DataFrame({\n",
    "    'Delayed': [1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    })\n",
    "assert_frame_equal(test5, answer5)\n",
    "\n",
    "test6_model = train_knn(X_train, y_train, 5)\n",
    "test6 = predict_knn(test6_model, X_valid)[:10]\n",
    "answer6 = pd.DataFrame({\n",
    "    'Delayed': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    })\n",
    "assert_frame_equal(test6, answer6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use accuracy to find the best model\n",
    "\n",
    "We are now going to use the validation set to search for the best value of $k$ from from $k=1$ to $k=50$. Thus, write a function named `compute_accuracy()` that trains 50 $k$-Nearest Neighbors model and returns a Numpy array of 50 accuracy scores for each model with different values of $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "aec6853bb128d1e7697e87d44d6776d9",
     "grade": false,
     "grade_id": "compute_accuracy_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(X_train, X_valid, y_train, y_valid, start=1, end=51):\n",
    "    '''\n",
    "    Find accuracy scores for kNN classifers\n",
    "    with n_neighbors = start, start + 1, start + 2, ..., end - 1.\n",
    "    Returns a Numpy array of length end - start.\n",
    "    For example, if start=1 and end=4, then len(scores) = 3, and\n",
    "    scores[0] cooresponds to the accuracy of kNN with k=1,\n",
    "    scores[1] the accuracy of kNN with k=2, ..., and\n",
    "    scores[2] the accuracy of KNN with k=3.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: A pandas.DataFrame\n",
    "    X_valid: A pandas.DataFrame\n",
    "    y_train: A pandas.DataFrame\n",
    "    y_valid: A pandas.DataFrame\n",
    "    start: An int.\n",
    "    end: An int.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A numpy.ndarray\n",
    "    '''\n",
    "    ##################\n",
    "    # YOUR CODE HERE\n",
    "    ##################\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will search the hyperparameter space ranging from $k=1$ to $k=50$ for the best accuracy score, but let's perform a short test first to see if the function is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "931808b2115289590d5611c8305ffece",
     "grade": true,
     "grade_id": "compute_accuracy_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test6 = compute_accuracy(X_train, X_valid, y_train, y_valid, 2, 5)\n",
    "assert_array_almost_equal(test6, [0.78034487, 0.74846536, 0.78298197])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do a full search from $k=1$ to $k=50$. This might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "645324d6aebd1327b2da54f1872707ff",
     "grade": false,
     "grade_id": "compute_accuracy_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "scores = compute_accuracy(X_train, X_valid, y_train, y_valid, 1, 51)\n",
    "k_best = np.argmax(scores) + 1 # because we started counting from k=1\n",
    "print('The best model: k = {}'.format(k_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have decided on our model ($k=48$), we can now use **both** the training set and the validation set for training, and then use the test set to evaulate the performance.\n",
    "\n",
    "```python\n",
    ">>> print(\"The accuracy score on the test set is {:2.1f}%.\".format(accuracy * 100))\n",
    "```\n",
    "\n",
    "```\n",
    "The accuracy of k-Nearest Neighbors is 82.0%.\n",
    "```\n",
    "\n",
    "Don't forget to normalize the data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0d996123d27c7a35ae7dfb1e2a6f6801",
     "grade": false,
     "grade_id": "train_knn_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_valid_normal, X_test_normal = map(normalize, [X_train_valid, X_test])\n",
    "\n",
    "final_model = train_knn(X_train_valid_normal, y_train_valid, n_neighbors=k_best)\n",
    "y_pred = predict_knn(final_model, X_test_normal)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"The accuracy of k-Nearest Neighbors is {:2.1f}%.\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of 82% looks pretty good, but we have to be careful when dealing with an unbalanced data set such as ours.\n",
    "\n",
    "```python\n",
    ">>> print((y_train == 0).sum())\n",
    "```\n",
    "\n",
    "```\n",
    "Delayed    163110\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> print((y_train == 1).sum())\n",
    "```\n",
    "\n",
    "```\n",
    "Delayed    41660\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "Flights that were not delayed outnumber delayed flights by 4-to-1. What would happen if we simply say there were no delayed flights? We automatically get an accuracy score of 79.6%.\n",
    "\n",
    "```python\n",
    ">>> accuracy_score(y_test.Delayed.values, np.zeros_like(y_test))\n",
    "```\n",
    "\n",
    "```\n",
    "0.79594766837100961\n",
    "```\n",
    "\n",
    "Maybe we should look at other performance metrics, such as the confusion matrix.\n",
    "\n",
    "## Confusion matrix\n",
    "\n",
    "Plot a a colored heatmap that displays the relationship between predicted and actual types. The `plot_confusion()` function must return a `maplotlib.axes.Axes` object. Use `numpy.histogram2d()` and `seaborn.heatmap()` as demonstrated in lesson 1. Here's an exmaple:\n",
    "\n",
    "![](https://raw.githubusercontent.com/UI-DataScience/info490-sp16/master/Week3/assignments/images/knn_confusion.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "2be9f6b0e4532ce8e7100ed59e785505",
     "grade": false,
     "grade_id": "plot_confusion_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion(): \n",
    "    '''\n",
    "    Plots a confusion matrix using numpy.histogram2d() and seaborn.heatmap().\n",
    "    Returns a maptlotlib.axes.Axes instance.\n",
    "    '''\n",
    "    ##################\n",
    "    # YOUR CODE HERE\n",
    "    ##################\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9f3d95c61088364e89b9095d190ed68b",
     "grade": false,
     "grade_id": "plot_confusion_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ax = plot_confusion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "26b7bf2378bb1a28b5fb53c32cf922a9",
     "grade": true,
     "grade_id": "plot_confusion_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(isinstance(ax, mpl.axes.Axes), True, msg=\"Your function should return a matplotlib.axes.Axes object.\")\n",
    "\n",
    "texts = [t.get_text() for t in ax.texts]\n",
    "assert_equal(texts, ['10558', '3370', '52604', '1725'])\n",
    "             \n",
    "x_tick_labels = [l.get_text() for l in ax.get_xticklabels()]\n",
    "y_tick_labels = [l.get_text() for l in ax.get_yticklabels()]\n",
    "assert_equal(y_tick_labels, ['Delayed', 'Not delayed'])\n",
    "\n",
    "assert_is_not(len(ax.title.get_text()), 0, msg=\"Your plot doesn't have a title.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}